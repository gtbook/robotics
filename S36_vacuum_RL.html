

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>3.6. Reinforcement Learning &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-312077-7"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-312077-7');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S36_vacuum_RL';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Warehouse Robots in 2D" href="S40_logistics_intro.html" />
    <link rel="prev" title="3.5. Markov Decision Processes" href="S35_vacuum_decision.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Introduction to Robotics and Perception - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction to Robotics and Perception
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_intro_state.html">1.1. Representing State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_intro_actions.html">1.2. Robot Actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_intro_sensing.html">1.3. Sensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="S14_intro_perception.html">1.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S15_intro_decision.html">1.5. Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S16_intro_learning.html">1.6. Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayes Nets</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">3.6. Reinforcement Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gtbook/robotics" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS36_vacuum_RL.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S36_vacuum_RL.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Reinforcement Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-to-get-data">3.6.1. Exploring to get Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-based-reinforcement-learning">3.6.2. Model-based Reinforcement Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-free-reinforcement-learning">3.6.3. Model-free Reinforcement Learning</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S36_vacuum_RL.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="reinforcement-learning">
<h1><span class="section-number">3.6. </span>Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permalink to this heading">#</a></h1>
<blockquote>
<div><p>We will talk about model-based and model-free learning.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S36-iRobot_vacuuming_robot-04.jpg"><img alt="Splash image with intelligent looking robot" class="align-center" src="_images/S36-iRobot_vacuuming_robot-04.jpg" style="width: 40%;" /></a>
<section id="exploring-to-get-data">
<h2><span class="section-number">3.6.1. </span>Exploring to get Data<a class="headerlink" href="#exploring-to-get-data" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>Where we gather experience.</p>
</div></blockquote>
<p>Let’s adapt the <code class="docutils literal notranslate"><span class="pre">policy_rollout</span></code> code from the previous section to generate a whole lot of experiences of the form <span class="math notranslate nohighlight">\((x,a,x',r)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">explore_randomly</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="n">N</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Roll out states given a random policy, for given horizon.&quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x1</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">horizon</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">next_state_distribution</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">T</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span>
        <span class="n">x_prime</span> <span class="o">=</span> <span class="n">next_state_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_prime</span><span class="p">,</span> <span class="n">R</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_prime</span><span class="p">]))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x_prime</span>
    <span class="k">return</span> <span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<p>Let us use it to create 499 experiences and show the first 10:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">explore_randomly</span><span class="p">(</span><span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;Living Room&quot;</span><span class="p">),</span> <span class="n">horizon</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(0, 1, 0, 10.0), (0, 0, 0, 10.0), (0, 3, 3, 0.0), (3, 0, 3, 0.0), (3, 1, 4, 0.0), (4, 2, 1, 0.0), (1, 0, 0, 10.0), (0, 1, 1, 0.0), (1, 0, 0, 10.0), (0, 2, 0, 10.0)]
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-based-reinforcement-learning">
<h2><span class="section-number">3.6.2. </span>Model-based Reinforcement Learning<a class="headerlink" href="#model-based-reinforcement-learning" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>Just count, then solve the MDP.</p>
</div></blockquote>
<p>We can <em>estimate</em> the transition probabilities <span class="math notranslate nohighlight">\(T\)</span> and reward table <span class="math notranslate nohighlight">\(R\)</span> from the data, and then we can use the algorithms from before to calculate the value function and/or optimal policy.</p>
<p>The math is just a variant of what we saw in the learning section of the last chapter. The rewards is easiest:</p>
<div class="math notranslate nohighlight">
\[
R(x,a,x') \approx \frac{1}{N(x,a,x')} \sum_{x,a,x'} r
\]</div>
<p>where <span class="math notranslate nohighlight">\(N(x,a,x')\)</span> counts how many times an experience <span class="math notranslate nohighlight">\((x,a,x')\)</span> was recorded. The transition probabilities are a bit trickier:</p>
<div class="math notranslate nohighlight">
\[
P(x'|x,a) \approx \frac{N(x,a,x)}{N(x,a)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(N(x,a)=\sum_{x'} N(x,a,x')\)</span> is the number of times we took action <span class="math notranslate nohighlight">\(a\)</span> in a state <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>The code associated with that is fairly simple, modulo some numpy trickery to deal with division by zero and <em>broadcasting</em> the division:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">T_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_prime</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="n">R_sum</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_prime</span><span class="p">]</span> <span class="o">+=</span> <span class="n">r</span>
    <span class="n">T_count</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_prime</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">R_estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">R_sum</span><span class="p">,</span> <span class="n">T_count</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">T_count</span><span class="o">!=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">xa_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">T_count</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">T_estimate</span> <span class="o">=</span> <span class="n">T_count</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">xa_count</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Above <code class="docutils literal notranslate"><span class="pre">T_count</span></code> corresponds to <span class="math notranslate nohighlight">\(N(x,a,x')\)</span>, and the variable <code class="docutils literal notranslate"><span class="pre">xa_count</span></code> is <span class="math notranslate nohighlight">\(N(x,a)\)</span>. It is good to check the latter to see whether our experiences were more or less representative, i.e., visited all state-action pairs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xa_count</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[30., 24., 37., 33.],
       [27., 30., 26., 26.],
       [20., 18., 21., 18.],
       [20., 22., 28., 27.],
       [24., 20., 27., 21.]])
</pre></div>
</div>
</div>
</div>
<p>This seems pretty good. If not, we can always gather more data, which we encourage you to experiment with.</p>
<p>We can compare the ground truth transition probabilities <span class="math notranslate nohighlight">\(T\)</span> with the estimated transition probabilities <span class="math notranslate nohighlight">\(\hat{T}\)</span>, e.g., for the living room:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ground truth:</span><span class="se">\n</span><span class="si">{</span><span class="n">T</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;estimate:</span><span class="se">\n</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">T_estimate</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ground truth:
[[1.  0.  0.  0.  0. ]
 [0.2 0.8 0.  0.  0. ]
 [1.  0.  0.  0.  0. ]
 [0.2 0.  0.  0.8 0. ]]
estimate:
[[1.   0.   0.   0.   0.  ]
 [0.25 0.75 0.   0.   0.  ]
 [1.   0.   0.   0.   0.  ]
 [0.27 0.   0.   0.73 0.  ]]
</pre></div>
</div>
</div>
</div>
<p>Not bad. And for the rewards:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ground truth:</span><span class="se">\n</span><span class="si">{</span><span class="n">R</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;estimate:</span><span class="se">\n</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">R_estimate</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ground truth:
[[10.  0.  0.  0.  0.]
 [10.  0.  0.  0.  0.]
 [10.  0.  0.  0.  0.]
 [10.  0.  0.  0.  0.]]
estimate:
[[ 1.00000000e+001  0.00000000e+000  0.00000000e+000  0.00000000e+000
   0.00000000e+000]
 [ 1.00000000e+001  0.00000000e+000  0.00000000e+000 -4.56301668e+042
   0.00000000e+000]
 [ 1.00000000e+001  1.01499979e+189  0.00000000e+000  0.00000000e+000
  -1.26162158e+012]
 [ 1.00000000e+001  0.00000000e+000  0.00000000e+000  0.00000000e+000
   0.00000000e+000]]
</pre></div>
</div>
</div>
</div>
<p>In summary, learning in this context can simply be done by gathering lots of experiences, and estimating models for how the world behaves.</p>
</section>
<section id="model-free-reinforcement-learning">
<h2><span class="section-number">3.6.3. </span>Model-free Reinforcement Learning<a class="headerlink" href="#model-free-reinforcement-learning" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>All you need is Q, la la la la.</p>
</div></blockquote>
<p>A different, model-free approach is <strong>Q_learning</strong>. In the above we tried to <em>model</em> the world by trying estimate the (large) transition and reward tables. However, remember from the previous section that there is a much smaller table of Q-values <span class="math notranslate nohighlight">\(Q(x,a)\)</span> that also allow us to act optimally, because we have</p>
<div class="math notranslate nohighlight">
\[
\pi^*(x) = \arg \max_a Q^*(x,a)
\]</div>
<p>where the Q-values are defined as</p>
<div class="math notranslate nohighlight">
\[
Q^*(x,a) \doteq \bar{R}(x,a) + \gamma \sum_{x'} P(x'|x, a) V^*(x')
\]</div>
<p>This begs the question whether we can simply learn the Q-values instead, which might be more <em>sample-efficient</em>, i.e., we would get more accurate values with less training data, as we have less quantities to estimate.</p>
<p>To do this, remember that the Bellman equation can be written as</p>
<div class="math notranslate nohighlight">
\[
V^*(x) = \max_a Q^*(x,a)
\]</div>
<p>allowing us to rewrite the Q-values from above as</p>
<div class="math notranslate nohighlight">
\[
Q^*(x,a) = \sum_{x'} P(x'|x, a) \{ R(x,a,x') + \gamma \max_{a'} Q^*(x',a') \}
\]</div>
<p>This gives us a way to estimate the Q-values, as we can approximate the above using a Monte Carlo estimate, summing over our experiences:</p>
<div class="math notranslate nohighlight">
\[
Q^*(x,a) \approx \frac{1}{N(x,a)} \sum_{x,a,x'} R(x,a,x') + \gamma \max_{a'} Q^*(x',a')
\]</div>
<p>Unfortunately the estimate above <em>depends</em> on the optimal Q-values. Hence, the final Q-learning algorithm applies this estimate gradually, by “alpha-blending” between old and new estimates, which also averages over the reward:</p>
<div class="math notranslate nohighlight">
\[
\hat{Q}(x,a) \leftarrow (1-\alpha) \hat{Q}(x,a) + \alpha \{R(x,a,x') +  \gamma \max_{a'} \hat{Q}(x',a') \}
\]</div>
<p>In code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1"># learning rate</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.9</span> <span class="c1"># discount factor</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_prime</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="n">old_Q_estimate</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span><span class="n">a</span><span class="p">]</span>
    <span class="n">new_Q_estimate</span> <span class="o">=</span> <span class="n">r</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">x_prime</span><span class="p">])</span>
    <span class="n">Q</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">old_Q_estimate</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">new_Q_estimate</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[90.90912135 76.84642722 90.48612199 79.43818799]
 [83.85973946 62.96199842 67.92228065 62.85652194]
 [59.10843607 71.85219102 57.99375708 62.38891699]
 [61.5340413  67.07495871 89.91803703 72.67162993]
 [70.45828019 61.42005275 69.50891634 62.62789414]]
</pre></div>
</div>
</div>
</div>
<p>These values are not yet quite accurate, as you can ascertain yourself by changing the number of experiences above, but note that an optimal policy can be achieved before we even converge.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S35_vacuum_decision.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3.5. </span>Markov Decision Processes</p>
      </div>
    </a>
    <a class="right-next"
       href="S40_logistics_intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Warehouse Robots in 2D</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-to-get-data">3.6.1. Exploring to get Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-based-reinforcement-learning">3.6.2. Model-based Reinforcement Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-free-reinforcement-learning">3.6.3. Model-free Reinforcement Learning</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>