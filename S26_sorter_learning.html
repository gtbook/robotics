
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2.6. Learning &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S26_sorter_learning';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2.7. Chapter Summary" href="S27_sorter_summary.html" />
    <link rel="prev" title="2.5. Decision Theory" href="S25_sorter_decision_theory.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Introduction to Robotics and Perception - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">2.6. Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S27_sorter_summary.html">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a differential-drive robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Cameras for Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S26_sorter_learning.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-a-discrete-pmf">2.6.1. Estimating a Discrete PMF</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#smoothing">2.6.1.1. Smoothing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-a-sensor-from-data">2.6.2. Modeling a Sensor from Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-a-gaussian">2.6.3. Fitting a Gaussian</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison">2.6.3.1. Comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">2.6.4. Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="learning">
<span id="sec-sorter-learning"></span><h1><span class="section-number">2.6. </span>Learning<a class="headerlink" href="#learning" title="Link to this heading">#</a></h1>
<p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S26_sorter_learning.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<blockquote id="index-0">
<div><p>We can learn prior and sensor models from data we collect.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S26-Trash_sorting_robot_with_gripper-06.jpg"><img alt="Splash image with robot intently studying a pice of trash" class="align-center" src="_images/S26-Trash_sorting_robot_with_gripper-06.jpg" style="width: 40%;" /></a>
<p>At various times in this chapter we seemed to pull information out of thin air. But the various probabilistic models we used can be <em>learned</em> from data. In Section 2.1 we talked about priors over state. Here we will estimate prior from counts, and introduce the idea of adding “bogus counts” in the case that we do not have a lot of data. Also, in section 2.3 we discussed sensor models, and here we estimate those sensor models from counts recorded for each of the possible states. Finally, while <em>counting</em> works for discrete sensors, for continuous sensors we have to do a bit more work. We will end this section by showing how to fit simple Gaussian sensor models to data.</p>
<section id="estimating-a-discrete-pmf">
<h2><span class="section-number">2.6.1. </span>Estimating a Discrete PMF<a class="headerlink" href="#estimating-a-discrete-pmf" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Count the occurrences for each category.</p>
</div></blockquote>
<p>In section 2.1 we introduced the notion of a probability mass function (PMF) to characterize the <em>a priori</em> probability of being in a certain state. It turns out that the <em>normalized counts</em> we obtain when observing states over a long time period provide a good approximation for the PMF. The more samples that go in, the better the approximation.</p>
<p>As an example, let us assume that, at a <em>different</em> trash sorting cell, we observe for a while and note the category for each piece of trash, recording as we go. We might see something like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Using <code class="docutils literal notranslate"><span class="pre">numpy</span></code> we can get the counts using the <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.bincount.html"><code class="docutils literal notranslate"><span class="pre">bincount</span></code></a> function. We then plot the counts using <code class="docutils literal notranslate"><span class="pre">plotly.express</span></code>, in Figure <a class="reference internal" href="#fig:counts_of_categories"><span class="xref myst">1</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Counts of each category in the data.</span>
<span class="c1">#| label: fig:counts_of_categories</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">px</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">counts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/bbff5bf3c3c7e919a08220d049b92d05e47c741264de87b5ab2537d0febe0686.png" src="_images/bbff5bf3c3c7e919a08220d049b92d05e47c741264de87b5ab2537d0febe0686.png" />
</div>
</div>
<p>We can then estimate the probability of each category <span class="math notranslate nohighlight">\(c_k\)</span> simply by dividing the count <span class="math notranslate nohighlight">\(N_k\)</span> by the number of data points <span class="math notranslate nohighlight">\(N\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0c0733e1-6e28-42dc-95a5-23333c87c5c8">
<span class="eqno">(2.45)<a class="headerlink" href="#equation-0c0733e1-6e28-42dc-95a5-23333c87c5c8" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(x_k) \approx \frac{N_k}{N}
\end{equation}\]</div>
<p>In our example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimated_pmf</span> <span class="o">=</span> <span class="n">counts</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Counts: </span><span class="si">{</span><span class="n">counts</span><span class="si">}</span><span class="se">\n</span><span class="s2">Estimated PMF: </span><span class="si">{</span><span class="n">estimated_pmf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Counts: [ 3 11  7  1  3]
Estimated PMF: [0.12 0.44 0.28 0.04 0.12]
</pre></div>
</div>
</div>
</div>
<p>We can now easily turn this into a GTSAM discrete prior for pretty-printing:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">Category</span><span class="p">,</span> <span class="n">estimated_pmf</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(Category):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>Category</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>cardboard</th><td>0.12</td></tr>
    <tr><th>paper</th><td>0.44</td></tr>
    <tr><th>can</th><td>0.28</td></tr>
    <tr><th>scrap metal</th><td>0.04</td></tr>
    <tr><th>bottle</th><td>0.12</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p id="index-1">Note that the counts are the only quantities one needs to estimate a PMF: a statistician would say that the counts are a <strong>sufficient statistic</strong> for the purpose of estimating the probability distribution. In fact, GTSAM can just take the counts themselves, as it normalizes internally:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">Category</span><span class="p">,</span> <span class="s2">&quot;3/11/7/1/3&quot;</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(Category):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>Category</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>cardboard</th><td>0.12</td></tr>
    <tr><th>paper</th><td>0.44</td></tr>
    <tr><th>can</th><td>0.28</td></tr>
    <tr><th>scrap metal</th><td>0.04</td></tr>
    <tr><th>bottle</th><td>0.12</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<section id="smoothing">
<h3><span class="section-number">2.6.1.1. </span>Smoothing<a class="headerlink" href="#smoothing" title="Link to this heading">#</a></h3>
<blockquote>
<div><p>We make up fake data to deal with sparse data sets.</p>
</div></blockquote>
<p id="index-2">A trick that statisticians and machine learning practitioners sometimes employ is <strong>smoothing</strong>, which is especially important when you have very little data. Indeed, sometimes a category value will get zero counts, even though you <em>know</em> that occasionally that category will appear in practice. Smoothing is the process of letting the estimator know this by adding “pseudo-counts”. For example, a very common approach is to simply add 1 to every count:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">smoothed_counts</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">smoothed_pmf</span> <span class="o">=</span> <span class="n">smoothed_counts</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">smoothed_counts</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Comparing the two, we see that the smoothed PMF is more uniform, and accords more probability to “under-counted” categories than the raw counts:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some pandas magic to display a nice side-by-side table:</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;raw&quot;</span><span class="p">:</span> <span class="n">estimated_pmf</span><span class="p">,</span> <span class="s2">&quot;smoothed&quot;</span><span class="p">:</span> <span class="n">smoothed_pmf</span><span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="n">categories</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>raw</th>
      <th>smoothed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cardboard</th>
      <td>0.12</td>
      <td>0.133333</td>
    </tr>
    <tr>
      <th>paper</th>
      <td>0.44</td>
      <td>0.400000</td>
    </tr>
    <tr>
      <th>can</th>
      <td>0.28</td>
      <td>0.266667</td>
    </tr>
    <tr>
      <th>scrap metal</th>
      <td>0.04</td>
      <td>0.066667</td>
    </tr>
    <tr>
      <th>bottle</th>
      <td>0.12</td>
      <td>0.133333</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Comparison of the raw and smoothed PMF.</span>
<span class="c1">#| label: fig:smoothed_pmf</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="n">barmode</span><span class="o">=</span><span class="s2">&quot;group&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Smoothed PMF&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">smoothed_pmf</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;smoothed&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/89dabbbc5864bf6f129b5694a886128a84cfaa61e16dd0bd020b10954aa8b54f.png" src="_images/89dabbbc5864bf6f129b5694a886128a84cfaa61e16dd0bd020b10954aa8b54f.png" />
</div>
</div>
</section>
</section>
<section id="modeling-a-sensor-from-data">
<h2><span class="section-number">2.6.2. </span>Modeling a Sensor from Data<a class="headerlink" href="#modeling-a-sensor-from-data" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>When learning a conditional distribution, we need to separate out the counts based on the conditioning variable.</p>
</div></blockquote>
<p>A <code class="docutils literal notranslate"><span class="pre">DiscreteConditional</span></code> determines the counts, grouped by the conditioning variable. In our case, <code class="docutils literal notranslate"><span class="pre">Category</span></code> can take on 5 separate values, and hence we have five groups. For example, for a binary sensor:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Conductivity</span> <span class="o">=</span> <span class="n">variables</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Conductivity&quot;</span><span class="p">)</span>
<span class="n">P_Conductivty_Category</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span>
    <span class="n">Conductivity</span><span class="p">,</span> <span class="p">[</span><span class="n">Category</span><span class="p">],</span> <span class="s2">&quot;80/20 40/60 12/4 100/150 10/10&quot;</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">P_Conductivty_Category</span><span class="p">,</span> <span class="n">variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(Conductivity|Category):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>Category</i></th><th>false</th><th>true</th></tr>
  </thead>
  <tbody>
    <tr><th>cardboard</th><td>0.8</td><td>0.2</td></tr>
    <tr><th>paper</th><td>0.4</td><td>0.6</td></tr>
    <tr><th>can</th><td>0.75</td><td>0.25</td></tr>
    <tr><th>scrap metal</th><td>0.4</td><td>0.6</td></tr>
    <tr><th>bottle</th><td>0.5</td><td>0.5</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>And for a three-valued sensor:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ThreeValued</span> <span class="o">=</span> <span class="n">variables</span><span class="o">.</span><span class="n">discrete</span><span class="p">(</span><span class="s2">&quot;ThreeValued&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Value1&quot;</span><span class="p">,</span> <span class="s2">&quot;Value2&quot;</span><span class="p">,</span> <span class="s2">&quot;Value3&quot;</span><span class="p">])</span>
<span class="n">P_ThreeValued_Category</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">ThreeValued</span><span class="p">,</span> <span class="p">[</span><span class="n">Category</span><span class="p">],</span>
                                                   <span class="s2">&quot;10/70/20 20/20/60 2/10/4 100/100/50 5/5/10&quot;</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">P_ThreeValued_Category</span><span class="p">,</span> <span class="n">variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(ThreeValued|Category):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>Category</i></th><th>Value1</th><th>Value2</th><th>Value3</th></tr>
  </thead>
  <tbody>
    <tr><th>cardboard</th><td>0.1</td><td>0.7</td><td>0.2</td></tr>
    <tr><th>paper</th><td>0.2</td><td>0.2</td><td>0.6</td></tr>
    <tr><th>can</th><td>0.125</td><td>0.625</td><td>0.25</td></tr>
    <tr><th>scrap metal</th><td>0.4</td><td>0.4</td><td>0.2</td></tr>
    <tr><th>bottle</th><td>0.25</td><td>0.25</td><td>0.5</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Once again, note that the <em>rows</em> are normalized to be proper PMFs, given the conditioning variable. The columns are not, and instead form likelihoods over the category, when a particular value is observed for <code class="docutils literal notranslate"><span class="pre">ThreeValued</span></code>.</p>
<p>Again, we can add pseudo-counts to all counts if we have very little data, or to specific groups if you only have prior knowledge about a particular setting. If you really know nothing about the behavior of a sensor, adding a pseudo-count of 1 is a good thing to do in general: it prevents according zero probability to a rare event. The downside is that you will have a biased view of the CPT, but this disadvantage quickly goes away as you add more and more data.</p>
</section>
<section id="fitting-a-gaussian">
<span id="index-3"></span><h2><span class="section-number">2.6.3. </span>Fitting a Gaussian<a class="headerlink" href="#fitting-a-gaussian" title="Link to this heading">#</a></h2>
<p>Recall that a Gaussian distribution is completely specified by two parameters: the mean <span class="math notranslate nohighlight">\(\mu\)</span>
and the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<p>If we observe <em>continuous</em> data that we suspect is generated from a Gaussian density, then we can easily compute an estimate of the mean <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> by</p>
<div class="amsmath math notranslate nohighlight" id="equation-abdea430-cd12-4a53-a42f-1733593f951a">
<span class="eqno">(2.46)<a class="headerlink" href="#equation-abdea430-cd12-4a53-a42f-1733593f951a" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{\mu} = \frac{1}{N} \sum_i x_i.
\end{equation} \]</div>
<p>The estimate <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> is sometimes called the <strong>empirical mean</strong>.
The other parameter we need is the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> defined as the expectation of the squared
deviation from the mean:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4c117ae7-cc6b-4874-94f8-d92d65210a54">
<span class="eqno">(2.47)<a class="headerlink" href="#equation-4c117ae7-cc6b-4874-94f8-d92d65210a54" title="Permalink to this equation">#</a></span>\[\begin{equation}
E[(x-\mu)^2].
\end{equation}\]</div>
<p>Estimating the variance can be done after we obtain the empirical mean <span class="math notranslate nohighlight">\(\hat{\mu}\)</span>, by</p>
<div class="amsmath math notranslate nohighlight" id="equation-0af47b5f-e8cf-46c9-b36f-6d8ebb40da20">
<span class="eqno">(2.48)<a class="headerlink" href="#equation-0af47b5f-e8cf-46c9-b36f-6d8ebb40da20" title="Permalink to this equation">#</a></span>\[\begin{equation}
\widehat{\sigma^2} = \frac{1}{N-1} \sum_i (x_i-\hat{\mu})^2.
\end{equation} \]</div>
<p>The standard deviation, <span class="math notranslate nohighlight">\(\sigma\)</span>, is defined as the square root of the variance, and hence
an estimate of the standard deviation is given by:</p>
<div class="amsmath math notranslate nohighlight" id="equation-52e92487-cf55-4029-82e0-4b15e912f6b8">
<span class="eqno">(2.49)<a class="headerlink" href="#equation-52e92487-cf55-4029-82e0-4b15e912f6b8" title="Permalink to this equation">#</a></span>\[\begin{equation}
\widehat{\sigma} = \sqrt{\widehat{\sigma^2}}.
\end{equation}\]</div>
<p><em>Note</em>: Above we divide by <span class="math notranslate nohighlight">\(N-1\)</span> and not by <span class="math notranslate nohighlight">\(N\)</span>. Informally, the reason is that we already “used up” one data point by estimating the mean from our samples, and we correct for that to get an “unbiased” estimate for the variance.</p>
<p>Below is some python code to do just that, using the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> library. Let us first generate some “data” from a Gaussian with known mean and standard deviation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># grams, say...</span>
<span class="n">stddev</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># also in grams</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># number of samples</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">stddev</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When we plot a histogram, we can see the typical “bell curve” shape emerge (try increasing N), as shown in Figure <a class="reference internal" href="#fig:histogram-of-generated-data"><span class="xref myst">3</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Histogram of the generated data.</span>
<span class="c1">#| label: fig:histogram-of-generated-data</span>
<span class="n">nbins</span> <span class="o">=</span> <span class="n">N</span><span class="o">//</span><span class="mi">10</span>
<span class="n">px</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">nbins</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/bba6ba114052df3da7126addae9a5f5f7340bd881386705945fd49b87fe9e24a.png" src="_images/bba6ba114052df3da7126addae9a5f5f7340bd881386705945fd49b87fe9e24a.png" />
</div>
</div>
<p>The sample mean is easy enough to compute with <code class="docutils literal notranslate"><span class="pre">np.mean</span></code> :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">mu_hat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>200.05007265893386
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2338.0494810682603
</pre></div>
</div>
</div>
</div>
<p>Note that  with 200 samples, even though the histogram is quite “messy”, the sample mean <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> is close to the true mean <span class="math notranslate nohighlight">\(\mu=200\)</span>.</p>
<p>There is also a function <code class="docutils literal notranslate"><span class="pre">np.var</span></code> that calculates the sample variance, but we need to take care to provide the <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code> argument to get the unbiased estimate (do <code class="docutils literal notranslate"><span class="pre">help(np.var)</span></code> to find out more).</p>
<p>Here is the code to compute variance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">var_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">data</span><span class="o">-</span><span class="n">mu_hat</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">var_hat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2338.0494810682603
</pre></div>
</div>
</div>
</div>
<p>By taking the square root, we see that it matches our ground truth standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span> quite well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigma_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_hat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sigma_hat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>48.35338127854411
</pre></div>
</div>
</div>
</div>
<section id="comparison">
<h3><span class="section-number">2.6.3.1. </span>Comparison<a class="headerlink" href="#comparison" title="Link to this heading">#</a></h3>
<p>We can now plot our estimated Gaussian together with the data in Figure <a class="reference internal" href="#fig:histogram-and-gaussian"><span class="xref myst">4</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Comparison of the histogram and the Gaussian distribution.</span>
<span class="c1">#| label: fig:histogram-and-gaussian</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">nbins</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">350</span><span class="p">)</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">N</span><span class="o">*</span><span class="p">(</span><span class="mi">400</span><span class="o">/</span><span class="n">nbins</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">var_hat</span><span class="p">)</span>  <span class="c1"># expected height of histogram...</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">K</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X</span><span class="o">-</span><span class="n">mu_hat</span><span class="p">)</span><span class="o">/</span><span class="n">var_hat</span><span class="p">)))</span>
<span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/dabff35cb14bf611259fd179180ad4a9fb6500cc3beeca2818c8e470ea390941.png" src="_images/dabff35cb14bf611259fd179180ad4a9fb6500cc3beeca2818c8e470ea390941.png" />
</div>
</div>
</section>
</section>
<section id="summary">
<h2><span class="section-number">2.6.4. </span>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<p>We saw above that learning conditional probability tables amounts to counting the occurrence of certain events. In the case of sensor models, it is really about the co-occurrence of an event: how often do we see a particular sensor reading in a particular state? Finally if the sensor is continuous, we can posit a parametric model. In this case we use the Gaussian, and use techniques from statistics to estimate its parameters. For a Gaussian we only need to estimate its mean <span class="math notranslate nohighlight">\(\mu\)</span> and its a variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, and we used techniques from statistics to estimate these.</p>
<p>In the case of discrete sensors we also looked at a very simple form of smoothing to cope with the absence of certain counts, which is common for rare events. In fact, this amounts to introducing what is called a <em>hyperprior</em> on the parameters to be estimated - in this case the numbers of a conditional probability table. Hyperpriors can also be used for estimating parameters of a Gaussian, but that is beyond the scope of this section.</p>
<p>You might think it is a bit of a stretch to call these procedures “learning”. And indeed, they are simple parameter estimation problems as encountered in a statistics 101 class. However, although we will look at much more sophisticated learning approaches, even these simple algorithms <em>learn</em> about the world from data. Based on the sensor models, a robot will change how it acts in the world. Together with a value system, supplied in the form of a cost matrix by its user, the robot will make more optimal decisions by observing how the world behaves.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S25_sorter_decision_theory.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2.5. </span>Decision Theory</p>
      </div>
    </a>
    <a class="right-next"
       href="S27_sorter_summary.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2.7. </span>Chapter Summary</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-a-discrete-pmf">2.6.1. Estimating a Discrete PMF</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#smoothing">2.6.1.1. Smoothing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-a-sensor-from-data">2.6.2. Modeling a Sensor from Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-a-gaussian">2.6.3. Fitting a Gaussian</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison">2.6.3.1. Comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">2.6.4. Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>