
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1.2. Reasoning &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-312077-7"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-312077-7');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-312077-7');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S12_reasoning';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="1.3. The Mathematics of Robotics" href="S13_math.html" />
    <link rel="prev" title="1.1. Models" href="S11_models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Introduction to Robotics and Perception - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction to Robotics and Perception
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayes Nets</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Reinforcement Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gtbook/robotics" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS12_reasoning.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S12_reasoning.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Reasoning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perception">1.2.1. Perception</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#planning">1.2.2. Planning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#task-planning">1.2.2.1. Task Planning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#path-planning">1.2.2.2. Path Planning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trajectory-planning">1.2.2.3. Trajectory Planning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning">1.2.3. Learning</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="reasoning">
<h1><span class="section-number">1.2. </span>Reasoning<a class="headerlink" href="#reasoning" title="Link to this heading">#</a></h1>
<blockquote>
<div><p>Reasoning provides the <em>intelligence</em> of so-called intelligent robotic systems.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S12-Robot_menagerie-03.jpg"><img alt="Splash image with thinking robot" class="align-center" src="_images/S12-Robot_menagerie-03.jpg" style="width: 40%;" /></a>
<p>Reasoning involves manipulating data and models, ultimately reaching conclusions. This can take the form of perception, in which sensor data and models are used to make inferences about the state of the world or the robot; planning, in which action models and the perceived state are used to infer a plan that can transform the state of the world or the robot from its current state to a desired state; and, learning, in which data and models are used to improve the robot’s performance over time. In this book, reasoning ranges from very simple mathematical manipulations of probabilities to learning millions of parameters for a deep neural network.</p>
<section id="perception">
<h2><span class="section-number">1.2.1. </span>Perception<a class="headerlink" href="#perception" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Perception uses sensor data to drive inference about the world.</p>
</div></blockquote>
<p>Sensors are characterized by observation models that map the state of the world to
sensor values.  These models are sometimes called <em>forward models</em>.
For a given state of the world, one can use geometry and physics to uniquely determine (modulo uncertainty) the sensor output.  Perception is concerned with the <em>inverse</em> problem:
Given a set of sensor measurements, infer something about the state of the world.
Inverse problems are notoriously difficult, in part because they are often ill-defined.
For example, in the noiseless case, if a range sensor is 10 meters from wall,
we can easily predict that the sensor will return <span class="math notranslate nohighlight">\(h(x) = z = 10\)</span>.
The inverse problem is to determine something about the state of the world,
given that the sensor measurement is <span class="math notranslate nohighlight">\(z = 10\)</span>.  This is an ill-defined problem, since there are many possible world states that could lead to a measurement of <span class="math notranslate nohighlight">\(z=10\)</span>.
The robot might be <span class="math notranslate nohighlight">\(10\)</span> meters from a wall, or perhaps another robot has crossed <span class="math notranslate nohighlight">\(10\)</span> meters in front of the sensor, or perhaps an open door <span class="math notranslate nohighlight">\(10\)</span> meters in front of the robot has just been closed.
Perception is concerned with these inverse problems.</p>
<p>In the presence of uncertainty, things become even more difficult. It is easy to illustrate the difficulty with a simple medical example. If you have the flu, there is a very high probability that you will have a fever.
But if you have a fever, what is the probability that you have the flu? The latter question is complicated by the fact that there are many possible causes for a fever. Medical doctors use the presence of fever, along with other evidence (sore throat? cough? burning eyes?), combined with contextual knowledge (is it flu season? has there been an outbreak of flu in the past days?) to make a diagnosis. In other words, they perform inference by fusing multiple sources of evidence, and considering the context for the evidence.</p>
<p>In this book we consider two main approaches to perception: approaches based on probability theory, and approaches that apply machine learning tools such as deep neural networks. In each case, tools from optimization are often used.</p>
<p>The first part of the book focuses mainly on probabilistic approaches. For example, the trash sorting robot in Chapter 2 uses a maximum likelihood approach to recognize categories of recycling material. This approach essentially optimizes the value of a conditional probability function that models sensors. In Chapter 4, probabilistic models of actions and sensors are combined to estimate a probability distribution for the robot’s current state. In Chapter 6, optimization over probabilistic models is used to simultaneously construct a map and localize the robot within the map (the SLAM problem).  In each of these cases, the reasoning and models are explicit.</p>
<p>We also describe how neural networks can be used to solve perception problems. Neural networks do not use explicit models. Instead, their reasoning process is essentially encoded as a set of weights on the connections in the network. Choosing the values for these weights is typically a large-scale optimization problem that is driven by available data.
In a sense, neural networks learn a solution to inverse probles. In Chapter 5, we introduce neural networks for computer vision problems, and in Chapter 7 we extend these ideas to neural radiance fields (NeRF).</p>
</section>
<section id="planning">
<h2><span class="section-number">1.2.2. </span>Planning<a class="headerlink" href="#planning" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Planning is the process of determining which actions to execute in order to effect desired changes in the world.</p>
</div></blockquote>
<p>Planning can mean very different things, depending on the complexity of the task, the time scale for actions,
the uncertainty involved, and the complexity of the robot.
For simple tasks that can be characterized at a fairly high level of abstraction, symbolic descriptions can be used, and planning can often be reduced to either a decision-theoretic problem, or to a graph search problem. This is the case for both the trash sorting robot and the vacuum cleaning robot.</p>
<p>For the trash sorting robot, planning reduces to making individual decisions about which bin is appropriate for a piece of trash. For the vacuum cleaning robot, planning takes the form of constructing an optimal policy: Given a specific goal location, determine the optimal action to apply for each possible robot state, such that the robot makes its way to the goal.</p>
<p>As we move down the abstraction hierarchy, from high-level task planning to low-level control, planning requires increasing computation, and begins to take into consideration both the geometry and the physics of the problem at hand. For example, when the dynamics of the task are important (as is the case for drones in Chapter 7), planning must consider the dynamic equations of the system.
If uncertainty is involved, it is impossible to provide deterministic performance guarantees,
and planning requires dealing with probabilistic outcomes.
We will consider all of these cases in this book.</p>
<section id="task-planning">
<h3><span class="section-number">1.2.2.1. </span>Task Planning<a class="headerlink" href="#task-planning" title="Link to this heading">#</a></h3>
<p>Task planning treats problems at a fairly high level of abstraction, ignoring details such
as the geometry of the environment, the specific path traversed by the robot,
and any consideration of dynamics (e.g., for drones that depend on aerodynamic properties to stay aloft).
Actions in a task plan are typically described in high-level, symbolic terms,
such as <em>move the piece of trash to the paper bin</em> for our trash sorting robot,
or <em>go to the kitchen</em> for our vacuum cleaning robot.
A task planner makes its decisions by considering the effects of actions at this high level.
A task planner might consider costs associated to placing a piece of trash in the wrong bin,
or probabilities associated to arriving to the correct room,
but it will not consider details such as how to grasp the item of trash or what should be the motor torques on the wheels of a robot to move it from the living room to the kitchen.</p>
<p>Task planning is useful when either (a) the robot has a set of basic skills, sometimes called <em>primitives</em> or <em>motion primitives</em> that can be executed reliably, and therefore need not be planned, or (b) when the task planner is integrated into an overall system that incorporates motion planning (this integrated problem is sometimes called <em>TAMP</em>, for Task And Motion Planning).  The trash sorting robot and the vacuum cleaning robot are examples of the former.</p>
</section>
<section id="path-planning">
<h3><span class="section-number">1.2.2.2. </span>Path Planning<a class="headerlink" href="#path-planning" title="Link to this heading">#</a></h3>
<p>Path planning deals with the problem of moving the robot from one position to another.  Avoiding collisions with obstacles in the environment (including humans and other robots) is generally a central concern for path planners.</p>
<p>An easy way to address this problem is to discretize the world into a grid and then label grid cells as either being free or as containing an obstacle. The path planning problem is then to find a sequence of free grid cells such that the initial robot position is contained in the starting cell and the goal position is contained in the final cell. The disadvantage to this approach is that the representation of free space is conservative.  If a cell is partially blocked by an obstacle, then the entire cell will be treated as an obstacle and therefore be unavailable to the robot; there may be cases for which a collision-free path exists in the world, but not in the grid. In such cases, the robot will be unable to find a free path, even though it exists.</p>
<p>For many tasks, grid-based approximations are not sufficiently accurate. Furthermore, the size of the required grid grows exponentially with the number of degrees of freedom for the system.
A robot that moves in the plane might use a <span class="math notranslate nohighlight">\(100 \times 100\)</span> grid to represent the position of the robot. If we decide to consider also the orientation of the robot, also using <span class="math notranslate nohighlight">\(100\)</span> discretization levels, the grid grows to <span class="math notranslate nohighlight">\(100 \times 100 \times 100\)</span>.  If we consider a drone and represent its 3D position and 3D orientation, the grid grows to <span class="math notranslate nohighlight">\(100^6\)</span>, a very large data structure, for a fairly coarse quantization of the drone’s configuration space.</p>
<p>For the problem of planning a collision-free path for a robot that can move in arbitrary directions, there exist exact algorithms that are guaranteed to find a solution when one exists, or to terminate in finite time when no solution exists (these algorithms are called <em>complete</em> algorithms). Unfortunately, even the fastest of these algorithms has computational complexity that increases exponentially with the number of degrees of freedom of the robot (in addition to being extremely difficult to implement). For this reason, much research in path planning has focused on computationally efficient algorithms that perform well in practice, even though deterministic performance guarantees are not available.  Randomized, sampling-based algorithms are the most popular of these, and we will see some of these in Chapter 5, to plan paths for our DDR.</p>
</section>
<section id="trajectory-planning">
<h3><span class="section-number">1.2.2.3. </span>Trajectory Planning<a class="headerlink" href="#trajectory-planning" title="Link to this heading">#</a></h3>
<p>While path planning considers the “shape” of the path from start to goal (e.g., consider the smoke trail that would be left by a sky-writing drone), trajectory planning also considers the time parameterization of that path (how fast the drone traverses the path).</p>
<p>In this book, dynamic effects become important in Chapter 7, where we consider a drone robot. Aerodynamics can be computationally difficult; to achieve ultimate accuracy requires solving systems of partial differential equations. Therefore, we will use numerical approximations for the aerodynamic effects and solve a trajectory optimization problem that considers performance criteria that include obstacle avoidance, start and goal states (i.e., boundary value specification), and smoothness (e.g., bounding velocity and acceleration). For completeness, we also introduce a control scheme that can execute the final trajectory on an actual drone.</p>
</section>
</section>
<section id="learning">
<h2><span class="section-number">1.2.3. </span>Learning<a class="headerlink" href="#learning" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>By learning from data we can make robots smarter.</p>
</div></blockquote>
<p>For many applications, it is impossible to program a robot for all situations that might occur.
In some cases, this is due to the fact that arbitrarily many possible situations could occur.
In other applications, things may simply be too complex to model exactly.
In still other cases, it is simply not possible to know a priori all of the conditions that might confront the robot.</p>
<p>Machine learning approaches can be used in these situations to adapt to unknown or changing circumstances,
or to improve the robot’s performance over time.
In this book, we will consider three main types of machine learning:
simple statistical analysis, reinforcement learning, and neural network-based learning.</p>
<p>For systems that have a few unknown parameters, it is often sufficient to use statistical methods
to estimate the values of those parameters.
For example, if the trash sorting robot does not know the prior probabilities for the different
categories of trash that arrive to the sorter, these probabilities can be estimated by observing
the system over time.
If a robot manipulates an unknown object, it can estimate the mass of that object by using
measurements from it’s sensors.
If sensors are noisy, but the parameters of their associated noise models are not known,
we can estimate these through calibration, which is also a kind of learning.</p>
<p>For systems that will operate over long periods of time, it is often possible to improve performance using experience.
<em>Reinforcement learning</em> is a popular approach. Simply stated, behaviors that lead to successful outcomes are rewarded,
reinforcing successful behavior. In Chapter 3, we introduce reinforcement learning for the vacuum cleaning robot,
including the popular variation known as <em>Q-learning</em>.
Q-learning does not explicitly learn which actions are most effective, but instead learns a function that models
the long-term reward for applying actions in specific states.</p>
<p>For problems that involve large data sets, neural network-based methods, particularly <em>deep learning</em> can often provide effective solutions. Neural networks can be viewed as function approximators. For the computer vision problem of object recognition, the approximated function takes an image as input and outputs a classification of the object. Many other vision tasks, such as image segmentation, scene depth, and scene motion can be solved using modern neural networks.</p>
<p>Neural networks are constructed from simple processing nodes that are interconnected by weighted edges. The weights effectively determine the computation done by the network, and therefore the key problem in neural networks is that of learning the weights.
We introduce neural networks, and then deep neural networks, in Chapter 5, for problems in image processing and computer vision.
Then, in Chapter 6, we combine Deep Learning with Reinforcement Learning, resulting in an approach called <em>Deep Reinforcement Learning,</em>
or <em>Deep RL.</em> Finally, in Chapter 7, we use the same differentiable optimization methods for modeling the environment, when we talk about Neural Radiance Fields (NeRFs) and their use in autonomous flight.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S11_models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1.1. </span>Models</p>
      </div>
    </a>
    <a class="right-next"
       href="S13_math.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1.3. </span>The Mathematics of Robotics</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perception">1.2.1. Perception</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#planning">1.2.2. Planning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#task-planning">1.2.2.1. Task Planning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#path-planning">1.2.2.2. Path Planning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trajectory-planning">1.2.2.3. Trajectory Planning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning">1.2.3. Learning</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>