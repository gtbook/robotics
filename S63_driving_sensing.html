
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>6.3. Sensing for Autonomous Vehicles &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S63_driving_sensing';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6.4. SLAM" href="S64_driving_perception.html" />
    <link rel="prev" title="6.2. Kinematics for Driving" href="S62_driving_actions.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Introduction to Robotics and Perception - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S27_sorter_summary.html">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a differential-drive robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Cameras for Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S63_driving_sensing.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Sensing for Autonomous Vehicles</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lidar">6.3.1. LIDAR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-intersection">6.3.2. Ray Intersection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulating-a-2d-lidar">6.3.3. Simulating a 2D LIDAR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#geometry-of-a-moving-lidar">6.3.4. Geometry of a Moving LIDAR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-lidar-scans">6.3.5. Real LIDAR Scans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-3d-maps">6.3.6. Creating 3D Maps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">6.3.7. GTSAM 101</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-and-3d-points">6.3.7.1. 2D and 3D Points</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-and-3d-rotations">6.3.7.2. 2D and 3D Rotations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reading-and-visualizing-lidar-clouds">6.3.7.3. Reading and Visualizing LIDAR clouds</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sensing-for-autonomous-vehicles">
<h1><span class="section-number">6.3. </span>Sensing for Autonomous Vehicles<a class="headerlink" href="#sensing-for-autonomous-vehicles" title="Link to this heading">#</a></h1>
<p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S63_driving_sensing.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<blockquote id="index-0">
<div><p>LIDAR, a sensor found in most autonomous cars, can be used to construct a 3D representation of the robot’s environment in real time.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S63-Autonomous_Vehicle_with_LIDAR_and_cameras-07.jpg"><img alt="Splash image with steampunk autonomous car" class="align-center" src="_images/S63-Autonomous_Vehicle_with_LIDAR_and_cameras-07.jpg" style="width: 40%;" />
</a>
<section id="lidar">
<h2><span class="section-number">6.3.1. </span>LIDAR<a class="headerlink" href="#lidar" title="Link to this heading">#</a></h2>
<p id="index-2"><span id="index-1"></span>LIDAR (LIght raDAR) is a technology that measures distance to an object by using laser light and the <strong>Time of Flight</strong> or <strong>ToF</strong> principle. There are several variants in use, and the simplest to explain is the <strong>direct ToF</strong> sensor, which sends out a short pulse and measures the elapsed time <span class="math notranslate nohighlight">\(\Delta t\)</span> for the light to bounce off an object and return to a detector collocated with the laser pulse emitter. If the object is situated at a distance <span class="math notranslate nohighlight">\(d\)</span> from the emitter-detector pair, we have</p>
<div class="amsmath math notranslate nohighlight" id="equation-c2278ff8-1fdb-4765-8c7e-a491a12f565a">
<span class="eqno">(6.26)<a class="headerlink" href="#equation-c2278ff8-1fdb-4765-8c7e-a491a12f565a" title="Permalink to this equation">#</a></span>\[\begin{equation}
\Delta t = \frac{2 d}{c} 
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(c\approx300,000km/s\)</span> is the speed of light. For example, for an object at 15m, we have</p>
<div class="amsmath math notranslate nohighlight" id="equation-b4a11ccd-f10f-4ee5-bb8f-94c5b2a22efb">
<span class="eqno">(6.27)<a class="headerlink" href="#equation-b4a11ccd-f10f-4ee5-bb8f-94c5b2a22efb" title="Permalink to this equation">#</a></span>\[\begin{equation}
\Delta t \approx \frac{2 \times 0.015}{300,000} = 0.1\mu s
\end{equation}\]</div>
<p>Assuming we can measure <span class="math notranslate nohighlight">\(\Delta t\)</span> accurately, we can then easily compute the distance:</p>
<div class="amsmath math notranslate nohighlight" id="equation-07d42c8f-750f-4265-bbea-baad1166bf0f">
<span class="eqno">(6.28)<a class="headerlink" href="#equation-07d42c8f-750f-4265-bbea-baad1166bf0f" title="Permalink to this equation">#</a></span>\[\begin{equation}
d= c\frac{\Delta t}{2}
\end{equation}\]</div>
<p>In a <em>scanning LIDAR</em>, there is typically one detector, whereas in a <em>flash LIDAR</em> a single pulse is emitted in a wide field of view, and an <em>array</em> of detectors, akin to a CCD sensor, is used to detect the returning light pulses in multiple directions at once.</p>
<p>In practice, <em>indirect</em> time of flight sensors are more prevalent in robotics and autonomous driving applications than direct ToF sensors. There are multiple reasons for this: measuring elapsed times at the nano-second scale is difficult and expensive, and the amount of light energy that needs to be emitted for direct ToF can also be a problem from an eye-safety perspective.
<strong>Indirect ToF</strong> is an attractive alternative, where the light is emitted as a waveform, e.g., a sine wave, and the returned light is correlated with the amplitude of the emitted light to calculate a phase shift. The elapsed time <span class="math notranslate nohighlight">\(\Delta t\)</span> and distance <span class="math notranslate nohighlight">\(d\)</span> can then be calculated from the phase shift.</p>
<p id="index-3">Two common scanning LIDAR technologies are in use for robotics: <strong>2D LIDAR</strong>, which consists of a single laser beam that is rotated around a fixed axis, and <strong>3D LIDAR</strong>, which has multiple laser/detector pairs rotated at different inclinations. 2D LIDAR is also often deployed on aircraft to create highly detailed digital elevation maps, where the third dimension is provided by the aircraft’s forward motion. LIDAR altimeters are even deployed from satellites in orbit around Earth or <a class="reference external" href="https://pgda.gsfc.nasa.gov/products/62">other planets</a>.</p>
</section>
<section id="ray-intersection">
<span id="index-4"></span><h2><span class="section-number">6.3.2. </span>Ray Intersection<a class="headerlink" href="#ray-intersection" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Intersecting rays is as easy as computing a dot product.</p>
</div></blockquote>
<p>To perform inference about the environment using LIDAR, we have to model how LIDAR beams interact with the environment, which in the case of polygonal objects comes down to line-line or line-plane intersections.</p>
<p>We examine the 2D line-line intersection case first. Assume we have a line in 2D with equation <span class="math notranslate nohighlight">\(\hat{n} \cdot p = d\)</span>, where <span class="math notranslate nohighlight">\(\hat{n}\)</span> is a normal vector and <span class="math notranslate nohighlight">\(d&gt;0\)</span> is the distance of the line to the origin. The hat notation signifies that the normal vector <span class="math notranslate nohighlight">\(\hat{n}\)</span> is normalized to length 1. Then if we have a ray of points <span class="math notranslate nohighlight">\(p = \hat{r} s\)</span> where <span class="math notranslate nohighlight">\(\hat{r}\)</span> is the <strong>ray direction</strong> and <span class="math notranslate nohighlight">\(s&gt;0\)</span> is a scalar, we can find the intersection by plugging the ray equation into the line equation</p>
<div class="amsmath math notranslate nohighlight" id="equation-cda6abae-2186-4246-8591-0d51e0ab79b0">
<span class="eqno">(6.29)<a class="headerlink" href="#equation-cda6abae-2186-4246-8591-0d51e0ab79b0" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{n} \cdot (\hat{r} s) = d,
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(a \cdot b \doteq a^T b = b^T a\)</span> is the standard vector dot product. We find the range <span class="math notranslate nohighlight">\(s\)</span> to the object as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-882536d7-7f08-4170-a626-1710ea4ef9fe">
<span class="eqno">(6.30)<a class="headerlink" href="#equation-882536d7-7f08-4170-a626-1710ea4ef9fe" title="Permalink to this equation">#</a></span>\[\begin{equation}
s = \frac{d}{\hat{n} \cdot \hat{r}}.
\end{equation}\]</div>
<p>We can ensure that <span class="math notranslate nohighlight">\(s&gt;0\)</span> and avoid a division by zero by checking the dot product before doing the division:</p>
<div class="amsmath math notranslate nohighlight" id="equation-ffaccf81-17df-4e9e-9242-7d4bc79c5947">
<span class="eqno">(6.31)<a class="headerlink" href="#equation-ffaccf81-17df-4e9e-9242-7d4bc79c5947" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{n} \cdot \hat{r} &gt; 0
\end{equation}\]</div>
<p>The following code implements this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">intersect</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">ray</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Intersect line/plane (n,d) with ray given by direction r.&quot;&quot;&quot;</span>
    <span class="n">cos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">ray</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span> <span class="o">/</span> <span class="n">cos</span> <span class="k">if</span> <span class="n">cos</span><span class="o">&gt;</span><span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">intersect</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">d</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ray</span><span class="o">=</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span> <span class="o">==</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
</div>
<p>
The story above generalizes <em>completely</em> to 3D, where with <span class="math notranslate nohighlight">\(\hat{n}\in\mathbb{R}^3\)</span> and <span class="math notranslate nohighlight">\(p\in\mathbb{R}^3\)</span>.
In this case, the equation <span class="math notranslate nohighlight">\(\hat{n} \cdot p = d\)</span> defines a <em>plane</em> in 3D:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">intersect</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point3</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">d</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ray</span><span class="o">=</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point3</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span> <span class="o">==</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="simulating-a-2d-lidar">
<h2><span class="section-number">6.3.3. </span>Simulating a 2D LIDAR<a class="headerlink" href="#simulating-a-2d-lidar" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Computing line intersections is the main computation when simulating 2D LIDAR.</p>
</div></blockquote>
<p>We now put the above to work to simulate a 2D LIDAR sensor situated at the origin. The <em>SICK Tim1xx</em> is a relatively low-cost 2D LIDAR sensor, which has a field of view of 200 degrees and a resolution of one beam per degree. Hence, we expect to simulate 200 measurements.</p>
<p>In our simple simulation code below, we create an environment from infinite lines. A more powerful simulator would allow for line <em>segments</em>, but infinite lines are enough to illustrate the principle. We create a corridor-like environment with three sides:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">north</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="mf">2.5</span>
<span class="n">east</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="mi">8</span>
<span class="n">south</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mf">2.5</span>
</pre></div>
</div>
</div>
</div>
<p>
Then, in Figure <a class="reference internal" href="#fig:lidar_rays_200"><span class="xref myst">1</span></a> we create 200 unit vectors that will correspond to 200 simulated rays. We create them at uniformly spaces angles ranging from -100 degrees to 100 degrees, with 0 facing due East in the Figure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: 200 unit vectors corresponding to LIDAR rays at different angles.</span>
<span class="c1">#| label: fig:lidar_rays_200</span>
<span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">rays</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Rot2</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">radians</span><span class="p">(</span><span class="n">angle</span><span class="p">))</span><span class="o">.</span><span class="n">matrix</span><span class="p">()[</span><span class="mi">0</span><span class="p">,:]</span> <span class="k">for</span> <span class="n">angle</span> <span class="ow">in</span> <span class="n">angles</span><span class="p">])</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">rays</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">rays</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_yaxes</span><span class="p">(</span><span class="n">scaleanchor</span> <span class="o">=</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">scaleratio</span> <span class="o">=</span> <span class="mi">1</span><span class="p">);</span> <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/062a1df7e0598f61c9905e74ce8ae0e40ce31c5adfd77a0a7397b1c0cb51af2a.png" src="_images/062a1df7e0598f61c9905e74ce8ae0e40ce31c5adfd77a0a7397b1c0cb51af2a.png" />
</div>
</div>
<p>Finally, we compute the intersection with the simulated corridor-like environment in Figure <a class="reference internal" href="#fig:lidar_scan_200"><span class="xref myst">2</span></a>, using the <code class="docutils literal notranslate"><span class="pre">intersect</span></code> function we defined earlier. Note the “environment” is just a a list of lines represented as <span class="math notranslate nohighlight">\((\hat n,d)\)</span> pairs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A simulated scan by intersecting 200 rays with the environment.</span>
<span class="c1">#| label: fig:lidar_scan_200</span>
<span class="n">scan</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ray</span> <span class="ow">in</span> <span class="n">rays</span><span class="p">:</span>
    <span class="n">ranges</span> <span class="o">=</span> <span class="p">[</span><span class="n">intersect</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">ray</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="p">[</span><span class="n">north</span><span class="p">,</span> <span class="n">east</span><span class="p">,</span> <span class="n">south</span><span class="p">]]</span>
    <span class="n">_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmin</span><span class="p">(</span><span class="n">ranges</span><span class="p">)</span>
    <span class="n">intersection</span> <span class="o">=</span> <span class="n">_range</span> <span class="o">*</span> <span class="n">ray</span>
    <span class="n">scan</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">intersection</span><span class="p">)</span>
<span class="n">scan_x</span><span class="p">,</span> <span class="n">scan_y</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">scan</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">scan_x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">scan_y</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_yaxes</span><span class="p">(</span><span class="n">scaleanchor</span> <span class="o">=</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">scaleratio</span> <span class="o">=</span> <span class="mi">1</span><span class="p">);</span> <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5c488100b675554b413aab2fa8e71eb890b76fcc00124d5a76d8e76517ea7e23.png" src="_images/5c488100b675554b413aab2fa8e71eb890b76fcc00124d5a76d8e76517ea7e23.png" />
</div>
</div>
<p>As you can see, the resulting scan of this corridor-like environment does not produce a uniform sampling on the walls. Because the rays are distributed uniformly in <em>angle</em> space, they graze the walls at increasingly shallow angles, and the distance between successive intersection points increases. Of course, this depends on the angle that the wall makes with the rays: the end of the corridor is far away and hence is sampled fairly uniformly. This is a typical pattern when working with LIDAR scanners.</p>
</section>
<section id="geometry-of-a-moving-lidar">
<h2><span class="section-number">6.3.4. </span>Geometry of a Moving LIDAR<a class="headerlink" href="#geometry-of-a-moving-lidar" title="Link to this heading">#</a></h2>
<p>Above we assumed that the ray is situated at the <em>world</em> origin, but we can also generalize to the case where the rays are defined in a <em>body coordinate frame</em> <span class="math notranslate nohighlight">\((R^w_b,t^w_b)\)</span>.
In this case, it is convenient to transform the plane to the body frame. We can do this by expressing a point <span class="math notranslate nohighlight">\(p^w\)</span> in world coordinates as a function of a point in body coordinates, <span class="math notranslate nohighlight">\(p^w = R^w_b p^b + t^w_b\)</span>, and plugging that into the plane equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-44f09108-4090-49f9-aed2-de8708c1d92a">
<span class="eqno">(6.32)<a class="headerlink" href="#equation-44f09108-4090-49f9-aed2-de8708c1d92a" title="Permalink to this equation">#</a></span>\[\begin{equation}
\begin{aligned}
\hat{n}^w \cdot p^w &amp;= d^w \\
\hat{n}^w \cdot \{ R^w_b p^b + t^w_b \} &amp;= d^w \\
\hat{n}^w \cdot R^w_b p^b + \hat{n}^w \cdot t^w_b &amp;= d^w \\
(R^w_b)^T \hat{n}^w \cdot p^b &amp;= d^w - \hat{n}^w \cdot t^w_b.
\end{aligned}
\end{equation}\]</div>
<p>where in the last line we made use of <span class="math notranslate nohighlight">\(a \cdot R b = R^T a \cdot b\)</span>.
Hence, we obtain a new plane equation <em>in the body frame</em> as</p>
<div class="amsmath math notranslate nohighlight" id="equation-14d3515a-6ec4-42d0-a009-13513bc809f6">
<span class="eqno">(6.33)<a class="headerlink" href="#equation-14d3515a-6ec4-42d0-a009-13513bc809f6" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{n}^b \cdot p^b = d^b
\end{equation}\]</div>
<p>with transformed plane parameters <span class="math notranslate nohighlight">\(\hat{n}^b \doteq (R^w_b)^T \hat{n}^w\)</span> and <span class="math notranslate nohighlight">\(d^b \doteq d^w - \hat{n}^w \cdot t^w_b\)</span>.</p>
<p>We can use a <code class="docutils literal notranslate"><span class="pre">Pose2</span></code> or <code class="docutils literal notranslate"><span class="pre">Pose3</span></code> object to specify the body frame, respectively in 2D or 3D, and then use it to transform plane coordinates:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">transform_to</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">wTb</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transform line/plane (n,d) to body coordinate frame&quot;&quot;&quot;</span>
    <span class="n">wRb</span> <span class="o">=</span> <span class="n">wTb</span><span class="o">.</span><span class="n">rotation</span><span class="p">()</span>
    <span class="n">wtb</span> <span class="o">=</span> <span class="n">wTb</span><span class="o">.</span><span class="n">translation</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">wRb</span><span class="o">.</span><span class="n">matrix</span><span class="p">()</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">wtb</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>
We can do this for lines in 2D</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wTb</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Pose2</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Rot2</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">radians</span><span class="p">(</span><span class="mi">20</span><span class="p">)),</span> <span class="n">t</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">transform_to</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="mi">5</span><span class="p">,</span> <span class="n">wTb</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([ 0.93969262, -0.34202014]), 3.0)
</pre></div>
</div>
</div>
</div>
<p>
and for planes in 3D:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wTb3</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Pose3</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Rot3</span><span class="o">.</span><span class="n">Yaw</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">radians</span><span class="p">(</span><span class="mi">45</span><span class="p">)),</span> <span class="n">t</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">transform_to</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point3</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="mi">5</span><span class="p">,</span> <span class="n">wTb3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([ 0.70710678, -0.70710678,  0.        ]), 4.0)
</pre></div>
</div>
</div>
</div>
<p>With this new functionality we can transform the world model and predict what the scan will look like, in body coordinates, as shown in Figure <a class="reference internal" href="#fig:lidar_scan_200_2"><span class="xref myst">3</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Simulated scan from a different location in the same environment.</span>
<span class="c1">#| label: fig:lidar_scan_200_2</span>
<span class="n">scan2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">transformed</span> <span class="o">=</span> <span class="p">[</span><span class="n">transform_to</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">wTb</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="p">[</span><span class="n">north</span><span class="p">,</span> <span class="n">east</span><span class="p">,</span> <span class="n">south</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">ray</span> <span class="ow">in</span> <span class="n">rays</span><span class="p">:</span>
    <span class="n">ranges</span> <span class="o">=</span> <span class="p">[</span><span class="n">intersect</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">ray</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">transformed</span><span class="p">]</span>
    <span class="n">_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmin</span><span class="p">(</span><span class="n">ranges</span><span class="p">)</span>
    <span class="n">intersection</span> <span class="o">=</span> <span class="n">_range</span> <span class="o">*</span> <span class="n">ray</span>
    <span class="n">scan2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">intersection</span><span class="p">)</span>
<span class="n">scan2_x</span><span class="p">,</span> <span class="n">scan2_y</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">scan2</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">scan2_x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">scan2_y</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_yaxes</span><span class="p">(</span><span class="n">scaleanchor</span> <span class="o">=</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">scaleratio</span> <span class="o">=</span> <span class="mi">1</span><span class="p">);</span> <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/83c0e4ac3d10e3e09048a8d0d08c486b23b93624b5282b2ceaa487ce291127b2.png" src="_images/83c0e4ac3d10e3e09048a8d0d08c486b23b93624b5282b2ceaa487ce291127b2.png" />
</div>
</div>
<p>As you can see above, when the robot rotates 20 degrees <em>counter-clockwise</em>, the resulting scan in body coordinates seems to be rotated 20 degrees in the <em>opposite</em> direction. This makes sense! The forward direction for the robot is along the horizontal x-axis, and as you can see in the scan, the robot seems to be “looking” at the correct (upper-right) corner of our little hallway example. This perhaps counter-intuitive behavior is something to always keep in mind when looking at animations of LIDAR scans.</p>
</section>
<section id="real-lidar-scans">
<h2><span class="section-number">6.3.5. </span>Real LIDAR Scans<a class="headerlink" href="#real-lidar-scans" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>From theory to practice.</p>
</div></blockquote>
<p>3D LIDAR sensors have been used in many autonomous driving efforts, e.g., by Waymo, Cruise, Argo, etc. Below we explore some real scans from the <a class="reference external" href="https://www.argoverse.org/av2.html">Argoverse 2 Lidar Dataset</a> <span id="id1">[<a class="reference internal" href="bibliography.html#id65" title="Benjamin Wilson, William Qi, Tanmay Agarwal, John Lambert, Jagjeet Singh, Siddhesh Khandelwal, Bowen Pan, Ratnesh Kumar, Andrew Hartnett, Jhony Kaesemodel Pontes, Deva Ramanan, Peter Carr, and James Hays. Argoverse 2: Next Generation Datasets for Self-driving Perception and Forecasting. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS Datasets and Benchmarks 2021). 2021.">Wilson <em>et al.</em>, 2021</a>]</span>.</p>
<p>First, let us look at a single scan, shown in Figure <a class="reference internal" href="#fig:lidar_scan_real"><span class="xref myst">4</span></a>, which was acquired using a <a class="reference external" href="https://velodynelidar.com/products/ultra-puck/">Velodyne</a> VLP-32C LIDAR sensor.
The <code class="docutils literal notranslate"><span class="pre">32</span></code> in the model name reflects the fact that, for this particular sensor, there are 32 separate laser beams at different inclinations, that spin around for a full 360 degree field of view. In this case, the inclination angles are uniformly sampled between -25 and +15 degrees with respect to horizontal, but of course this depends on the application/sensor model.</p>
<p>Several things worth noting when looking at the single scan below, taken when the Argo test car is turning at an intersection:</p>
<ul class="simple">
<li><p>The location of the car (at the origin) is marked by concentric circles formed by the lowest beams.</p></li>
<li><p>The range is approximately 200m, so we can see fairly far down the cross streets.</p></li>
<li><p>Occlusion is significant: objects close to the car throw “occlusion shadows.”</p></li>
<li><p>Everything is in <em>body coordinates</em>, and the streets appear rotated because the car is actually turning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: An actual 3D Velodyne LIDAR scan from an autonomous vehicle.</span>
<span class="c1">#| label: fig:lidar_scan_real</span>
<span class="n">real_scans</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">driving</span><span class="o">.</span><span class="n">read_lidar_points</span><span class="p">(</span><span class="s1">&#39;Figures6/lidar/PC_315967795019746000.ply&#39;</span><span class="p">)}</span>
<span class="n">driving</span><span class="o">.</span><span class="n">visualize_cloud</span><span class="p">(</span><span class="n">real_scans</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">show_grid_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8889de54015c491b27bfab89e48b9e0fc1afa5c2bc2bb748541054d159420a77.png" src="_images/8889de54015c491b27bfab89e48b9e0fc1afa5c2bc2bb748541054d159420a77.png" />
</div>
</div>
<p>We can also learn some things from looking at two successive scans in Figure <a class="reference internal" href="#fig:lidar_scan_real_2"><span class="xref myst">5</span></a>.
The scans are slightly rotated and translated from each other,
and this will be exactly how we can infer the motion of the car in the next section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Two successive LIDAR scans from an autonomous vehicle.</span>
<span class="c1">#| label: fig:lidar_scan_real_2</span>
<span class="n">real_scans</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">driving</span><span class="o">.</span><span class="n">read_lidar_points</span><span class="p">(</span><span class="s1">&#39;Figures6/lidar/PC_315967795520065000.ply&#39;</span><span class="p">)</span>
<span class="n">driving</span><span class="o">.</span><span class="n">visualize_clouds</span><span class="p">([</span><span class="n">real_scans</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">real_scans</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">show_grid_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/019452f83edf3c6b1d3bb7e573bc7c3e7813dc33a1e186392c5ae8a67c0da329.png" src="_images/019452f83edf3c6b1d3bb7e573bc7c3e7813dc33a1e186392c5ae8a67c0da329.png" />
</div>
</div>
<p>Finally, let us look - in Figure <a class="reference internal" href="#fig:lidar_scan_real_8"><span class="xref myst">6</span></a> - at scans that are taken a bit further apart, in this case there are 8 scans that we skipped.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Two LIDAR scans from an autonomous vehicle that are eight frames apart.</span>
<span class="c1">#| label: fig:lidar_scan_real_8</span>
<span class="n">real_scans</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="n">driving</span><span class="o">.</span><span class="n">read_lidar_points</span><span class="p">(</span><span class="s1">&#39;Figures6/lidar/PC_315967795919523000.ply&#39;</span><span class="p">)</span>
<span class="n">driving</span><span class="o">.</span><span class="n">visualize_clouds</span><span class="p">([</span><span class="n">real_scans</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">real_scans</span><span class="p">[</span><span class="mi">9</span><span class="p">]],</span> <span class="n">show_grid_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/237d4d76d5b3139902360b017d8ea425bdc2d41885ff97b90611aa6b18544422.png" src="_images/237d4d76d5b3139902360b017d8ea425bdc2d41885ff97b90611aa6b18544422.png" />
</div>
</div>
<p>By inspecting (you can do this interactively using the <a class="reference external" href="https://gtbook.github.io/gtbook/driving.html">gtbook website</a>) you can see that the car is <em>still</em> turning, but as the two scans are further apart the “mis-alginment” is more pronounced.</p>
</section>
<section id="creating-3d-maps">
<h2><span class="section-number">6.3.6. </span>Creating 3D Maps<a class="headerlink" href="#creating-3d-maps" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Point clouds can be used to represent the 3D world.</p>
</div></blockquote>
<p id="index-5">If we know the exact pose at which a LIDAR scan was taken, we can transform the points in the scan into absolute coordinates, and create an extended <strong>point cloud map</strong> of the environment. In math, suppose we <em>know</em> that a scan was taken at <span class="math notranslate nohighlight">\(T^w_b\)</span>, then we can transform all LIDAR points <span class="math notranslate nohighlight">\(P^b\)</span>, which are given in body coordinates, to world coordinates:</p>
<div class="amsmath math notranslate nohighlight" id="equation-893a3e42-e593-4f05-be0c-5022149d407c">
<span class="eqno">(6.34)<a class="headerlink" href="#equation-893a3e42-e593-4f05-be0c-5022149d407c" title="Permalink to this equation">#</a></span>\[\begin{equation}
P^w = \phi(T^w_b, P^b)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi\)</span> the action of <span class="math notranslate nohighlight">\(SE(3)\)</span> on points in <span class="math notranslate nohighlight">\(\mathbb{R}^3\)</span>. Earlier in this chapter we saw this can be done by matrix multiplication, but GTSAM actually implements <span class="math notranslate nohighlight">\(\phi\)</span> directly as <code class="docutils literal notranslate"><span class="pre">Pose3::transformFrom</span></code>. This method can be applied to a single <code class="docutils literal notranslate"><span class="pre">Point3</span></code> (just a <span class="math notranslate nohighlight">\(3\times 1\)</span> vector, really) or on many points simultaneously, by passing in a <span class="math notranslate nohighlight">\(3\times N\)</span> matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scan_in_world</span> <span class="o">=</span> <span class="n">wTb3</span><span class="o">.</span><span class="n">transformFrom</span><span class="p">(</span><span class="n">real_scans</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scan_in_world</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3, 86651)
</pre></div>
</div>
</div>
</div>
<p>We will use this capability in the next section to produce large scale sparse point cloud maps of the environment around an autonomous vehicle.</p>
</section>
<section id="gtsam-101">
<h2><span class="section-number">6.3.7. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>A deeper dive in the GTSAM concepts used above.</p>
</div></blockquote>
<section id="d-and-3d-points">
<h3><span class="section-number">6.3.7.1. </span>2D and 3D Points<a class="headerlink" href="#d-and-3d-points" title="Link to this heading">#</a></h3>
<p>In GTSAM <code class="docutils literal notranslate"><span class="pre">Point2</span></code> and <code class="docutils literal notranslate"><span class="pre">Point3</span></code> are simply functions that return 2D and 3D numpy vectors, respectively:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Point3</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">p</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">P</span><span class="p">),</span> <span class="n">P</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt; [3. 4.]
&lt;class &#39;numpy.ndarray&#39;&gt; [5. 6. 7.]
</pre></div>
</div>
</div>
</div>
</section>
<section id="d-and-3d-rotations">
<h3><span class="section-number">6.3.7.2. </span>2D and 3D Rotations<a class="headerlink" href="#d-and-3d-rotations" title="Link to this heading">#</a></h3>
<p>2D and 3D rotations are represented internally by <span class="math notranslate nohighlight">\(2 \times 2\)</span> matrices and <span class="math notranslate nohighlight">\(3 \times 3\)</span> matrices, respectively, but these are wrapped into the classes <code class="docutils literal notranslate"><span class="pre">Rot2</span></code> and <code class="docutils literal notranslate"><span class="pre">Rot3</span></code>. We can print them, and get the rotation matrix via the <code class="docutils literal notranslate"><span class="pre">matrix()</span></code> method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R1</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Rot2</span><span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">180</span><span class="p">)</span> <span class="c1"># 20 degrees rotation</span>
<span class="nb">print</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">R1</span><span class="o">.</span><span class="n">matrix</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>theta: 0.349066
 [[ 0.93969262 -0.34202014]
 [ 0.34202014  0.93969262]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R2</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Rot3</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">R2</span><span class="o">.</span><span class="n">matrix</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R: [
	1, 0, 0;
	0, 1, 0;
	0, 0, 1
]
 [[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
</pre></div>
</div>
</div>
</div>
<p>While there are various methods to create 3D rotation matrices (use help!), above we only use the named constructor <code class="docutils literal notranslate"><span class="pre">Yaw</span></code> , which is a rotation around the z-axis. Below is an example, which you can compare with the 2D rotation example above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R3</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">Rot3</span><span class="o">.</span><span class="n">Yaw</span><span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">180</span><span class="p">)</span> <span class="c1"># 20 degrees rotation around Z</span>
<span class="nb">print</span><span class="p">(</span><span class="n">R3</span><span class="p">,</span> <span class="n">R3</span><span class="o">.</span><span class="n">matrix</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R: [
	0.939693, -0.34202, 0;
	0.34202, 0.939693, 0;
	0, 0, 1
]
 [[ 0.93969262 -0.34202014  0.        ]
 [ 0.34202014  0.93969262  0.        ]
 [ 0.          0.          1.        ]]
</pre></div>
</div>
</div>
</div>
<p>We will look at 3D rotations in much more detail in Chapter 7, when we look at drones.</p>
</section>
<section id="reading-and-visualizing-lidar-clouds">
<h3><span class="section-number">6.3.7.3. </span>Reading and Visualizing LIDAR clouds<a class="headerlink" href="#reading-and-visualizing-lidar-clouds" title="Link to this heading">#</a></h3>
<p>The utility functions <code class="docutils literal notranslate"><span class="pre">read_lidar_points</span></code> and <code class="docutils literal notranslate"><span class="pre">visualize_clouds</span></code> are not part of GTSAM, but are part of the gtbook library that accompanies this book. On the <a class="reference external" href="https://gtbook.github.io/gtbook/driving.html">gtbook website</a> <span id="id2">[<a class="reference internal" href="bibliography.html#id26" title="Frank Dellaert. gtbook: an nbdev powered toolbox for Frank and Seth’s robotics book. 2024. URL: https://gtbook.github.io/gtbook/.">Dellaert, 2024</a>]</span> you can find much more detailed documentation as well as the source code, but <code class="docutils literal notranslate"><span class="pre">help</span></code> is very comprehensive for those functions. While the visualization code is statically rendered in the book, when you open the Colab things should be rendered as interactive <code class="docutils literal notranslate"><span class="pre">plotly</span></code> scatter plots. Try it!</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S62_driving_actions.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">6.2. </span>Kinematics for Driving</p>
      </div>
    </a>
    <a class="right-next"
       href="S64_driving_perception.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6.4. </span>SLAM</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lidar">6.3.1. LIDAR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-intersection">6.3.2. Ray Intersection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulating-a-2d-lidar">6.3.3. Simulating a 2D LIDAR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#geometry-of-a-moving-lidar">6.3.4. Geometry of a Moving LIDAR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-lidar-scans">6.3.5. Real LIDAR Scans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-3d-maps">6.3.6. Creating 3D Maps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">6.3.7. GTSAM 101</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-and-3d-points">6.3.7.1. 2D and 3D Points</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-and-3d-rotations">6.3.7.2. 2D and 3D Rotations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reading-and-visualizing-lidar-clouds">6.3.7.3. Reading and Visualizing LIDAR clouds</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>