
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2.7. Chapter Summary &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S27_sorter_summary';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. A Robot Vacuum Cleaner" href="S30_vacuum_intro.html" />
    <link rel="prev" title="2.6. Learning" href="S26_sorter_learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Introduction to Robotics and Perception - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a differential-drive robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Cameras for Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S27_sorter_summary.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter Summary</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#models">2.7.1. Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reasoning">2.7.2. Reasoning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background-and-history">2.7.3. Background and History</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-summary">
<h1><span class="section-number">2.7. </span>Chapter Summary<a class="headerlink" href="#chapter-summary" title="Link to this heading">#</a></h1>
<a class="reference internal image-reference" href="_images/S20-Trash_sorting_robot_with_gripper-03.jpg"><img alt="Splash image with heroic trash-sorting robot in sunset light" class="align-center" src="_images/S20-Trash_sorting_robot_with_gripper-03.jpg" style="width: 60%;" /></a>
<p>In this chapter, we used the example of a trash sorting robot to introduce key concepts from probability theory, decision theory, and even machine learning, and showed how these concepts can be used to begin building robotic systems that operate in real world settings, where significant uncertainty may exist.</p>
<section id="models">
<span id="index-0"></span><h2><span class="section-number">2.7.1. </span>Models<a class="headerlink" href="#models" title="Link to this heading">#</a></h2>
<p>Probability theory provides the mathematical foundation for dealing with uncertainties that confront
robotic systems.
In this chapter, we used probability to reason about the uncertain category of an object in the robot’s work space.
We began by introducing <em>probability distributions</em>, which assign probability values to <em>events</em> (i.e., to subsets of the set of all possible outcomes). In the case of discrete outcomes, such as our five categories
of trash, these probability distributions are called <em>probability mass functions</em> or <em>PMFs</em>, and they assign finite probability to each possible category.
When the set of outcomes is continuous, such as the scale we used to measure an object’s weight,
these probability distributions are called <em>probability density functions</em> or <em>PDFs</em>, and they assign probability values to subsets of real numbers, for example, to intervals of the form <span class="math notranslate nohighlight">\([a,b]\)</span>,
and this probabilty value can be computed by integrating the PDF over the interval.
Interestingly, for the continuous case, zero probability is assigned to any individual outcome,
since this would correspond to an interval of the form <span class="math notranslate nohighlight">\([a,a]\)</span>, and for any continuous
function <span class="math notranslate nohighlight">\(f\)</span>, we have <span class="math notranslate nohighlight">\(\int_a^a f(u)du = 0\)</span>.</p>
<p>While probability distributions give some insight into the behavior of individual random outcomes,
in robotics we are often interested in average behavior over long periods of time. For the example of our trash sorting robot, we might like to characterize the average performance of the system over days, or even weeks.
<em>Expectation</em> is a property of probability distributions that gives insight into average behavior over many trials.
The expected value of a discrete random variable is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-405bbcb7-6eb8-4f7f-9cc0-1b1b074732ce">
<span class="eqno">(2.50)<a class="headerlink" href="#equation-405bbcb7-6eb8-4f7f-9cc0-1b1b074732ce" title="Permalink to this equation">#</a></span>\[\begin{equation}
E[X] = \sum_{i=1}^n x_i p_X(x_i)
\end{equation}\]</div>
<p>This expression bears strong resemblance to the equation for the weighted average of
a set of data values, and this is no coincidence.
In fact, this is the essence of the weak law of large numbers, which says that,
as the number of data points goes to infinity,
the average of a set of data points will approach the expected value of the probability
distribution from which the data were drawn.</p>
<p>When there are multiple sources of uncertainty in the world, we can use <em>joint probability distributions</em> to characterize the stochastic relationships between different random quantities.
For example, what is the probability that a piece of trash
will conduct electricity and simultaneously weigh between <span class="math notranslate nohighlight">\(1.5\)</span> and <span class="math notranslate nohighlight">\(3.0\)</span> kg?
A joint PMF for two discrete random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> is denoted by
<span class="math notranslate nohighlight">\(p_{XZ}(x,z)\)</span>, and is defined by <span class="math notranslate nohighlight">\(p_{XZ}(x,z) = P(X=x, Z=z)\)</span>.
(Recall that we use upper case letters to denote random variables,
and lower case letters to denote possible values taken by these random variables.)
This can be extended to any number of random variables, so that, in theory, all uncertainties
in the world could be modeled by a single joint probability distribution.
However, specifying a complete joint probability distribution is exceedingly expensive.
Consider that if we have <span class="math notranslate nohighlight">\(n\)</span> random variables which take on <span class="math notranslate nohighlight">\(N_1, N_2,\dots N_n\)</span> possible values, respectively,
the size of a table to represent the joint probability distribution
would be <span class="math notranslate nohighlight">\(N_1 \times N_2 \times \dots N_n\)</span>, i.e., the size of this data structure
grows exponentially with the number of random variables.</p>
<p>Happily, for most real-world scenarios, we really don’t need the complete joint probability distribution.
The reason for this is that the interactions between random quantities often have a fairly local kind
of behavior.
Because of this property, we can often capture the essential interactions among random variables
using <em>conditional probability distributions</em>, which capture the individual stochastic relationships between
smaller sets of random variables.
For example, we can describe the conditional probability that an object is scrap metal if it conducts electricity,
or, conversely, the probability that an object will conduct electricity if it is scrap metal.
Conditional probability distributions are typically used to model sensor behavior;
the conditional probability <span class="math notranslate nohighlight">\(P(Z| X=x)\)</span> denotes the probability distribution for random variable <span class="math notranslate nohighlight">\(Z\)</span>
given that the random variable <span class="math notranslate nohighlight">\(X\)</span> takes the value <span class="math notranslate nohighlight">\(x\)</span>.
This kind of model is sometimes called a forward sensor model, since it models the behavior of the sensor
given the state of the world.
Note that the conditional distribution <span class="math notranslate nohighlight">\(P(Z | X=x)\)</span> is itself a valid probability distribution.
For example, if <span class="math notranslate nohighlight">\(Z\)</span> is a discrete random variable, we would have <span class="math notranslate nohighlight">\(\sum_i P(Z=z_i | X=x) =1\)</span>.</p>
<p>We also saw how probabilistic models can be incorporated into computational solutions via sampling.
In particular, we developed an algorithm that uses the cumulative distribution function to generate samples for a given particular probability distribution. We used this sampling algorithm to investigate the empirical relationship between outcomes generated from a probability distribution and the expected value of the distribution.</p>
</section>
<section id="reasoning">
<h2><span class="section-number">2.7.2. </span>Reasoning<a class="headerlink" href="#reasoning" title="Link to this heading">#</a></h2>
<p>While the various kinds of probability models nicely describe the stochastic nature of the world,
it is not immediately obvious how they could be used to make inferences about the world,
or as a basis for decision-making in an uncertain world.
The key idea that enables this kind of reasoning is captured in Bayes’ theorem:</p>
<div class="amsmath math notranslate nohighlight" id="equation-25728f4b-ab83-480a-8f97-8f77d4131d09">
<span class="eqno">(2.51)<a class="headerlink" href="#equation-25728f4b-ab83-480a-8f97-8f77d4131d09" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X|Z=z)=\frac{P(Z=z|X)P(X)}{P(Z=z)}
\end{equation} \]</div>
<p>Note that the forward model, <span class="math notranslate nohighlight">\(P(Z=z|X)\)</span> appears on the right hand side, and is used to compute the <em>inverse model</em>
<span class="math notranslate nohighlight">\(P(X | Z=z)\)</span>. For example, if we are given the value of a sensor reading, <span class="math notranslate nohighlight">\(Z\)</span>, Bayes’ theorem can
be used to compute the probability associated to the state <span class="math notranslate nohighlight">\(X\)</span>.
For this reason, Bayes’ theorem is sometimes referred to as an inversion theorem.</p>
<p>We can use Bayes’ theorem to compute the <em>maximum a posteriori</em> estimate (or <em>MAP</em> estimate) for the value of <span class="math notranslate nohighlight">\(X\)</span> given sensor reading <span class="math notranslate nohighlight">\(Z =z\)</span> by solving the optimization problem:</p>
<div class="amsmath math notranslate nohighlight" id="equation-e409e6be-1b52-4579-981a-439cfdf76673">
<span class="eqno">(2.52)<a class="headerlink" href="#equation-e409e6be-1b52-4579-981a-439cfdf76673" title="Permalink to this equation">#</a></span>\[\begin{equation}
x^*_{MAP} = \arg \max_x P(x|z)
\end{equation}\]</div>
<p>Note that this computation requires that we have access to the prior probability distribution <span class="math notranslate nohighlight">\(P(X)\)</span>.
In cases where this is not available, we may instead choose to compute the <em>maximum likelihood</em> estimate (or <em>MLE</em>),
which is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-59207b6e-7cc2-4619-9933-add951356aa1">
<span class="eqno">(2.53)<a class="headerlink" href="#equation-59207b6e-7cc2-4619-9933-add951356aa1" title="Permalink to this equation">#</a></span>\[\begin{equation}
x^*_{MLE} =  \arg \max_x L(x;z) =  \arg \max_x P(Z=z|X) 
\end{equation}\]</div>
<p>in which <span class="math notranslate nohighlight">\(L(x;z) = P(Z=z|X)\)</span> is called the likelihood.
Note that the likelihood is <em>not</em> a valid probability distribution,
since typically <span class="math notranslate nohighlight">\(\sum_i P(Z=z | X=x_i) \neq 1\)</span>.</p>
<!-- **Some words about learning - estimating a pdf, modeling senors and calibration, parameter estimation.
OR DOES THIS GO IN THE MODELING SECTION?** --></section>
<section id="background-and-history">
<h2><span class="section-number">2.7.3. </span>Background and History<a class="headerlink" href="#background-and-history" title="Link to this heading">#</a></h2>
<p>The origins of probability theory can be traced back to games of chance in ancient societies, but the first real attempts to formalize the study of probability came during the Renaissance, in the works of mathematicians such as Cardano, Pascal, and Fermat. These early mathematical approaches focused mainly on games of chance, with a strong empirical flavor. The line between statistics and probability theory was a blurry one in Renaissance times.</p>
<p>It was Bayes, in the eighteenth century, who pioneered the idea of using evidence, together with ideas from probability theory, to draw inferences. While what we now know as Bayes’ theorem is a general result that does not depend on the specific probability distributions under consideration, Bayes studied the specific case of inferring the parameter of a binomial distribution given observed outcomes. The more general development is due largely to Laplace, in the years following the death of Bayes.</p>
<p>What we think of today as probability theory was formalized in the early 1930’s by Kolmogorov. It was Kolmogorov who formulated the three axioms that form the basis for modern probability theory:</p>
<ol class="arabic simple">
<li><p>For any event <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(P(A) \geq 0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(\Omega)=1\)</span>.</p></li>
<li><p>For disjoint events <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, <span class="math notranslate nohighlight">\(P(A\cup B) = P(A) + P(B)\)</span>.</p></li>
</ol>
<p>Equipped with these three axioms and a background in <em>real analysis</em>, one can derive most all of the important results that comprise modern probability theory.
The Renaissance mathematicians were interested in understanding random phenomena. Kolmogorov, a Russian mathematician, was interested in establishing a rigorous theoretical foundation for probability theory.</p>
<p>One of the best recent books we have found useful is the book <a class="reference external" href="https://probability4datascience.com/index.html">“Introduction to Probability for Data Science”</a> <span id="id1">[<a class="reference internal" href="bibliography.html#id6" title="Stanley H. Chan. Introduction to Probability for Data Science. Michigan Publishing Services, 2023. ISBN 978-1-60785-747-1. URL: https://probability4datascience.com/index.html.">Chan, 2023</a>]</span>.
The classic reference for statistical reasoning, including
maximum likelihood estimation and Bayesian decision theory
is <span id="id2">[<a class="reference internal" href="bibliography.html#id37" title="R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classification. Wiley, 2012. ISBN 9781118586006. URL: https://books.google.co.uk/books?id=Br33IRC3PkQC.">Duda <em>et al.</em>, 2012</a>]</span>.
Anders Hald has written two volumes on the history of probability theory,
one that covers the period from Bernoulli, De Moivre and Laplace to the mid-twentieth century,
with particular attention to estimation problems <span id="id3">[<a class="reference internal" href="bibliography.html#id33" title="Anders Hald. A history of mathematical statistics from 1750 to 1930. Wiley, 1998.">Hald, 1998</a>]</span>,
and one that covers developments prior to 1750 <span id="id4">[<a class="reference internal" href="bibliography.html#id34" title="Anders Hald. A History of Probability and Statistics and Their Applications before 1750. Wiley, 2003.">Hald, 2003</a>]</span>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S26_sorter_learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2.6. </span>Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="S30_vacuum_intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>A Robot Vacuum Cleaner</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#models">2.7.1. Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reasoning">2.7.2. Reasoning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background-and-history">2.7.3. Background and History</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>