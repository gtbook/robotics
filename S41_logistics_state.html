
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>4.1. Continuous State &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S41_logistics_state';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4.2. Moving in 2D" href="S42_logistics_actions.html" />
    <link rel="prev" title="4. Warehouse Robots in 2D" href="S40_logistics_intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Introduction to Robotics and Perception - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S27_sorter_summary.html">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a differential-drive robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Cameras for Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S41_logistics_state.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Continuous State</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-densities">4.1.1. Gaussian Densities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-finite-element-method">4.1.2. The Finite Element Method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-sampling-based-representation">4.1.3. A Sampling-based representation.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-probabilities">4.1.4. Computing Probabilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">4.1.5. GTSAM 101</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtbook-101">4.1.6. GTbook 101</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="continuous-state">
<h1><span class="section-number">4.1. </span>Continuous State<a class="headerlink" href="#continuous-state" title="Link to this heading">#</a></h1>
<p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S41_logistics_state.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<blockquote id="index-0">
<div><p>The motion of our warehouse robots is restricted to translation in the 2D plane (i.e., there is no rotational motion).</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S41-Warehouse_robots-07.jpg"><img alt="Splash image with warehouse robot in two different states" class="align-center" src="_images/S41-Warehouse_robots-07.jpg" style="width: 40%;" /></a>
<p>Imagine a vast warehouse, with rows of storage, a flat concrete floor, and many people operating alongside robots to fulfill orders and replenish inventory.
In logistics applications of this kind, the main job of the robot is to transport items from one location
to another. An accurate and complete map of the warehouse layout is typically available, and the motion
of the robot is fairly simple, often restricted to translation in directions that are parallel to coordinate
axes defined by the arrangement of storage shelves.
Such motions can be achieved by a robot equipped with omni-wheels, which allow instantaneous
motion in any direction.
Because the robot’s motion is limited to pure translation, the orientation of the robot
does not change, and need not be considered when defining the robot state.
Furthermore, because these robots typically move at relatively low speeds, we need not consider forces
(or wheel torques) that are required to effect these motions.</p>
<p>For this special case of robots that translate in the plane, and whose instantaneous
velocity is the command input, the state space is merely the location of the robot
in the world with respect to some global coordinate frame:</p>
<div class="amsmath math notranslate nohighlight" id="equation-fa649764-18df-40a7-8341-76a530f30075">
<span class="eqno">(4.1)<a class="headerlink" href="#equation-fa649764-18df-40a7-8341-76a530f30075" title="Permalink to this equation">#</a></span>\[\begin{equation}
x\in {\cal D} \subset \mathbb{R}^2
\end{equation}\]</div>
<p>In the remainder of this chapter, we will consider a rectangular warehouse
that is 100 by 50 meters, a good size warehouse, similar to a typical DIY store.
In this case, <span class="math notranslate nohighlight">\( {\cal D} = [0,100] \times [0,50]\)</span>.</p>
<p>In previous chapters, we considered discrete state spaces (categories of objects, rooms in a house). Here, the
state space is continuous, which brings a need for more sophisticated methods for dealing with uncertainty.
We can broadly divide these approaches into two categories:
directly using exact, parameterized probability density functions (PDFs),
and using discrete approximations to probability distributions.
When using exact PDFs, we will restrict our attention to the multivariate (in our case, bivariate) Gaussian distribution
to characterize uncertainty in state.
We have previously used univariate Gaussians to model weight for our trash sorting robot,
and the extension to the 2D case is not so difficult.
In the of approximate representations of probability distributions,
we will introduce two complementary methods: a finite element method, and a sampling-based method.
In the former, we approximate the state space by a two-dimensional grid, and keep track of the
probability mass in each individual grid cell.
In the latter, we represent a PDF by a weighted collection of samples.
This representation is particularly amenable to propagating uncertainties that arise during
robot motion.</p>
<section id="gaussian-densities">
<h2><span class="section-number">4.1.1. </span>Gaussian Densities<a class="headerlink" href="#gaussian-densities" title="Link to this heading">#</a></h2>
<p id="index-3"><span id="index-2"></span><span id="index-1"></span>As we have seen with the trash sorting robot, a one-dimensional Gaussian density can be used
to represent continuous random variables.
The Gaussian probability density function (PDF) is defined by</p>
<div class="amsmath math notranslate nohighlight" id="equation-7591ebb3-0d9e-42b1-b63a-940d79b3ee13">
<span class="eqno">(4.2)<a class="headerlink" href="#equation-7591ebb3-0d9e-42b1-b63a-940d79b3ee13" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{N}(x;\mu,\sigma^2) \doteq \frac{1}{k} \exp\{ - \frac{1}{2} \frac{(x-\mu)^2}{\sigma^2} \}
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu\)</span> is the mean, <span class="math notranslate nohighlight">\(\sigma^2\)</span> is the variance, and <span class="math notranslate nohighlight">\(k=\sqrt{2\pi}\sigma\)</span> is a normalization constant.
It is instructive to consider the term in the exponent.</p>
<ol class="arabic simple">
<li><p>The term <span class="math notranslate nohighlight">\(x-\mu\)</span> is the signed distance from <span class="math notranslate nohighlight">\(x\)</span> to the mean.</p></li>
<li><p>The term <span class="math notranslate nohighlight">\((x-\mu)^2\)</span> is the squared distance from <span class="math notranslate nohighlight">\(x\)</span> to the mean.</p></li>
<li><p>The term <span class="math notranslate nohighlight">\(\sigma^{-2}(x-\mu)^2\)</span> is a weighted squared-distance to the mean.</p></li>
</ol>
<p>Thus, we can interpret the negative log of a 1D Gaussian as a simple quadratic error or “energy” function. This fact is worth emphasizing: <em>a Gaussian density is the probability density associated with a quadratic error function with zero error at the mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</em> We suggestively write this quadratic below as</p>
<div class="amsmath math notranslate nohighlight" id="equation-bf465d9f-4cb7-43ca-81a4-4f038e5a60cb">
<span class="eqno">(4.3)<a class="headerlink" href="#equation-bf465d9f-4cb7-43ca-81a4-4f038e5a60cb" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{E}(x;\mu,\sigma^2) \doteq \frac{1}{2} (x-\mu)\sigma^{-2}(x-\mu)
\end{equation}\]</div>
<p id="index-5"><span id="index-4"></span>The energy analogy can be extended to the multivariate case.
In the 1D case, the mean and variance are scalars.
For the <span class="math notranslate nohighlight">\(n\)</span>-dimensional case when <span class="math notranslate nohighlight">\(x\in\mathbb{R}^n\)</span>, the mean is a vector,  <span class="math notranslate nohighlight">\(\mu\in\mathbb{R}^n\)</span>,
and the concept of variance is extended to define a
<strong>covariance matrix</strong> <span class="math notranslate nohighlight">\(\Sigma\in\mathbb{R}^{n\times n}\)</span>,
a symmetric, positive definite matrix that characterizes the “spread” of a quadratic in multiple dimensions.
This allows us to generalize the 1D error function above to the <span class="math notranslate nohighlight">\(n\)</span>-dimensional case as</p>
<div class="amsmath math notranslate nohighlight" id="equation-6902a743-a6c5-47f6-bc92-e52836fd0551">
<span class="eqno">(4.4)<a class="headerlink" href="#equation-6902a743-a6c5-47f6-bc92-e52836fd0551" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{E}(x;\mu,\Sigma) \doteq \frac{1}{2} (x-\mu)^T\Sigma^{-1}(x-\mu)
\end{equation}\]</div>
<p>We define a <strong>multivariate Gaussian density</strong> using the error function <span class="math notranslate nohighlight">\(\mathcal{E}(x;\mu,\Sigma)\)</span>
as follows</p>
<div class="amsmath math notranslate nohighlight" id="equation-300d2ee6-324b-4868-bb5e-5c29abbe7076">
<span class="eqno">(4.5)<a class="headerlink" href="#equation-300d2ee6-324b-4868-bb5e-5c29abbe7076" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{N}(x;\mu,\Sigma) \doteq \frac{1}{k} \exp\{ - \frac{1}{2} (x-\mu)^T\Sigma^{-1}(x-\mu) \}
\end{equation}\]</div>
<p>The (non-obvious) normalization constant k can be written very elegantly in terms of the determinant of <span class="math notranslate nohighlight">\(2\pi\Sigma\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-19a1b14a-d805-45ec-b4f8-8e623a7943b4">
<span class="eqno">(4.6)<a class="headerlink" href="#equation-19a1b14a-d805-45ec-b4f8-8e623a7943b4" title="Permalink to this equation">#</a></span>\[\begin{equation}
k=\sqrt{(2\pi)^{n}|\Sigma|}=\sqrt{|2\pi\Sigma|}.
\end{equation}\]</div>
<p>Another name for multivariate Gaussian probability density is the multivariate normal distribution. We prefer to use <em>density</em> to denote its continuous nature, and Gaussian instead of “normal”, but it is good to be aware of both nomenclatures.</p>
<p>To better understand the multivariate Gaussian PDF, consider a simple two-dimensional example,</p>
<div class="amsmath math notranslate nohighlight" id="equation-406a2f85-29f5-4651-8ac3-b1f16ebe9405">
<span class="eqno">(4.7)<a class="headerlink" href="#equation-406a2f85-29f5-4651-8ac3-b1f16ebe9405" title="Permalink to this equation">#</a></span>\[\begin{equation}
\begin{aligned}
\mu &amp;= \begin{bmatrix} 4 \\ 10 \end{bmatrix} \\
\\
\Sigma &amp;= \begin{bmatrix} 
\sigma^2_{xx} &amp; 0 \\
0 &amp; \sigma^2_{yy} 
\end{bmatrix}
\end{aligned}
\end{equation}\]</div>
<p>If we evaluate <span class="math notranslate nohighlight">\(\mathcal{E}(x;\mu,\Sigma)\)</span> for this case, we obtain</p>
<div class="amsmath math notranslate nohighlight" id="equation-3c16f36d-7a1b-4bcf-b8cf-323d106938f8">
<span class="eqno">(4.8)<a class="headerlink" href="#equation-3c16f36d-7a1b-4bcf-b8cf-323d106938f8" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{E}(x;\mu,\Sigma) = \frac{1}{\sigma^2_{xx}}(x - 4)^2 + \frac{1}{\sigma^2_{yy}}(y - 10)^2
\end{equation}\]</div>
<p>which is the familiar equation of an axis-aligned ellipse in the plane with center at <span class="math notranslate nohighlight">\((4, 10)\)</span>.
This form gives a nice geometric interpretation to the Gaussian PDF.
For any constant <span class="math notranslate nohighlight">\(k\)</span>,
the value of  <span class="math notranslate nohighlight">\(\mathcal{N}(x;\mu,\Sigma)\)</span> is constant for all <span class="math notranslate nohighlight">\(x\)</span> that satisfy
<span class="math notranslate nohighlight">\(\mathcal{E}(x;\mu,\Sigma) = k\)</span>.
For a 2D Gaussian, the level sets <span class="math notranslate nohighlight">\(\{ x \; | \; \mathcal{E}(x;\mu,\Sigma) = k \}\)</span> always take the form
of a concentric ellipses (centered at <span class="math notranslate nohighlight">\(\mu\)</span>) whose axes are determined by the covariance matrix <span class="math notranslate nohighlight">\(\Sigma\)</span>.
When illustrating 2D Gaussian PDFs, it is typical to show a few level sets (as in the example below),
which is why there are so many ellipses in the figures below.</p>
<p>In python, none of the packages we rely on for this book define a Gaussian, but it is easy enough to do in code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,)),</span> <span class="n">cov</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate multivariate Gaussian at x of shape(m,n), yields (m,) vector.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;error: x has shape </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">cov</span><span class="p">))</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
    <span class="n">E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">e</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span> <span class="o">*</span> <span class="n">e</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">E</span><span class="p">)</span><span class="o">/</span><span class="n">k</span>
</pre></div>
</div>
</div>
</div>
<p>The simple code above has limitations: it <em>only</em> works for dimensionality <span class="math notranslate nohighlight">\(n\geq2\)</span>.  In this chapter we will be working in 2D, so below we show the effect of mean and covariance as density contour plots in Figure <a class="reference internal" href="#fig:example_gaussians"><span class="xref myst">1</span></a>. The first two Gaussians in the figure are <em>axis-parallel</em>, and the covariance matrices simply contain the squared standard deviations of the <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> dimensions on their diagonals. The third Gaussian shows the case where <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are positively correlated, around a mean of <span class="math notranslate nohighlight">\((50,15)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Some example Gaussian densities in 2D.</span>
<span class="c1">#| label: fig:example_gaussians</span>
<span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">20</span><span class="p">,</span><span class="mi">25</span><span class="p">),(</span><span class="mi">70</span><span class="p">,</span><span class="mi">40</span><span class="p">),(</span><span class="mi">50</span><span class="p">,</span><span class="mi">15</span><span class="p">)]]</span>
<span class="n">covariances</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="n">sx</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">sy</span><span class="o">**</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">sx</span><span class="p">,</span><span class="n">sy</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">)]]</span>
<span class="n">covariances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">40</span><span class="p">,</span><span class="mi">35</span><span class="p">],[</span><span class="mi">35</span><span class="p">,</span><span class="mi">40</span><span class="p">]]))</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">go</span><span class="o">.</span><span class="n">Contour</span><span class="p">(</span><span class="n">z</span><span class="o">=</span><span class="n">gaussian</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">map_coords</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">),</span> <span class="n">contours_coloring</span><span class="o">=</span><span class="s1">&#39;lines&#39;</span><span class="p">,</span>
        <span class="n">line_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">showscale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">mean</span><span class="p">,</span><span class="n">cov</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">,</span><span class="n">covariances</span><span class="p">)]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">);</span> <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/60662b30b580cf95514acd1ec33e1135051052e643456db1392f5ed9e58b290f.png" src="_images/60662b30b580cf95514acd1ec33e1135051052e643456db1392f5ed9e58b290f.png" />
</div>
</div>
<p id="index-6">One advantage of the Gaussian as a probability density is that it is easy to specify and to compute with. A disadvantage is that it provides a fairly restricted class of densities: in particular, it is a <em>unimodal</em> density, meaning that it only has a single maximum. Hence, we will never be able to represent two equally probable locations in space, for example. One way to get around this limitation is to use a <em>mixture</em> of Gaussian densities. This is a well known technique, and has its merits, but is outside the scope of this book.</p>
</section>
<section id="the-finite-element-method">
<h2><span class="section-number">4.1.2. </span>The Finite Element Method<a class="headerlink" href="#the-finite-element-method" title="Link to this heading">#</a></h2>
<p>Representing uncertainty using multivariate Gaussians has the appeal of providing
an exact representation that depends on only a small number of parameters (the mean and covariance matrix).
However, as mentioned above, multivariate Gaussians suffer from several limitations,
including the inability to easily deal with multimodal distributions (e.g.,
if the robot thinks it could be in any one of several aisles,
but is fairly sure that it is located halfway down the aisle).
A second limitation of Gaussians is that they are… Gaussians, and therefore they
are of limited utility when uncertainty does not conform to the normal distribution.</p>
<p>One way to deal with these limitations is to introduce approximate, grid-based representations
of uncertainty.
With this approach, each grid cell contains an associated probability mass.
As the robot moves in the environment, the probabilities assigned to each grid cell
are updated based on uncertainty in the motion model (as we’ll see in the next section).
When sensor data are available, perception algorithms can be used to reduce uncertainty,
thereby concentrating probability mass in grid cells associated with higher likelihood
values (as we’ll see in the section on perception).
Because this approximation does not rely on a parameterization of the PDF (e.g., it is
not specified by a mean and covariance matrix), it can be used to approximate any PDF,
with accuracy that depends on the number of cells in the grid.</p>
<p id="index-7">Grid-based representations embody the classical trade-off between accuracy and complexity.
The accuracy of the representation depends on the resolution along the grid coordinate
axes, but the number of cells in the grid grows exponentially (with the dimension of the space)
as a function of this resolution.
Choosing the <em>resolution</em> for our discretization scheme is therefore a key design decision.
For example, if we pick 1x1 meter cells, we are looking at <span class="math notranslate nohighlight">\(100\times50=5000\)</span> cells. But <span class="math notranslate nohighlight">\(1m^2\)</span> seems a bit coarse for navigating with a robot. Could we get away with <span class="math notranslate nohighlight">\(10cm\)</span> resolution?
Here we immediately see difficulty that arises due to the exponential complexity associated to grids. In our case, increasing the resolution by 10, from 1 meter to 10cm, increases the number of cells needed by a factor of <span class="math notranslate nohighlight">\(10^2=100\)</span>, from 5000 to <span class="math notranslate nohighlight">\(1000\times500=500k\)</span>.
This difficulty, while significant in the 2D case, rapidly becomes untenable as the dimensionality of the problem
increases.</p>
<p>In Figure <a class="reference internal" href="#fig:example_gaussians_finite"><span class="xref myst">2</span></a> we show what the 1x1 meter discretization looks like for our warehouse example, using the same three Gaussian densities from above to illustrate a multimodal density.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A finite element representation of the example Gaussian densities.</span>
<span class="c1">#| label: fig:example_gaussians_finite</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
<span class="k">for</span> <span class="n">mean</span><span class="p">,</span><span class="n">cov</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">,</span><span class="n">covariances</span><span class="p">):</span>
    <span class="n">probabilities</span> <span class="o">+=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">map_coords</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="n">probabilities</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">probabilities</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8f7d0c0bdda10169080e652505a081f4f564551abfb38407805e8ead296e9cb3.png" src="_images/8f7d0c0bdda10169080e652505a081f4f564551abfb38407805e8ead296e9cb3.png" />
</div>
</div>
</section>
<section id="a-sampling-based-representation">
<h2><span class="section-number">4.1.3. </span>A Sampling-based representation.<a class="headerlink" href="#a-sampling-based-representation" title="Link to this heading">#</a></h2>
<p id="index-8">Sampling-based methods offer a simple, efficient alternative.
Grid-based representations can be remarkably inefficient:
regardless of how the probability mass is distributed over the state space, the number of cells
remains fixed, and each cell must be considered when propagating uncertainty.
Instead of discretizing the space and keeping track of the probability mass assigned to each grid cell,
we can discretize the probability mass, and keep track of how that probability mass moves through
the state space as uncertainty is propagated forward in time.
Sampling-based approaches do exactly this.</p>
<p id="index-9">In sampling-based methods the density <span class="math notranslate nohighlight">\(p(x)\)</span> is represented by a set of N random <em>samples</em> or,
often called <em>particles,</em> <span class="math notranslate nohighlight">\(S=\{s^{(i)};i\in1..N\}\)</span> drawn from <span class="math notranslate nohighlight">\(p(x)\)</span>.
We are able to do this because of the essential duality between the samples and the density from which they are generated: from the samples we can always approximately reconstruct the density, e.g. using a histogram.</p>
<p>Sampling-based approaches can be significantly more efficient than grid-based approaches.
First, the number of samples need not grow exponentially with the dimension of the space.
Second, because we (attempt to) keep only samples that represent significant concentrations of probability
mass, the number of samples will be small in areas that are unlikely.
Finally, sampling-based approaches lend themselves to computationally efficient simulation schemes,
and these can form the basis for perception algorithms used in localization (as we shall see shortly).</p>
<p>In Figure <a class="reference internal" href="#fig:example_gaussians_samples"><span class="xref myst">3</span></a>, we use a <code class="docutils literal notranslate"><span class="pre">numpy</span></code> random number generator to sample from the three Gaussians we defined above, and display the resulting sets of samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A sampling-based representation of the example Gaussian densities.</span>
<span class="c1">#| label: fig:example_gaussians_samples</span>
<span class="n">N</span><span class="o">=</span><span class="mi">500</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
           <span class="k">for</span> <span class="n">mean</span><span class="p">,</span><span class="n">cov</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">,</span><span class="n">covariances</span><span class="p">)]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">sample</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">sample</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
        <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">samples</span><span class="p">)]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">);</span> <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/efb4088d2f73fc27b6992f288cc91c647c2b56637e609f39a04061b681c39ff3.png" src="_images/efb4088d2f73fc27b6992f288cc91c647c2b56637e609f39a04061b681c39ff3.png" />
</div>
</div>
</section>
<section id="computing-probabilities">
<h2><span class="section-number">4.1.4. </span>Computing Probabilities<a class="headerlink" href="#computing-probabilities" title="Link to this heading">#</a></h2>
<p>In general, for continuous random variables, probability mass is computed by integrating probability density
over a domain.
In the 2D case,  we can find the probability of the state <span class="math notranslate nohighlight">\(x\)</span> being contained in any finite region <span class="math notranslate nohighlight">\({\cal R}\)</span> by integrating the PDF over <span class="math notranslate nohighlight">\({\cal R}\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-1c65f62e-3253-4b1f-89f2-891ffa59c0da">
<span class="eqno">(4.9)<a class="headerlink" href="#equation-1c65f62e-3253-4b1f-89f2-891ffa59c0da" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(x\in {\cal R}) = \int_{x\in {\cal R}} p(x) dx
\end{equation}\]</div>
<p>In the case of Gaussian PDFs, it is not possible to compute this integral in closed form, but
thanks to the nice geometric properties of the level sets of Gaussian PDFs, there
are efficient numerical methods to do so.</p>
<p>In the case of grid-based approximations, computing the probability mass assigned to a specific
region amounts to summing the probabilities associated to the grid cells that define that region.</p>
<p>For sampling-based approximations, a set of weighted samples can be used to construct
histogram-style representation of the probability distribution.</p>
</section>
<section id="gtsam-101">
<h2><span class="section-number">4.1.5. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>The GTSAM concepts used in this section, explained.</p>
</div></blockquote>
<p>We really used only one concept from GTSAM above, which is <code class="docutils literal notranslate"><span class="pre">Point2</span></code>. For maximal compatibility with numpy, in python this is just a function that creates a 2D, float numpy array. Inside GTSAM, it is represented as an Eigen vector, where Eigen is the C++ equivalent of numpy.</p>
</section>
<section id="gtbook-101">
<h2><span class="section-number">4.1.6. </span>GTbook 101<a class="headerlink" href="#gtbook-101" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>About the support code we use throughout this book</p>
</div></blockquote>
<p>Because in this chapter we will use the same code over and over again, we defined some of the key functions in the <code class="docutils literal notranslate"><span class="pre">gtbook</span></code> library accompanying this book. In particular, above we used the following:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">logistics.map_coords</span></code>: a numpy array of shape (50, 100, 2) with x and y coordinates for every cell in the map, at 1m resolution.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logistics.show_map</span></code>: takes a probability image and plots it using plotly’s <code class="docutils literal notranslate"><span class="pre">imshow</span></code> function</p></li>
</ul>
<p>
As always, you can get help on functions by calling <code class="docutils literal notranslate"><span class="pre">help</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on function show_map in module gtbook.logistics:

show_map(image=None, markers=None, file: str = None, marker={})
    Show image on warehouse map, possibly with markers
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S40_logistics_intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Warehouse Robots in 2D</p>
      </div>
    </a>
    <a class="right-next"
       href="S42_logistics_actions.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4.2. </span>Moving in 2D</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-densities">4.1.1. Gaussian Densities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-finite-element-method">4.1.2. The Finite Element Method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-sampling-based-representation">4.1.3. A Sampling-based representation.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-probabilities">4.1.4. Computing Probabilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">4.1.5. GTSAM 101</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtbook-101">4.1.6. GTbook 101</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>