{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ghLEweEVYMmD",
   "metadata": {},
   "source": [
    "# State Space for a differential-drive robot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lOxbf2Yi5pvG",
   "metadata": {
    "colab_type": "text",
    "tags": [
     "no-tex"
    ]
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gtbook/robotics/blob/main/S51_diffdrive_state.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8QVmE4S-v1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U gtbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azWgi15MntHa",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import gtsam\n",
    "from gtbook.display import pretty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "NU6EI-EUqeor",
   "metadata": {},
   "source": [
    "```{index} state; configuration space\n",
    "```\n",
    "\n",
    "> Unlike robots with omni-directional wheels, the orientation of a differential-drive robot matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c105e5",
   "metadata": {
    "tags": [
     "no-pdf"
    ]
   },
   "source": [
    "<img src=\"Figures5/S51-Two-wheeled_Toy_Robot-03.jpg\" alt=\"Splash image with differential-drive robots in different states\" width=\"40%\" align=center style=\"vertical-align:middle;margin:10px 0px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mjHixibVjIOR",
   "metadata": {},
   "source": [
    "```{index} pair: differential-drive robot; DDR\n",
    "```\n",
    "<figure id=\"fig:duckiebot\">\n",
    "<img src=\"https://github.com/gtbook/robotics/blob/main/Figures5/duckiebot.png?raw=1\" style=\"width:14cm\" alt=\"\">\n",
    "<figcaption>Two views of the Duckiebot platform. Note the two actuated wheels in the front of the robot, and the castor wheel in the back.</figcaption>\n",
    "</figure>\n",
    "\n",
    "So far we have seen two kinds of state space: discrete state spaces (the categories of trash, the rooms in a house)\n",
    "and continuous state spaces that were equivalent to $\\mathbb{R}^2$ (the position of a logistics robot in a warehouse).\n",
    "In this chapter, we consider a robot whose state space includes the orientation of the robot as well as its position.\n",
    "In particular, we consider differential-drive robots (DDRs), such as the Duckiebot shown in Figure [1](#fig:duckiebot).\n",
    "DDRs have two actuated wheels that share a common axis of rotation, and typically have a castor wheel in the back\n",
    "to stabilize the robot (without this castor wheel, the DDR would essentially be equivalent to a Segway two-wheeled scooter).\n",
    "Unlike robots with omni-directional wheels, DDRs cannot move in the direction parallel to the wheel axis -- they can only move\n",
    "in the steering direction. Because of this, it is necessary to include the orientation of the robot in its state description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F4pYeCN49Kv7",
   "metadata": {},
   "source": [
    "<figure id=\"fig:DDR-coordinate-frame\">\n",
    "<img src=\"https://github.com/gtbook/robotics/blob/main/Figures5/DDR-coordinate-frame.png?raw=1\" style=\"width:9cm\" alt=\"\">\n",
    "<figcaption>A Coordinate frame that is rigidly attached to a DDR.</figcaption>\n",
    "</figure>\n",
    "\n",
    "```{index} body-attached frame\n",
    "```\n",
    "Representing the state of the logistics robot was straightforward, we merely used the x- and y-coordinates of the robot's center of mass\n",
    "(in the case of a robot with circular shape, the center of this circle).\n",
    "Representing orientation is slightly more complex, and cannot be accomplished by merely encoding properties of a single point on the robot.\n",
    "Instead, we rigidly attach a coordinate frame to the robot, and define the robot state by the position of the origin of this\n",
    "frame and the orientation of the frame with respect to the world frame.\n",
    "We refer to the robot's frame as the *body-attached frame*, or merely the robot frame.\n",
    "For DDRs, it is typical to place the origin of the body-attached frame at the midpoint between the two wheels, and to align its\n",
    "x-axis with the forward steering direction. The y-axis is coincident with the axis of wheel rotation.\n",
    "This frame is illustrated in Figure [2](#fig:DDR-coordinate-frame)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AW7BDGHma2Y1",
   "metadata": {},
   "source": [
    "```{index} configuration, configuration space\n",
    "```\n",
    "In many robotics applications, if we are interested only in geometric aspects of the problem (e.g., if we are not concerned with dynamics, or with forces that are required to effect motion), we use the term *configuration space* instead of the term *state space*. \n",
    "A **configuration**, denoted by $q$, is a complete specification of the location of every point on a robotic system (assuming that a model of the robot\n",
    "is available).  The **configuration space**, denoted by ${\\cal Q}$, is the set of all configurations.\n",
    "For a DDR, the position and orientation of the robot provide such a specification; if we know the position and orientation of the robot,\n",
    "we can infer the location of any point on the robot.\n",
    "In this chapter, we will therefore use ${\\cal Q} = \\mathbb{R}^2 \\times [0, 2\\pi),$\n",
    "and $q = (x,y,\\theta)$ to parameterize the configuration space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qUYBzGvNnt2j",
   "metadata": {},
   "source": [
    "<figure id=\"fig:DDR-wheel-centers\">\n",
    "<img src=\"https://github.com/gtbook/robotics/blob/main/Figures5/DDR-wheel-centers.png?raw=1\" style=\"width:9cm\" alt=\"\">\n",
    "<figcaption>Determining the position of the wheel centers.</figcaption>\n",
    "</figure>\n",
    "\n",
    "As an example, consider the problem of determining the x-y position of the wheel centers\n",
    "for the DDR shown in Figure [3](#fig:DDR-wheel-centers).\n",
    "If the wheelbase (i.e., the distance between the two wheel centers) is denoted by $L$,\n",
    "and the robot is in configuration $q=(x,y.\\theta)$,\n",
    "then the x-y coordinates of the left and right wheel centers are given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\left[ \\begin{array}{c} x_{\\mathrm{left}} \\\\ y_{\\mathrm{left}} \\end{array}\\right]\n",
    "=\n",
    "\\left[ \\begin{array}{c} x - \\frac{L}{2} \\sin \\theta \\\\ \\ \\\\ y + \\frac{L}{2} \\cos \\theta \\end{array}\\right]\n",
    "\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\n",
    "\\left[ \\begin{array}{c} x_{\\mathrm{right}}  \\\\ y_{\\mathrm{right}} \\end{array}\\right]\n",
    "=\n",
    "\\left[ \\begin{array}{c} x + \\frac{L}{2} \\sin \\theta \\\\ \\ \\\\ y - \\frac{L}{2} \\cos \\theta \\end{array}\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gmjDBptZ2m_L",
   "metadata": {},
   "source": [
    "<figure id=\"fig:DDR-arbitrary-point\">\n",
    "<img src=\"https://github.com/gtbook/robotics/blob/main/Figures5/DDR-arbitrary-point.png?raw=1\" style=\"width:9cm\" alt=\"\">\n",
    "<figcaption>A Coordinate frame that is rigidly attached to a DDR.</figcaption>\n",
    "</figure>\n",
    "\n",
    "We can apply the same geometric analysis to any point on the robot.\n",
    "Consider a point $p$ that is rigidly attached to the robot, as shown in Figure [4](#fig:DDR-arbitrary-point).\n",
    "We can define the coordinates of $p$ with respect to the body-attached frame as\n",
    "$p^{\\mathrm{body}} = [p_x, p_y]^T$.\n",
    "If the robot is in configuration $q=(x,y.\\theta)$,\n",
    "then\n",
    "the x-y coordinates of $p$ with respect to the world coordinate frame are given by\n",
    "\\begin{equation}\n",
    "p^{\\mathrm{world}} =\n",
    "\\left[ \\begin{array}{c} \n",
    "x +p_x \\cos \\theta - p_y \\sin \\theta \\\\ \n",
    "y +p_x \\sin \\theta + p_y \\cos \\theta\n",
    " \\end{array}\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w0OhUZI3oswC",
   "metadata": {},
   "source": [
    "As shown in these examples, given a model of the robot,\n",
    "knowing the configuration $q = (x,y,\\theta)$ is sufficient to allow us to determine the position of any point on the robot.\n",
    "Nevertheless, the procedure we used above -- using simple planar geometry to infer positions in an ad hoc way -- is not\n",
    "so satisfying.\n",
    "Furthermore, our choice to represent orientation using $\\theta \\in [0,2\\pi)$ also has some problems.\n",
    "Mainly these problems are due to wrap-around at $\\theta = 2\\pi$.\n",
    "Suppose, for example, that the orientation of the robot is $2\\pi - \\epsilon$ for any $\\epsilon > 0$.\n",
    "If the robot rotates in the positive direction, we will see large change in $\\theta$.\n",
    "In fact, no matter how small we make $\\epsilon$, the change in $\\theta$ will be approximately $2\\pi$ when the\n",
    "wrap-around happens.\n",
    "Therefore, our mapping from the actual robot orientation to the representation by $\\theta$ is not continuous.\n",
    "This causes lots of problems, both mathematically and for implementations in code.\n",
    "For now, we will use GTSAM to deal with these difficulties,\n",
    "but in the next chapter we will introduce homogeneous transformations, which provide a solution to all of these difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xvO9IjdhYiUF",
   "metadata": {},
   "source": [
    "## Configurations in GTSAM\n",
    "\n",
    "In GTSAM, we use the class `gtsam.Pose2` to represent a configuration $q = (x,y,\\theta)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TQuWx3jaQch1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose: (12.4, 42.5, 0.785398)\n",
      "with x=12.4, y=42.5, theta=0.7853981633974482\n"
     ]
    }
   ],
   "source": [
    "pose = gtsam.Pose2(12.4, 42.5, math.radians(45))\n",
    "print(f\"pose: {pose}with x={pose.x()}, y={pose.y()}, theta={pose.theta()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iYyqVKbscNBS",
   "metadata": {},
   "source": [
    "{raw:tex}`\\noindent`\n",
    "Note that internally we represent poses using radians, hence the ugly looking number above. Often, it makes sense to specify *and* display angles in degrees, which makes specifying poses and debugging code easier. Hence, we also provide a \"pretty\" version that does the conversion for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GTVL3B859N73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(x=12.4, y=42.5, theta=45.0)"
      ],
      "text/plain": [
       "<gtbook.display.pretty at 0x107a98400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty(pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DNInTYxbC3vq",
   "metadata": {},
   "source": [
    "{raw:tex}`\\noindent`\n",
    "Using a real number $\\theta$ to represent orientation, while convenient and familiar, is *not* ideal as numbers that are offset by 360 degrees represent the same orientation. In other words, there is *not* a one-to-one relationship between orientation and its representation as a float value. Hence, internally GTSAM stores the orientation as *two* numbers, the unit vector $(\\cos\\theta,\\sin\\theta)$, which *is* a unique representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u2M_tiZeepY_",
   "metadata": {},
   "source": [
    "## Densities over Pose\n",
    "\n",
    "> We also need to think about probability densities over poses. \n",
    "\n",
    "It is conceptually easy to extend the *finite element* approximation to include orientation: just discretize $\\theta$ using some chosen resolution, e.g., one bin for every 5 degrees. However, one thing to keep in mind is that angles *wrap*. Hence, the topology of the \"map\" in the orientation dimension is like a circle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qOTrnD8Vqy1a",
   "metadata": {},
   "source": [
    "A sampling-based representation is *much* easier: we just add a value $\\theta$ to each sample, or, even better, uses `Pose2` samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x6hLIb0b1fU4",
   "metadata": {},
   "source": [
    "Finally, Gaussian densities over pose/orientation are not actually trivial to reason over, and we will postpone discussion of this to the next chapter."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "S51_diffdrive_state.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "latex_metadata": {
   "affiliation": "Georgia Institute of Technology",
   "author": "Frank Dellaert and Seth Hutchinson",
   "title": "Introduction to Robotics"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
