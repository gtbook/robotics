{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "tags": [
     "no-tex"
    ]
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gtbook/robotics/blob/main/S70_drone_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JoW4C_OkOMhe",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U gtbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "10-snNDwOSuC",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# no imports\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nAvx4-UCNzt2"
   },
   "source": [
    "# Autonomous Drones in 3D\n",
    "\n",
    "> Flying cameras and smooth motion planning.\n",
    "\n",
    "<img src=\"Figures7/S70-Autonomous_camera_drone-06.jpg\" alt=\"Splash image with ominous looking steampunk drone\" width=\"60%\" align=center style=\"vertical-align:middle;margin:10px 0px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nAvx4-UCNzt2"
   },
   "source": [
    "**Unmanned Aerial Vehicles** (UAVs) take autonomy into the next dimension: into three dimensions, to be exact. Whereas autonomous vehicles are bound to earth, UAVs take to the air. Hence, their perception and planning problems are fundamentally harder in a geometric sense. On the other hand, our airspace is currently much sparser than our roads are, and thus dynamic obstacle avoidance is less of an issue.\n",
    "\n",
    "In this chapter we will concentrate on a very popular class of UAVs: quadrotors. These are craft equipped with four actuated rotors that allow for very simple control algorithms, yet achieving very agile flight. Because the quadrotor design is cheap to manufacture and there is a large market for camera drones, most quadrotor vehicles have a rather small form factor and are designed to be easily portable. Sometimes this segment of the UAV market is designated as **Micro Aerial Vehicles** or MAVs, a term we will use throughout this chapter.\n",
    "\n",
    "After an initial discussion on how to represent the state of a quadrotor, we discuss how exactly to model flight and actions to control flight. For sensing we introduce a new sensor: the inertial measurement unit. We wil use that sensor and again use cameras, but now focused on **3D reconstruction** of the scene from a moving camera. This will require us to introduce some more mathematical tools, but almost the same tools can be used in order to *plan* in 3D, via **trajectory optimization**. Finally, in the learning section we focus on a hot new deep-learning-based 3D reconstruction technique: Neural Radiance Fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In summary, in this chapter we will cover the following topics:\n",
    "\n",
    "- 7.1 State:\t\tWe talk about 3D geometry and define the space $SO(3)$ of 3D rotations and the space $SE(3)$ of 3D rigid poses/transformations.\n",
    "- 7.2 Actuators: \tWe discuss the mathematics of quad-rotor flight, paying particular attention to the different 3D coordinate frames involved, and introduce the equations of 3D motion.\n",
    "- 7.3 Sensors: \t    We introduce a new sensor, the inertial measurement unit, and also discuss calibrated stereo cameras.\n",
    "- 7.4 Perception: \tUsing these sensors, we use factor graphs to fuse inertial and visual information in a technique called *Visual SLAM*.\n",
    "- 7.5 Planning: \tWe also use factor graphs to *plan* trajectories for MAVs, introducing trajectory optimization.\n",
    "- 7.6 Learning:     Finally, we discuss a deep-learning based approach to ontain a 3D reconstruction of an unknown environment from images: Neural Radiance Fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "S11_sorter_state.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "latex_metadata": {
   "affiliation": "Georgia Institute of Technology",
   "author": "Frank Dellaert and Seth Hutchinson",
   "title": "Introduction to Robotics"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
