
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>4.6. Some System Identification &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S46_logistics_learning';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4.7. Chapter Summary" href="S47_logistics_summary.html" />
    <link rel="prev" title="4.5. Planning for Logistics" href="S45_logistics_planning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Introduction to Robotics and Perception - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S27_sorter_summary.html">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S46_logistics_learning.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Some System Identification</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-parameter-estimation">4.6.1. Maximum Likelihood Parameter Estimation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-code-example">4.6.2. ML Code Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extending-to-multi-dimensional-systems">4.6.3. Extending to multi-dimensional systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-linear-regression">4.6.4. Multivariate Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-ml-code-example">4.6.5. Multivariate ML Code Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application-motion-model-estimation">4.6.6. Application: Motion Model Estimation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-maximization">4.6.7. Expectation Maximization</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="some-system-identification">
<h1><span class="section-number">4.6. </span>Some System Identification<a class="headerlink" href="#some-system-identification" title="Link to this heading">#</a></h1>
<p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S46_logistics_learning.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<blockquote id="index-0">
<div><p>We can “learn” measurement and motion models.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S46-Warehouse_robots-09.jpg"><img alt="Splash image with various evolutions of warehouse robots" class="align-center" src="_images/S46-Warehouse_robots-09.jpg" style="width: 40%;" /></a>
<p>In this section, we will limit ourselves to learning linear conditional Gaussians from data.
In Section 4.1, we discussed three different ways to represent densities over a two dimensional state
<span class="math notranslate nohighlight">\(x\in\mathbb{R}^2\)</span>: Gaussian densities, finite element approximations, and samples.
In Section 4.4 we presented three different Bayes filters stemming from each of these choices.
However, in each case the motion model was the same: a conditional Gaussian where the mean was a <em>linear</em> function of the previous state. In this section we will investigate whether we can learn both the linear mapping as well as the noise parameters, from data.</p>
<section id="maximum-likelihood-parameter-estimation">
<h2><span class="section-number">4.6.1. </span>Maximum Likelihood Parameter Estimation<a class="headerlink" href="#maximum-likelihood-parameter-estimation" title="Link to this heading">#</a></h2>
<p>Let us first consider a one dimensional system (i.e., <span class="math notranslate nohighlight">\(x_k \in \mathbb{R}\)</span> is a scalar),
and a sensor model that is linear with additive Gaussian noise:</p>
<div class="amsmath math notranslate nohighlight" id="equation-503d675c-1d2d-4be0-b40b-064a3a21dab6">
<span class="eqno">(4.51)<a class="headerlink" href="#equation-503d675c-1d2d-4be0-b40b-064a3a21dab6" title="Permalink to this equation">#</a></span>\[\begin{equation}
z_k = h(x_k) + n_k = C x_k + n_k
\end{equation}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(n_k\)</span> denotes zero-mean, Gaussian noise with covariance <span class="math notranslate nohighlight">\(R\)</span>.</p>
<p>In the one dimensional case, both <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(R=\sigma^2\)</span> are scalars, and estimating them will be similar to the Gaussian parameter estimation from Section 2.6. Remember that there we estimated a sample mean <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> from a set of <span class="math notranslate nohighlight">\(N\)</span> data points, by simply computing the average of the data values:</p>
<div class="amsmath math notranslate nohighlight" id="equation-e5bb6672-8192-4132-b144-ab452d7b612c">
<span class="eqno">(4.52)<a class="headerlink" href="#equation-e5bb6672-8192-4132-b144-ab452d7b612c" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{\mu} = \frac{1}{N} \sum_i z_i.
\end{equation}\]</div>
<p>The underlying reason is that this minimizes the negative log likelihood (nll) of <span class="math notranslate nohighlight">\(\mu\)</span> given the data <span class="math notranslate nohighlight">\(X\)</span> by</p>
<div class="amsmath math notranslate nohighlight" id="equation-98c8ea05-a59e-4822-8c54-370ff72ade2f">
<span class="eqno">(4.53)<a class="headerlink" href="#equation-98c8ea05-a59e-4822-8c54-370ff72ade2f" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{\mu} = \arg \min_\mu \sum_i \text{nll}(\mu; z_i) = \arg \min_\mu \sum_i \frac{1}{2\sigma^2} (\mu - z_i)^2,
\end{equation}\]</div>
<p>hence this is a <em>maximum likelihood</em> (ML) estimator of <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>Suppose we are given a set of ground truth values <span class="math notranslate nohighlight">\(\{x_k\}\)</span> for the state along with corresponding
measurement values <span class="math notranslate nohighlight">\(\{z_k\}\)</span>.
If we generalize the scheme from Chapter 2, the negative log likelihood of <span class="math notranslate nohighlight">\(C\)</span> given the data for our measurement model becomes</p>
<div class="amsmath math notranslate nohighlight" id="equation-9f93c9d4-139b-4c89-9f22-ad8bcc564824">
<span class="eqno">(4.54)<a class="headerlink" href="#equation-9f93c9d4-139b-4c89-9f22-ad8bcc564824" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{C} = \arg \min_C \sum_k \text{nll}(C; x_k, z_k) = \arg \min_C \sum_k \frac{1}{2\sigma^2} (C x_k - z_k)^2.
\end{equation}\]</div>
<p>Taking the derivative with respect to <span class="math notranslate nohighlight">\(C\)</span> and setting to zero we have</p>
<div class="amsmath math notranslate nohighlight" id="equation-ac7a228d-c0f1-4cf2-b409-70bae8b67b2e">
<span class="eqno">(4.55)<a class="headerlink" href="#equation-ac7a228d-c0f1-4cf2-b409-70bae8b67b2e" title="Permalink to this equation">#</a></span>\[\begin{equation}
\sum_k x_k(\hat{C} x_k - z_k) = 0,
\end{equation}\]</div>
<p>yielding</p>
<div class="amsmath math notranslate nohighlight" id="equation-27ccff2c-d13e-412b-aaf9-a9d811420894">
<span class="eqno">(4.56)<a class="headerlink" href="#equation-27ccff2c-d13e-412b-aaf9-a9d811420894" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{C} = \frac{\sum_k x_k z_k}{\sum_k x_k^2}.
\end{equation}\]</div>
<p>Fitting the variance then be done using</p>
<div class="amsmath math notranslate nohighlight" id="equation-21527f73-7474-45ec-acb4-78fc9ad38ef6">
<span class="eqno">(4.57)<a class="headerlink" href="#equation-21527f73-7474-45ec-acb4-78fc9ad38ef6" title="Permalink to this equation">#</a></span>\[\begin{equation}
\widehat{\sigma^2} = \frac{1}{N-1} \sum_k (\hat{C} x_k - z_k)^2.
\end{equation} \]</div>
</section>
<section id="ml-code-example">
<h2><span class="section-number">4.6.2. </span>ML Code Example<a class="headerlink" href="#ml-code-example" title="Link to this heading">#</a></h2>
<p>Consider a one dimensional version of the warehouse problem in which the robot
moves only along the <span class="math notranslate nohighlight">\(x\)</span> axis.
Let us simulate some states randomly from the <span class="math notranslate nohighlight">\(x\)</span> direction in the warehouse, i.e., between 0 and 100 meters, and then the measurement <span class="math notranslate nohighlight">\(z\)</span> from those sampled <span class="math notranslate nohighlight">\(x\)</span> coordinates, and then plot them against each other:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Plot of location versus measured location. </span>
<span class="c1">#| label: fig:location_vs_measured_location</span>
<span class="n">C</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># scaling from meters to centimeters</span>
<span class="n">R</span> <span class="o">=</span> <span class="mi">30</span><span class="o">**</span><span class="mi">2</span>  <span class="c1"># 30 centimeter standard deviation</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># number of samples</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span> <span class="c1"># warehouse length</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">C</span><span class="o">*</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">R</span><span class="p">))</span>
<span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">Z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a3a751e7f0f9f4fff5717640f92fc2929e825886992dadbe8c97fbdb1536ff27.png" src="_images/a3a751e7f0f9f4fff5717640f92fc2929e825886992dadbe8c97fbdb1536ff27.png" />
</div>
</div>
<p>It is pretty clear that the slope is 100. Can our math corroborate?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimated_C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">*</span><span class="n">Z</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;estimated C = </span><span class="si">{</span><span class="n">estimated_C</span><span class="si">}</span><span class="s2"> (cm/m)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>estimated C = 100.04450962851038 (cm/m)
</pre></div>
</div>
</div>
</div>
<p>Pretty close! The variance and standard deviation are likewise well estimated:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimated_R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">estimated_C</span><span class="o">*</span><span class="n">X</span><span class="o">-</span><span class="n">Z</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;estimated R=</span><span class="si">{</span><span class="n">estimated_R</span><span class="si">}</span><span class="s2"> (cm^2), stddev=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">estimated_R</span><span class="p">)</span><span class="si">}</span><span class="s2"> (cm)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>estimated R=880.3803332903113 (cm^2), stddev=29.671203772181393 (cm)
</pre></div>
</div>
</div>
</div>
</section>
<section id="extending-to-multi-dimensional-systems">
<h2><span class="section-number">4.6.3. </span>Extending to multi-dimensional systems<a class="headerlink" href="#extending-to-multi-dimensional-systems" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>For multi-dimensional systems, if the undertainties for the various dimensions are independent, we can solve the parameter estimation problems independently.</p>
</div></blockquote>
<p>In the warehouse example, for the GPS-like sensor, we assumed that the <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> were measured directly and that the noise on them was uncorrelated, and that the noise for each dimension had variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.
When this assumption holds, the parameter estimation problem is to estimate the
independent 1D scaling factors <span class="math notranslate nohighlight">\(C_x\)</span> and <span class="math notranslate nohighlight">\(C_y\)</span>, and the scalar variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>
We can use the code above to do so for <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> independently.</p>
</section>
<section id="multivariate-linear-regression">
<h2><span class="section-number">4.6.4. </span>Multivariate Linear Regression<a class="headerlink" href="#multivariate-linear-regression" title="Link to this heading">#</a></h2>
<p>For more general measurement processes or motion models, we typically need heavier machinery. The scalar case above is an instance of <em>linear regression</em>, and it can be generalized to the multivariate case. Let us assume a multivariate linear measurement model</p>
<div class="amsmath math notranslate nohighlight" id="equation-ce320fef-9986-4197-89b8-d1c9f98cb4ba">
<span class="eqno">(4.58)<a class="headerlink" href="#equation-ce320fef-9986-4197-89b8-d1c9f98cb4ba" title="Permalink to this equation">#</a></span>\[\begin{equation}
z_k = H x_k + n_k
\end{equation}\]</div>
<p>where now <span class="math notranslate nohighlight">\(z_k\in\mathbb{R}^m\)</span>, <span class="math notranslate nohighlight">\(x_k\in\mathbb{R}^n\)</span>, and <span class="math notranslate nohighlight">\(H\)</span> an <span class="math notranslate nohighlight">\(m \times n\)</span> matrix. Again, <span class="math notranslate nohighlight">\(n_k\)</span> is assumed zero mean Gaussian, with covariance matrix <span class="math notranslate nohighlight">\(R\)</span>.</p>
<p>The negative log likelihood of <span class="math notranslate nohighlight">\(H\)</span> given the data for our measurement model is</p>
<div class="amsmath math notranslate nohighlight" id="equation-8850dabb-8017-4024-a1a5-98e69535541a">
<span class="eqno">(4.59)<a class="headerlink" href="#equation-8850dabb-8017-4024-a1a5-98e69535541a" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{H} = \arg \min_H \sum_k \text{nll}(H; x_k, z_k) = \arg \min_H \sum_k \frac{1}{2} (H x_k - z_k)^T R^{-1}(H x_k - z_k).
\end{equation}\]</div>
<p>Unfortunately, the estimation process for arbitrary <span class="math notranslate nohighlight">\(R\)</span> is out of scope for this text. But if we assume <em>isotropic</em> noise with covariance matrix <span class="math notranslate nohighlight">\(I \sigma^2\)</span>, then the optimization problem simplifies to</p>
<div class="amsmath math notranslate nohighlight" id="equation-7d1c924c-ca86-41de-ad22-4ad7c6f4b6ec">
<span class="eqno">(4.60)<a class="headerlink" href="#equation-7d1c924c-ca86-41de-ad22-4ad7c6f4b6ec" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{H} = \arg \min_H \frac{1}{2\sigma^2} \sum_k \sum_i (H_i x_k - z_{ki})^2,
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(H_i\)</span> is the <span class="math notranslate nohighlight">\(i^th\)</span> row of <span class="math notranslate nohighlight">\(H\)</span>. Making use of the fact that the scalar <span class="math notranslate nohighlight">\(H_i x_k\)</span> can be re-written as <span class="math notranslate nohighlight">\(x_k^T H_i^T\)</span>, and then setting the derivative with respect to <span class="math notranslate nohighlight">\(H_i^T\)</span> to zero we have, for all <span class="math notranslate nohighlight">\(i\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3a054540-c226-435f-a5ef-3f6bb0f7ed6b">
<span class="eqno">(4.61)<a class="headerlink" href="#equation-3a054540-c226-435f-a5ef-3f6bb0f7ed6b" title="Permalink to this equation">#</a></span>\[\begin{equation}
\sum_k x_k (x_k^T \hat{H}_i^T - z_{ki}) = 0,
\end{equation}\]</div>
<p>yielding the following expression for the <span class="math notranslate nohighlight">\(i^{th}\)</span> row of <span class="math notranslate nohighlight">\(H\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0fb1a2cf-78d6-4764-8409-f84039b88f75">
<span class="eqno">(4.62)<a class="headerlink" href="#equation-0fb1a2cf-78d6-4764-8409-f84039b88f75" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{H}_i^T = (\sum_k x_k x_k^T)^{-1} \sum_k x_k z_{ki}.
\end{equation}\]</div>
<p>Note the resemblance with the scalar case, but be mindful that the quantity in parentheses is an <span class="math notranslate nohighlight">\(n\times n\)</span> matrix whose inverse will exist only if its rank is equal to the dimensionality of the system, <span class="math notranslate nohighlight">\(n\)</span>.
This rank condition is farily easy to satisfy, and is essentially a requirement that the data set
be sufficiently rich.
It is interesting to note that the <span class="math notranslate nohighlight">\(i^{th}\)</span> row of <span class="math notranslate nohighlight">\(\hat{H}\)</span> is formed as sum of the input vectors <span class="math notranslate nohighlight">\(x_k\)</span>, weighted by the <span class="math notranslate nohighlight">\(i^{th}\)</span> element of the measurement. Finally, we can collect the above for all <span class="math notranslate nohighlight">\(i\)</span> and write:</p>
<div class="amsmath math notranslate nohighlight" id="equation-eb6caa46-5881-49be-8e38-33783536e1c2">
<span class="eqno">(4.63)<a class="headerlink" href="#equation-eb6caa46-5881-49be-8e38-33783536e1c2" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{H}^T = (\sum_k x_k x_k^T)^{-1} \sum_k x_k z_k^T.
\end{equation}\]</div>
<p>After this, we can again recover the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> by</p>
<div class="amsmath math notranslate nohighlight" id="equation-b2440038-f2f0-45c6-8ca4-4940c37cdb52">
<span class="eqno">(4.64)<a class="headerlink" href="#equation-b2440038-f2f0-45c6-8ca4-4940c37cdb52" title="Permalink to this equation">#</a></span>\[\begin{equation}
\widehat{\sigma^2} = \frac{1}{(m N-m n)} \sum_k \sum_i |\hat{H}_i x_k - z_{ki}|^2.
\end{equation}\]</div>
<p>in which <span class="math notranslate nohighlight">\(N\)</span> is the number of data points.
Above we would divide by <span class="math notranslate nohighlight">\(m N\)</span> as that is how many elements there are in the double sum. However, to get an unbiased estimate we need to subtract <span class="math notranslate nohighlight">\(mn\)</span> from the denominator as that is how many entries we already estimated with <span class="math notranslate nohighlight">\(H\)</span>.</p>
</section>
<section id="multivariate-ml-code-example">
<h2><span class="section-number">4.6.5. </span>Multivariate ML Code Example<a class="headerlink" href="#multivariate-ml-code-example" title="Link to this heading">#</a></h2>
<p>Let us simulate some <em>2D</em> states randomly in the warehouse, and multiply with a random <span class="math notranslate nohighlight">\(3\times 2\)</span> <span class="math notranslate nohighlight">\(H\)</span> matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">],[</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">],[</span><span class="mi">50</span><span class="p">,</span><span class="mi">60</span><span class="p">]])</span> <span class="c1"># scaling from meters to centimeters</span>
<span class="n">R</span> <span class="o">=</span> <span class="mi">30</span><span class="o">**</span><span class="mi">2</span>  <span class="c1"># 30 centimeter standard deviation</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># number of samples</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">50</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span> <span class="c1"># warehouse dimensions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">R</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The multivariate estimator:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">H_transpose</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">@</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">Z</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">H_optimal</span> <span class="o">=</span> <span class="n">H_transpose</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;H_optimal=</span><span class="se">\n</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">H_optimal</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>H_optimal=
[[ 9.88 20.18]
 [30.03 40.  ]
 [49.96 59.94]]
</pre></div>
</div>
</div>
</div>
<p>Pretty close! And the estimate for the standard deviation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">H_optimal</span> <span class="o">@</span> <span class="n">X</span> <span class="o">-</span> <span class="n">Z</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">N</span><span class="o">-</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>30.686358139314535
</pre></div>
</div>
</div>
</div>
</section>
<section id="application-motion-model-estimation">
<h2><span class="section-number">4.6.6. </span>Application: Motion Model Estimation<a class="headerlink" href="#application-motion-model-estimation" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Linear regression can be used to estimate all of the parameters of a general linear motion model.</p>
</div></blockquote>
<p>Assuming we have a dataset of triplets <span class="math notranslate nohighlight">\(x_k, u_k, x_{k+1}\)</span>, i.e., the current state <span class="math notranslate nohighlight">\(x_k\in\mathbb{R}^n\)</span>, the control <span class="math notranslate nohighlight">\(u_k\in\mathbb{R}^p\)</span>, and the next state <span class="math notranslate nohighlight">\(x_{k+1}\in\mathbb{R}^n\)</span>. Note the similarities with the reinforcement learning setup in Section 3.6! If we assume a <em>linear process model</em> then we should have:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5504dfe1-59a4-4801-b35d-d883697f4bc3">
<span class="eqno">(4.65)<a class="headerlink" href="#equation-5504dfe1-59a4-4801-b35d-d883697f4bc3" title="Permalink to this equation">#</a></span>\[\begin{equation}
x_{k+1} = A x_k + B u_k + w_k
\end{equation}\]</div>
<p>where typically the covariance on the <em>process noise</em> <span class="math notranslate nohighlight">\(w_k\)</span> is denoted as <span class="math notranslate nohighlight">\(Q\)</span>. We only have to note that we can write this in the form needed by the multivariate ML estimator, as</p>
<div class="amsmath math notranslate nohighlight" id="equation-cee31c68-24f8-4fd4-96d5-5b5feb5aea59">
<span class="eqno">(4.66)<a class="headerlink" href="#equation-cee31c68-24f8-4fd4-96d5-5b5feb5aea59" title="Permalink to this equation">#</a></span>\[\begin{equation}
x_{k+1} = \begin{bmatrix} A &amp; B \end{bmatrix} \begin{bmatrix} x_k \\ u_k \end{bmatrix} + w_k
\end{equation}\]</div>
<p>Again, we generate some random states, controls, and next states:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># number of samples</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">50</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span> <span class="c1"># states</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span> <span class="c1"># controls, zero mean, 5m standard deviation</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># 2 meter standard deviation</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="n">B</span> <span class="o">@</span> <span class="n">U</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">R</span><span class="p">))</span> <span class="c1"># the next state</span>
</pre></div>
</div>
</div>
</div>
<p>The multivariate estimator:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">XU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">X</span><span class="p">,</span><span class="n">U</span><span class="p">])</span>
<span class="n">XU</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4, 500)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">AB_transpose</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">XU</span> <span class="o">@</span> <span class="n">XU</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">@</span> <span class="p">(</span><span class="n">XU</span> <span class="o">@</span> <span class="n">Z</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">AB_optimal</span> <span class="o">=</span> <span class="n">AB_transpose</span><span class="o">.</span><span class="n">T</span>
<span class="n">A_optimal</span><span class="p">,</span> <span class="n">B_optimal</span> <span class="o">=</span> <span class="n">AB_optimal</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">],</span> <span class="n">AB_optimal</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;A_optimal=</span><span class="se">\n</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">A_optimal</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;B_optimal=</span><span class="se">\n</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">B_optimal</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A_optimal=
[[ 1. -0.]
 [ 0.  1.]]
B_optimal=
[[ 1.01 -0.01]
 [-0.01  1.  ]]
</pre></div>
</div>
</div>
</div>
<p>Pretty close! And the estimate for the standard deviation (note the changed denominator!):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">AB_optimal</span> <span class="o">@</span> <span class="n">XU</span> <span class="o">-</span> <span class="n">Z</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">N</span><span class="o">-</span><span class="mi">8</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.994820602112946
</pre></div>
</div>
</div>
</div>
</section>
<section id="expectation-maximization">
<h2><span class="section-number">4.6.7. </span>Expectation Maximization<a class="headerlink" href="#expectation-maximization" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>We can estimate unknown parameters even if we don’t have access to ground truth state values.</p>
</div></blockquote>
<p id="index-1">The above assumed that we had perfect knowledge of the state <span class="math notranslate nohighlight">\(x_k\)</span> at all times. But what if we only had access to the controls <span class="math notranslate nohighlight">\(U\)</span> and measurements <span class="math notranslate nohighlight">\(Z\)</span>? A natural idea is to try and estimate the states with the techniques from Section 4.4, and then somehow use the posterior density <span class="math notranslate nohighlight">\(p(X|U,Z)\)</span> to estimate any unknown parameters <span class="math notranslate nohighlight">\(\Theta\)</span>. However, the estimation problem itself <em>uses</em> the parameters, so we have a chicken and egg problem!</p>
<p>The <strong>expectation-maximization</strong> or <strong>EM algorithm</strong> is an algorithm that allows us to estimate measurement and motion models <em>even when the state is only observed from measurements</em>. We do need <em>some</em> initial estimate <span class="math notranslate nohighlight">\(\Theta^1\)</span> for the parameters <span class="math notranslate nohighlight">\(\Theta\)</span>, and the idea is to then alternate between two steps:</p>
<ul class="simple">
<li><p>E-step: calculate the density <span class="math notranslate nohighlight">\(p(X|U,Z;\Theta^t)\)</span> on hidden states <span class="math notranslate nohighlight">\(X\)</span>, <em>given</em> the guess <span class="math notranslate nohighlight">\(\Theta^t\)</span>.</p></li>
<li><p>M-Step: maximize the <em>expected</em> log-likelihood with respect to <span class="math notranslate nohighlight">\(\Theta^{t+1}\)</span> under this density.</p></li>
</ul>
<p id="index-2">We do not discuss the detailed derivations here, but we do want to mention that a particularly simple variant of EM is to use a particle filter in the E-step. We can then simply “pretend” that the samples form a large dataset, and perform the above estimation procedures in the M-step. This is an instance of a so-called <strong>Monte Carlo EM</strong> algorithm, and the amazing fact is that this then actually converges to an ML estimate for the unknown parameters <span class="math notranslate nohighlight">\(\Theta\)</span>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S45_logistics_planning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4.5. </span>Planning for Logistics</p>
      </div>
    </a>
    <a class="right-next"
       href="S47_logistics_summary.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4.7. </span>Chapter Summary</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-parameter-estimation">4.6.1. Maximum Likelihood Parameter Estimation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-code-example">4.6.2. ML Code Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extending-to-multi-dimensional-systems">4.6.3. Extending to multi-dimensional systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-linear-regression">4.6.4. Multivariate Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-ml-code-example">4.6.5. Multivariate ML Code Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application-motion-model-estimation">4.6.6. Application: Motion Model Estimation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-maximization">4.6.7. Expectation Maximization</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>