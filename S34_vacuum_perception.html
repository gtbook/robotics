
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.4. Perception with Graphical Models &#8212; Introduction to Robotics and Perception</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3.5. Markov Decision Processes" href="S35_vacuum_decision.html" />
    <link rel="prev" title="3.3. Dynamic Bayes Nets" href="S33_vacuum_sensing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-312077-7', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Robotics and Perception</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction to Robotics and Perception
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S10_introduction.html">
   1. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S11_intro_state.html">
     1.1. Representing State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S12_intro_actions.html">
     1.2. Robot Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S13_intro_sensing.html">
     1.3. Sensing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S14_intro_perception.html">
     1.4. Perception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S15_intro_decision.html">
     1.5. Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S16_intro_learning.html">
     1.6. Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S20_sorter_intro.html">
   2. A Trash Sorting Robot
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S21_sorter_state.html">
     2.1. Modeling the World State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S22_sorter_actions.html">
     2.2. Actions for Sorting Trash
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S23_sorter_sensing.html">
     2.3. Sensors for Sorting Trash
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S24_sorter_perception.html">
     2.4. Perception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S25_sorter_decision_theory.html">
     2.5. Decision Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S26_sorter_learning.html">
     2.6. Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="S30_vacuum_intro.html">
   3. A Robot Vacuum Cleaner
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="S31_vacuum_state.html">
     3.1. Modeling the State of the Vacuum Cleaning Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S32_vacuum_actions.html">
     3.2. Actions over time
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S33_vacuum_sensing.html">
     3.3. Dynamic Bayes Nets
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.4. Perception with Graphical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S35_vacuum_decision.html">
     3.5. Markov Decision Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S36_vacuum_RL.html">
     3.6. Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S40_logistics_intro.html">
   4. Warehouse Robots in 2D
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S41_logistics_state.html">
     4.1. Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S42_logistics_actions.html">
     4.2. Moving in 2D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S43_logistics_sensing.html">
     4.3. Sensor Models with Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S44_logistics_perception.html">
     4.4. Localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S45_logistics_planning.html">
     4.5. Planning for Logistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S46_logistics_learning.html">
     4.6. Some System Identification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S50_diffdrive_intro.html">
   5. A Mobile Robot With Simple Kinematics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S51_diffdrive_state.html">
     5.1. State Space for a Differential Drive Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S52_diffdrive_actions.html">
     5.2. Motion Model for the Differential Drive Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S53_diffdrive_sensing.html">
     5.3. Robot Vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S54_diffdrive_perception.html">
     5.4. Computer Vision 101
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S55_diffdrive_planning.html">
     5.5. Path Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S56_diffdrive_learning.html">
     5.6. Deep Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S60_driving_intro.html">
   6. Autonomous Vehicles
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S61_driving_state.html">
     6.1. Planar Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S62_driving_actions.html">
     6.2. Kinematics for Driving
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S63_driving_sensing.html">
     6.3. Sensing for Autonomous Vehicles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S64_driving_perception.html">
     6.4. SLAM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S65_driving_planning.html">
     6.5. Planning for Autonomous Driving.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S66_driving_DRL.html">
     6.6. Deep Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S70_drone_intro.html">
   7. Autonomous Drones in 3D
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S71_drone_state.html">
     7.1. Moving in Three Dimensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S72_drone_actions.html">
     7.2. Multi-rotor Aircraft
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S73_drone_sensing.html">
     7.3. Sensing for Drones
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/S34_vacuum_perception.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/gtbook/robotics"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS34_vacuum_perception.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/gtbook/robotics/main?urlpath=tree/S34_vacuum_perception.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference-in-bayes-nets">
   3.4.1. Inference in Bayes Nets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#full-posterior-inference">
     3.4.1.1. Full Posterior Inference
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-probably-explanation">
     3.4.1.2. Maximum Probably Explanation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#efficiency-not">
     3.4.1.3. Efficiency (Not!)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-a-posteriori-estimation">
     3.4.1.4. Maximum a Posteriori estimation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercises">
     3.4.1.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hidden-markov-models">
   3.4.2. Hidden Markov Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-robot-hmm">
     3.4.2.1. Example: Robot HMM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-inference-in-hmms">
   3.4.3. Naive Inference in HMMs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#factor-graphs">
   3.4.4. Factor Graphs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-bayes-nets-into-factor-graphs">
   3.4.5. Converting Bayes Nets into Factor Graphs.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise">
     3.4.5.1. Exercise
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#factor-graphs-in-gtsam">
     3.4.5.2. Factor Graphs in GTSAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#computing-with-factor-graphs">
   3.4.6. Computing with Factor Graphs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-mpe-with-gtsam">
     3.4.6.1. Naive MPE with GTSAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-max-product-algorithm-for-hmms">
   3.4.7. The Max-Product Algorithm for HMMs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#eliminating-x-1">
     3.4.7.1. Eliminating
     <span class="math notranslate nohighlight">
      \(X_1\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#eliminating-x-2">
     3.4.7.2. Eliminating
     <span class="math notranslate nohighlight">
      \(X_2\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#eliminating-x-3">
     3.4.7.3. Eliminating
     <span class="math notranslate nohighlight">
      \(X_3\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#back-substitution">
     3.4.7.4. Back-substitution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-max-product">
     3.4.7.5. Summary: Max-Product
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity">
     3.4.7.6. Complexity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#max-product-in-gtsam">
     3.4.7.7. Max-product in GTSAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sum-product-algorithm-for-hmms">
   3.4.8. The Sum-Product Algorithm for HMMs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sidebar">
     3.4.8.1. Sidebar
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sum-product-in-gtsam">
     3.4.8.2. Sum-Product in GTSAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gtsam-101">
   3.4.9. GTSAM 101
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Perception with Graphical Models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference-in-bayes-nets">
   3.4.1. Inference in Bayes Nets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#full-posterior-inference">
     3.4.1.1. Full Posterior Inference
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-probably-explanation">
     3.4.1.2. Maximum Probably Explanation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#efficiency-not">
     3.4.1.3. Efficiency (Not!)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-a-posteriori-estimation">
     3.4.1.4. Maximum a Posteriori estimation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercises">
     3.4.1.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hidden-markov-models">
   3.4.2. Hidden Markov Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-robot-hmm">
     3.4.2.1. Example: Robot HMM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-inference-in-hmms">
   3.4.3. Naive Inference in HMMs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#factor-graphs">
   3.4.4. Factor Graphs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-bayes-nets-into-factor-graphs">
   3.4.5. Converting Bayes Nets into Factor Graphs.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise">
     3.4.5.1. Exercise
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#factor-graphs-in-gtsam">
     3.4.5.2. Factor Graphs in GTSAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#computing-with-factor-graphs">
   3.4.6. Computing with Factor Graphs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-mpe-with-gtsam">
     3.4.6.1. Naive MPE with GTSAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-max-product-algorithm-for-hmms">
   3.4.7. The Max-Product Algorithm for HMMs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#eliminating-x-1">
     3.4.7.1. Eliminating
     <span class="math notranslate nohighlight">
      \(X_1\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#eliminating-x-2">
     3.4.7.2. Eliminating
     <span class="math notranslate nohighlight">
      \(X_2\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#eliminating-x-3">
     3.4.7.3. Eliminating
     <span class="math notranslate nohighlight">
      \(X_3\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#back-substitution">
     3.4.7.4. Back-substitution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-max-product">
     3.4.7.5. Summary: Max-Product
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complexity">
     3.4.7.6. Complexity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#max-product-in-gtsam">
     3.4.7.7. Max-product in GTSAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sum-product-algorithm-for-hmms">
   3.4.8. The Sum-Product Algorithm for HMMs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sidebar">
     3.4.8.1. Sidebar
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sum-product-in-gtsam">
     3.4.8.2. Sum-Product in GTSAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gtsam-101">
   3.4.9. GTSAM 101
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S34_vacuum_perception.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From section 3.2:</span>
<span class="n">wxyz</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;W&quot;</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">Z1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="p">[</span><span class="n">X1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="p">[</span><span class="n">Y1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="p">[</span><span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="s2">&quot;1/1&quot;</span><span class="p">)</span>

<span class="c1"># From Section 3.3:</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">light_levels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="perception-with-graphical-models">
<h1><span class="section-number">3.4. </span>Perception with Graphical Models<a class="headerlink" href="#perception-with-graphical-models" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>Perception for dynamic Bayes nets is equivalent to inference in hidden Markov models or HMMs.</p>
</div></blockquote>
<p><strong>This Section is still in draft mode and was released for adventurous spirits (and TAs) only.</strong></p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<div align='center'>
<img src='https://github.com/gtbook/robotics/blob/main/Art/steampunk/S34-iRobot%20vacuuming%20robot-02.jpg?raw=1' style='height:256 width:100%'/>
</div>
</div></div>
</div>
<p>Bayes nets are great for <em>modeling</em>, but for infering the state of the robot over time we need better data structures.
We first more formally define what we mean by inference, and introduce MAP and MPE inferemce.
We then define hidden Markov models, and highlight their connection with robot
localization over time.
We then show how to efficiently perform inference by converting any Bayes net (with evidence) to a factor graph.
We show both full posterior inference, MPE, and MAP estimation for HMMs.</p>
<div class="section" id="inference-in-bayes-nets">
<h2><span class="section-number">3.4.1. </span>Inference in Bayes Nets<a class="headerlink" href="#inference-in-bayes-nets" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Inference can mean full posterior inference, maximum probable explanation, or maximum a posteriori inference.</p>
</div></blockquote>
<p><strong>Inference</strong> is the process of obtaining knowledge about a subset of
variables given the known values for another subset of variables. In
this section we will talk about how to do inference when the joint
distribution is specified using a Bayes net, but we will not take
advantage of the sparse structure of the network. Hence, the algorithms
below are completely general, for any (discrete) joint probability
distribution, as long as you can evaluate the joint.</p>
<div class="section" id="full-posterior-inference">
<h3><span class="section-number">3.4.1.1. </span>Full Posterior Inference<a class="headerlink" href="#full-posterior-inference" title="Permalink to this headline">¶</a></h3>
<p>The simplest case occurs when we can <em>partition</em> the variables into two
sets: the hidden variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and the observed values
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>. Then we can simply apply Bayes’ rule, but now applied to
<em>sets</em> of variables, to obtain an expression for the posterior over the
hidden variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Using the “easy” version of Bayes’ law
we obtain</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})\propto P(\mathcal{X}, \mathcal{Z}=\mathfrak{z}), \]</div>
<p>where <span class="math notranslate nohighlight">\(\mathfrak{z}\)</span> is the set of observed values for all variables in
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">show</span><span class="p">(</span><span class="n">wxyz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S34_vacuum_perception_9_0.svg" src="_images/S34_vacuum_perception_9_0.svg" /></div>
</div>
<p>There is an easy algorithm to calculate the posterior distribution
above: simply enumerate all tuples <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> in a table, evaluate
<span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z}=\mathfrak{z})\)</span> for each one, and then
normalize. As an example, let us consider the Bayes net on W, X, Y, Z above,
and take <span class="math notranslate nohighlight">\(\mathcal{X}=(X, Y)\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Z}=(W, Z)\)</span>.
As before, let us assume that each variable can take on 10 different outcomes, and that
<span class="math notranslate nohighlight">\(\mathfrak{z}=(2, 7)\)</span>. The resulting table for
<span class="math notranslate nohighlight">\(P(X, Y|W=2, Z=7)\propto P(W=2, X, Y, Z=7)\)</span> is shown in the table below:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><em>x</em></p></th>
<th class="text-align:center head"><p><em>y</em></p></th>
<th class="text-align:center head"><p><em>P(W=2, X=x, Y=y, Z=7)</em></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>1</p></td>
<td class="text-align:center"><p>1</p></td>
<td class="text-align:center"><p><em>P(W=2|X=1, Y=1)P(X=1\Y=1, Z=7)P(Y=1\Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>1</p></td>
<td class="text-align:center"><p>2</p></td>
<td class="text-align:center"><p><em>P(W=2|X=1, Y=2)P(X=1|Y=2, Z=7)P(Y=2|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>…</p></td>
<td class="text-align:center"><p>…</p></td>
<td class="text-align:center"><p>…</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>10</p></td>
<td class="text-align:center"><p>9</p></td>
<td class="text-align:center"><p><em>P(W=2|X=10, Y=9)P(X=10|Y=9, Z=7)P(Y=9|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>10</p></td>
<td class="text-align:center"><p>10</p></td>
<td class="text-align:center"><p><em>P(W=2|X=10, Y=10)P(X=10|Y=10, Z=7)P(Y=10|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p></p></td>
<td class="text-align:center"><p></p></td>
<td class="text-align:center"><p><em><span class="math notranslate nohighlight">\(\sum_{x, y}\)</span>P(W=2, X=x, Y=y, Z=7)</em></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="maximum-probably-explanation">
<h3><span class="section-number">3.4.1.2. </span>Maximum Probably Explanation<a class="headerlink" href="#maximum-probably-explanation" title="Permalink to this headline">¶</a></h3>
<p>A common inference problem associated with Bayes nets is the <strong>most
probable explanation</strong> or MPE for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>: given the values
<span class="math notranslate nohighlight">\(\mathfrak{z}\)</span> for <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, what is the most probable joint
assignment to the other variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>? While the posterior
gives us the complete picture, the MPE is different in nature: it is a
single assignment of values to <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>:</p>
<div class="math notranslate nohighlight">
\[x^*_{MPE} = \arg \max_x P(\mathcal{X}|\mathcal{Z}=\mathfrak{z}).\]</div>
<p>For example, given
<span class="math notranslate nohighlight">\(\mathfrak{z}=(2, 7)\)</span>, the MPE for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> could be <span class="math notranslate nohighlight">\(X=3\)</span> and
<span class="math notranslate nohighlight">\(Y=6\)</span>. Note that to compute the MPE, we need not bother with
normalizing: we can simply find the maximum entry in the unnormalized
posterior values.</p>
</div>
<div class="section" id="efficiency-not">
<h3><span class="section-number">3.4.1.3. </span>Efficiency (Not!)<a class="headerlink" href="#efficiency-not" title="Permalink to this headline">¶</a></h3>
<p>In both these inference problems, the simple algorithm outlined above is
<em>not</em> efficient. In the example the table is 100 entries long, and in
general the number of entries is exponential in the size of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. However, when inspecting the entries in the table
there are already some obvious ways to save: for example, <span class="math notranslate nohighlight">\(P(Z=7)\)</span> is a
common factor in all entries, so clearly we should not even bother
multiplying it in. Below we will discuss methods to fully
exploit the structure of the Bayes net to perform efficient inference.</p>
<p>If we had an efficient way to do inference, an MPE estimate would be a
great way to estimate the trajectory of a robot over time. For example,
using the “robot” dynamic Bayes net example from the last section, let us
assume that we are given the value of all observations <span class="math notranslate nohighlight">\(O\)</span> and actions
<span class="math notranslate nohighlight">\(A\)</span>. Then the MPE would simply be a trajectory of robot states through
the grid. This is an example of robot localization over time, and is a
key capability of a mobile robot. However, it will have to wait until we
can do efficient inference.</p>
</div>
<div class="section" id="maximum-a-posteriori-estimation">
<h3><span class="section-number">3.4.1.4. </span>Maximum a Posteriori estimation<a class="headerlink" href="#maximum-a-posteriori-estimation" title="Permalink to this headline">¶</a></h3>
<p>Finally, another well known inference problem is the <strong>maximum a
posteriori</strong> or MAP estimate: given the values of some variables
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, what is the most probable joint assignment to a <em>subset</em>
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> of the other variables? In this case the variables are
partitioned into three sets: the variables of interest <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>,
the nuisance variables <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, and the observed variables
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>:</p>
<div class="math notranslate nohighlight">
\[x^*_{MAP} = \arg \max_x P(x|o) = \arg \max_x L(x; o) P(X)\]</div>
<p>We have</p>
<div class="math notranslate nohighlight">
\[
P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})=\sum_{\mathfrak{y}}P(\mathcal{X}, \mathcal{Y}=\mathfrak{y}|\mathcal{Z}=\mathfrak{z})\propto\sum_{\mathfrak{y}}P(\mathcal{X}, \mathcal{Y}=\mathfrak{y}, \mathcal{Z}=\mathfrak{z}).
\]</div>
<p>Finding a MAP estimate is more expensive than finding the MPE, as in
addition to enumerating all possible combinations of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> values, we now need to calculate
a possibly large number of sums, each exponential in the size of
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. In addition, the <em>number</em> of sums is
exponential in the size of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Below we will see that
while we can still exploit the Bayes net structure, MAP estimates are
fundamentally more expensive even in that case.</p>
</div>
<div class="section" id="exercises">
<h3><span class="section-number">3.4.1.5. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Show that in the example above, if we condition on known values for <span class="math notranslate nohighlight">\(\mathcal{Z}=(X,Y)\)</span>, the
posterior <span class="math notranslate nohighlight">\(P(W,Z|X,Y)\)</span> factors, and as a consequence we only have to
enumerate two tables of length 10, instead of a large table of
size 100.</p></li>
<li><p>Calculate the size of the table needed to enumerate the posterior
over the states <span class="math notranslate nohighlight">\(S\)</span> the robot dynamic Bayes net from the previous section,
given the value of all observations <span class="math notranslate nohighlight">\(O\)</span> and actions <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>Show that if we are given the states, inferring the actions is
actually quite efficient, even with the brute force enumeration.
Hint: this is similar to the first exercise above.</p></li>
</ol>
</div>
</div>
<div class="section" id="hidden-markov-models">
<h2><span class="section-number">3.4.2. </span>Hidden Markov Models<a class="headerlink" href="#hidden-markov-models" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>HMMs are a general framework for perception over time.</p>
</div></blockquote>
<p>Here we will generalize from robots to arbitrary state and observation spaces. In the previous section we discussed dynamic Bayes networks to model how a robot state evolves over time by taking actions, and how measurements result in a particular state. In this section we will ask <em>how we can recover the state of the robot given only the observations</em>, i.e. without knowing the states: the state is “hidden”. Here we will consider a general framework to anser this question.</p>
<p>A <strong>hidden Markov model</strong> or HMM is a dynamic Bayes net that has two
types of variables: states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.
The states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> are connected sequentially and satisfy the what
is called the <strong>Markov property</strong>: the probability of a state <span class="math notranslate nohighlight">\(X_{t}\)</span> is
only dependent on the value of the previous state <span class="math notranslate nohighlight">\(X_{t-1}\)</span>. As we saw before, we call a sequence of random variables with this property a <strong>Markov chain.</strong>
In addition, in an HMM we refer to the states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> as <em>hidden</em>
states, as typically we cannot directly observe their values. Instead,
they are indirectly observed through the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>,
where we have one measurement per hidden state. When these two
properties are satisfied, we call this probabilistic model a hidden
Markov model.</p>
<figure> 
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/hmm-v2.png?raw=1" id="fig:unrolledHMM" style="width:14cm" alt="">
<figcaption>An HMM, unrolled over three time-steps, represented by a Bayes net.</figcaption>
</figure>
<p>Figure
<a href="#fig:unrolledHMM" data-reference-type="ref" data-reference="fig:unrolledHMM">1</a>
shows an example of an HMM for three time steps, i.e..,
<span class="math notranslate nohighlight">\(\mathcal{X}=\{X_1, X_2, X_3\}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Z}=\{Z_1, Z_2, Z_3\}\)</span>. As we discussed, in a Bayes net
each node is associated with a conditional distribution: the Markov
chain has the prior <span class="math notranslate nohighlight">\(P(X_1)\)</span> and transition probabilities
<span class="math notranslate nohighlight">\(P(X_2|X_1)\)</span> and <span class="math notranslate nohighlight">\(P(X_3|X_2)\)</span>, whereas the measurements <span class="math notranslate nohighlight">\(Z_{t}\)</span>
depend only on the state <span class="math notranslate nohighlight">\(X_{t}\)</span>, modeled by measurement models
<span class="math notranslate nohighlight">\(P(Z_{t}|X_{t})\)</span>. In other words, the Bayes net encodes the following
joint distribution <span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z})\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X}, \mathcal{Z})=P(X_1)P(Z_1|X_1)P(X_2|X_1)P(Z_2|X_2)P(X_3|X_2)P(Z_3|X_3)\]</div>
<p>Note that we can also write this more succinctly as</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X}, \mathcal{Z})=P(\mathcal{Z}|\mathcal{X})P(\mathcal{X})\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X})=P(X_1, X_2, X_3)=P(X_1)P(X_2|X_1)P(X_3|X_2)\]</div>
<p>is the prior over state <em>trajectories</em>.</p>
<div class="section" id="example-robot-hmm">
<h3><span class="section-number">3.4.2.1. </span>Example: Robot HMM<a class="headerlink" href="#example-robot-hmm" title="Permalink to this headline">¶</a></h3>
<p>Let us re-create the dynamic Bayes net from the previous section here, with 3 time steps:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dbn</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">sensor_spec</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)):</span>
    <span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
<span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1/1/1/1/1&quot;</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">dbn</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S34_vacuum_perception_18_0.svg" src="_images/S34_vacuum_perception_18_0.svg" /></div>
</div>
</div>
</div>
<div class="section" id="naive-inference-in-hmms">
<h2><span class="section-number">3.4.3. </span>Naive Inference in HMMs<a class="headerlink" href="#naive-inference-in-hmms" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Inference is easy to implement naively, but hopelessly inefficient.</p>
</div></blockquote>
<p>In inference, we might want to infer the maximum probable explanation
(MPE) for the states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> given values
<span class="math notranslate nohighlight">\(\mathfrak{z}=\{z_1, z_2, z_3\}\)</span> for <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>. As we saw
before, one way to perform inference is to apply Bayes’ rule to obtain an expression for the <em>posterior</em> probability distribution over
the state trajectory <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, given the measurements
<span class="math notranslate nohighlight">\(\mathcal{Z}=\mathfrak{z}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
P(\mathcal{X}|\mathcal{Z}) &amp; \propto P(\mathcal{Z}=\mathfrak{z}|\mathcal{X})P(\mathcal{X}) \\
&amp; =L(\mathcal{X}; \mathcal{Z}=\mathfrak{z})P(\mathcal{X})\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(P(\mathcal{X})\)</span> is the trajectory prior
and the <strong>likelihood</strong> <span class="math notranslate nohighlight">\(L(\mathcal{X}; \mathcal{Z}=\mathfrak{z})\)</span> of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> given <span class="math notranslate nohighlight">\(\mathcal{Z}=\mathfrak{z}\)</span> is defined as beforeas a  function of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\mathcal{X}; \mathcal{Z}=\mathfrak{z}) &amp; \doteq P(\mathcal{Z}=\mathfrak{z}|\mathcal{X})\\
&amp; =P(z_1|X_1)P(z_2|X_2)P(z_3|X_3)\\
&amp; =L(X_1; Z_1)L(X_2; Z_2)L(X_3; Z_3)\end{aligned}
\end{split}\]</div>
<p>Hence, a naive implementation for finding the <strong>most probable
explanation</strong> (MPE) for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> would tabulate all possible
trajectories <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and calculate the posterior <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span> for each one.
Unfortunately the number of entries in this giant table is
<em>exponential</em> in the number of states. Not only is this computationally
prohibitive for long trajectories, but intuitively it is clear that for
many of these trajectories we are computing the same values over and
over again. In fact, there are three different approaches to improve on
this:</p>
<ol class="simple">
<li><p>Branch &amp; bound</p></li>
<li><p>Dynamic programming</p></li>
<li><p>Inference using factor graphs</p></li>
</ol>
<p>Branch and bound is a powerful technique but will not generalize to
continuous variables, like the other two approaches will. And, we will
see that dynamic programming, which underlies the classical inference
algorithms in the HMM literature, is just a special case of the last
approach. Hence, here we will dive in and immediately go for the most
general approach: inference in factor graphs.</p>
</div>
<div class="section" id="factor-graphs">
<h2><span class="section-number">3.4.4. </span>Factor Graphs<a class="headerlink" href="#factor-graphs" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Factor graphs are <em>the</em> correct representation in which do inference.</p>
</div></blockquote>
<p>We first introduce the notion of factors.
Again referring to the example from Figure
<a href="#fig:unrolledHMM" data-reference-type="ref" data-reference="fig:unrolledHMM">1</a>,
let us consider the posterior.
Since the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> are <em>known</em>, the posterior is
proportional to the product of six <strong>factors</strong>, three of which derive
from the the Markov chain, and three are likelihood factors as defined
before:</p>
<div class="math notranslate nohighlight">
\[
P(\mathcal{X}|\mathcal{Z})\propto P(X_1)L(X_1; z_1)P(X_2|X_1)L(X_2; z_2)P(X_3|X_2)L(X_3; z_3)
\]</div>
<p>Some of these factors are unary factors, and some are binary factors.
In particular, above some of the factors depend on just one hidden variable,
for example <span class="math notranslate nohighlight">\(L(X_2; z_2)\)</span>, whereas others depend on two variables, e.g., the
transition model <span class="math notranslate nohighlight">\(P(X_3|X_2)\)</span>.
Measurements are not counted here,
because once we are <em>given</em> the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, they merely
function as known parameters in the likelihoods <span class="math notranslate nohighlight">\(L(X_{t}; z_{t})\)</span>, which
are seen as functions of <em>just</em> the state <span class="math notranslate nohighlight">\(X_{t}\)</span>.</p>
<figure>
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/fg-v2.png?raw=1" id="fig: HMM-FG" style="width:60.0%" alt="">
<figcaption>An HMM with observed measurements, unrolled over time, represented as a factor graph.</figcaption>
</figure>
<p>This motivates a different graphical model, a <strong>factor graph</strong>, in which
we only represent the <em>hidden</em> variables <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, and <span class="math notranslate nohighlight">\(X_3\)</span>,
connected to factors that encode probabilistic information on them. For
our example with three hidden states, the corresponding factor graph is
shown in Figure
<a href="#fig: HMM-FG" data-reference-type="ref" data-reference="fig: HMM-FG">2</a> above.
It should be clear from the figure that the connectivity of a factor
graph encodes, for each factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span>, which subset of variables
<span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span> it depends on. We write:</p>
<div class="math notranslate nohighlight">
\[
\phi(\mathcal{X})=\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)\phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\]</div>
<p>where the factors above are defined to correspond one-to-one to the six factors in the posterior,
e.g.,</p>
<div class="math notranslate nohighlight">
\[\phi_6(X_3)\doteq L(X_3; z_3).\]</div>
<p>All measurements are associated with unary factors, whereas the Markov chain is
associated mostly with binary factors, with the exception of the unary
factor <span class="math notranslate nohighlight">\(\phi_1(X_1)\)</span>. Note that in defining the factors we can omit
any normalization factors, which in many cases results in computational
savings.</p>
<p>Formally a factor graph is a bipartite graph
<span class="math notranslate nohighlight">\(F=(\mathcal{U}, \mathcal{V}, \mathcal{E})\)</span> with two types of nodes:
<strong>factors</strong> <span class="math notranslate nohighlight">\(\phi_{i}\in\mathcal{U}\)</span> and <strong>variables</strong>
<em><span class="math notranslate nohighlight">\(X_{j}\in\mathcal{V}\)</span>.</em> Edges <span class="math notranslate nohighlight">\(e_{ij}\in\mathcal{E}\)</span> are always between
factor nodes and variables nodes. The set of random variable nodes
adjacent to a factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span> is written as <span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span>. With
these definitions, a factor graph <span class="math notranslate nohighlight">\(F\)</span> defines the factorization of a
global function <span class="math notranslate nohighlight">\(\phi(\mathcal{X})\)</span> as</p>
<div class="math notranslate nohighlight">
\[\phi(\mathcal{X})=\prod_{i}\phi_{i}(\mathcal{X}_{i}).\]</div>
<p>In other words, the independence relationships are encoded by the edges
<span class="math notranslate nohighlight">\(e_{ij}\)</span> of the factor graph, with each factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span> a function of
<em>only</em> the variables <span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span> in its adjacency set. As example,
for the factor graph in Figure
<a href="#fig: HMM-FG" data-reference-type="ref" data-reference="fig: HMM-FG">2</a>
we have: $<span class="math notranslate nohighlight">\(\begin{aligned}
\mathcal{X}_1 &amp; =\{X_1\}\\
\mathcal{X}_2 &amp; =\{X_1\}\\
\mathcal{X}_3 &amp; =\{X_1, X_2\}\\
\mathcal{X}_4 &amp; =\{X_2\}\\
\mathcal{X}_5 &amp; =\{X_2, X_3\}\\
\mathcal{X}_6 &amp; =\{X_3\}\end{aligned}\)</span>$</p>
</div>
<div class="section" id="converting-bayes-nets-into-factor-graphs">
<h2><span class="section-number">3.4.5. </span>Converting Bayes Nets into Factor Graphs.<a class="headerlink" href="#converting-bayes-nets-into-factor-graphs" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>It is trivial to convert Bayes nets with given variables into factor graphs.</p>
</div></blockquote>
<figure>
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/hmm-v2.png?raw=1" id="fig:conversion" style="width:12cm" alt="">
<figcaption>Bayes net representation of an HMM.</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/fg-v2.png?raw=1" id="fig:conversion" style="width:14cm" alt="">
<figcaption>Conversion of HMM above to a factor graph, where measurements are known.</figcaption>
</figure>
<p>Every Bayes net can be trivially converted to a factor graph, as shown above.
Recall that every node in a Bayes net denotes a conditional density on the
corresponding variable and its parent nodes. Hence, the conversion is
quite simple: every Bayes net node splits in <em>both</em> a variable node and
a factor node in the corresponding factor graph. The factor is connected
to the variable node, as well as the variable nodes corresponding to the
parent nodes in the Bayes net. If some nodes in the Bayes net are
evidence nodes, i.e., they are given as known variables, we omit the
corresponding variable nodes: the known variable simply becomes a fixed
parameter in the corresponding factor.</p>
<div class="section" id="exercise">
<h3><span class="section-number">3.4.5.1. </span>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Convert the dynamic Bayes net from the previous section into a factor graph, assuming <em>no</em> known variables.</p></li>
<li><p>Finally, do the same again, but now assume the states are given. Reflect on the remarkable phenomenon that happens.</p></li>
</ol>
</div>
<div class="section" id="factor-graphs-in-gtsam">
<h3><span class="section-number">3.4.5.2. </span>Factor Graphs in GTSAM<a class="headerlink" href="#factor-graphs-in-gtsam" title="Permalink to this headline">¶</a></h3>
<p>Let us create the factor graph directly using GTSAM. Before we do, however, we need to instantiate the given actions and measurements, both of which are assumed known:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actions</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="s1">&#39;R&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="s1">&#39;U&#39;</span><span class="p">})</span>
<span class="n">measurements</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dark&#39;</span><span class="p">,</span> <span class="s1">&#39;medium&#39;</span><span class="p">,</span> <span class="s1">&#39;light&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now we create the factorgraph, first adding the prior <span class="math notranslate nohighlight">\(\phi(X_1)=P(X_1)\)</span> on <span class="math notranslate nohighlight">\(X_1\)</span>, then the binary factors <span class="math notranslate nohighlight">\(\phi(X_k, X_{k+1}) = P(X_{k+1}|X_k, A_k=a_k)\)</span>, and then the measurements likelihood factors <span class="math notranslate nohighlight">\(\phi(X_k; Z_k=z_k) \propto P(Z_k=z_k|X_k)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">graph</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteFactorGraph</span><span class="p">()</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1 1 1 1 1&quot;</span><span class="p">)</span>  <span class="c1"># \phi(X_1) = P(X_1)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">conditional</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
    <span class="n">conditional_a_k</span> <span class="o">=</span> <span class="n">conditional</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>  <span class="c1"># \phi(X,X+) = P(X+|X,A=a)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">conditional_a_k</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">measurement</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">measurements</span><span class="p">):</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">conditional</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">sensor_spec</span><span class="p">)</span>
    <span class="n">z_k</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">light_levels</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">measurement</span><span class="p">)</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="n">conditional</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">z_k</span><span class="p">)</span>  <span class="c1"># \phi(X) = P(Z=z|X)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S34_vacuum_perception_28_0.svg" src="_images/S34_vacuum_perception_28_0.svg" /></div>
</div>
<p>Note that discrete distributions and conditionals, like <span class="math notranslate nohighlight">\(P(X_0)\)</span> above, are perfectly fine factors, and in fact <em>derive</em> from the factor type in GTSAM. This is what allows us to add them directly the graph as is. Note that in a real implementation we might not take the detour to first construct the conditionals as above: we did so because they were conveniently available here, but typically we would construct factors directly.</p>
</div>
</div>
<div class="section" id="computing-with-factor-graphs">
<h2><span class="section-number">3.4.6. </span>Computing with Factor Graphs<a class="headerlink" href="#computing-with-factor-graphs" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>We can evaluate, optimize, and sample from factor graphs.</p>
</div></blockquote>
<p>Once we convert a Bayes net with evidence into a factor graph where the
evidence is all implicit in the factors, we can support a number of
different computations. First, given any factor graph defining an
unnormalized density <span class="math notranslate nohighlight">\(\phi(X)\)</span>, we can easily <strong>evaluate</strong> it for any
given value, by simply evaluating every factor and multiplying the
results. The factor graph represents the unnormalized posterior, i.e.,
<span class="math notranslate nohighlight">\(\phi(\mathcal{X})\propto P(\mathcal{X}|\mathcal{Z})\)</span>.</p>
<p>Evaluation opens up the way to <strong>optimization</strong>, e.g., finding the most probable
explanation or MPE, as we will do below. In the case of discrete
variables, graph search methods can be applied, but we will use a
different approach.</p>
<p>While local or global maxima of the posterior are often of most
interest, <strong>sampling</strong> from a probability density can be used to
visualize, explore, and compute statistics and expected values
associated with the posterior. However, the ancestral sampling method we
discussed earlier only applies to directed acyclic graphs. There are
however more general sampling algorithms that can be used for factor
graphs, more specifically Markov chain Monte Carlo (MCMC) methods. One
such method is Gibbs sampling, which proceeds by sampling one variable
at a time from its conditional density given all other variables it is
connected to via factors. This assumes that this conditional density can
be easily obtained, which is in fact true for discrete variables.</p>
<p>Below we use factor graphs as the organizing principle for probabilistic
inference. In later chapters we will expand their use to continuous
variables, and will see that factor graphs aptly describe the
independence assumptions and sparse nature of the large nonlinear
least-squares problems arising in robotics. But their usefulness extends
far beyond that: they are at the core of the sparse linear solvers we
use as building blocks, they clearly show the nature of filtering and
incremental inference, and lead naturally to distributed and/or parallel
versions of robotics.</p>
<div class="section" id="naive-mpe-with-gtsam">
<h3><span class="section-number">3.4.6.1. </span>Naive MPE with GTSAM<a class="headerlink" href="#naive-mpe-with-gtsam" title="Permalink to this headline">¶</a></h3>
<p>Because our factor graph is so small, it does not hurt to show off how easy it is to implement the naive algorithm. We just loop over all possible state trajectories, keep track of the</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mpe_value</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">mpe_trajectory</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">for</span> <span class="n">x1</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">x2</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x3</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
            <span class="n">trajectory</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">x1</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">x2</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">x3</span><span class="p">})</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">graph</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">mpe_value</span><span class="p">:</span>
                <span class="n">mpe_value</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">mpe_trajectory</span> <span class="o">=</span> <span class="n">trajectory</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;found MPE solution with value </span><span class="si">{</span><span class="n">mpe_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">mpe_trajectory</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>found MPE solution with value 0.3277:
</pre></div>
</div>
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Hallway</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="the-max-product-algorithm-for-hmms">
<h2><span class="section-number">3.4.7. </span>The Max-Product Algorithm for HMMs<a class="headerlink" href="#the-max-product-algorithm-for-hmms" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Max-product on HMMs, also known as the Viterbi algorithm, is a dynamic-programming algorithm for finding the MPE.</p>
</div></blockquote>
<p>In this section we discuss an algorithm that is much faster than the naive algorithm to find the MPE.
Given a factor graph, the <strong>max-product algorithm</strong> is an <span class="math notranslate nohighlight">\(O(n)\)</span> algorithm
to find the maximum probable explanation or MPE.
We will use the example from Figure
<a href="#fig: HMM-FG" data-reference-type="ref" data-reference="fig: HMM-FG">2</a>
to give the intuition. To find the MPE for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> we need to
<em>maximize</em> the product</p>
<div class="math notranslate nohighlight">
\[\phi(X_1, X_2, X_3)=\prod\phi_{i}(\mathcal{X}_{i})\]</div>
<p>i.e., the <strong>value</strong> of the factor graph.</p>
<p>Because the value of the factor graph is a product of factor values, we can compute its maximum recursively, dynamic programming style:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\max_\mathcal{X} \prod\phi_{i}(\mathcal{X}_{i})
&amp;= \max_{X_1, X_2, X_3} ~~~\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) &amp;\phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\ &amp;= \max_{X_2, X_3} ~~~\{ \max_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \} &amp;\phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\ &amp;= \max_{X_2, X_3} ~~~\tau(X_2) &amp;\phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\tau(X_2)\doteq \max_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)\)</span>. After we  recursively find the optimal values for <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(X_3\)</span>, we can recover <span class="math notranslate nohighlight">\(X_1\)</span> by</p>
<div class="math notranslate nohighlight">
\[
g_1(X_2) = \arg \max_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)
\]</div>
<p>where the <em>lookup table</em> can be created at the same time that we compute <span class="math notranslate nohighlight">\(\tau(X_2)\)</span>.</p>
<p>Below we use the factor graph to illustrate how the max-product algorithm
proceeds one variable at a time, using “Bayes-net-style” directed edges to represent the lookup tables <span class="math notranslate nohighlight">\(g_k(X_{k+1})\)</span>, and factors to represent the <span class="math notranslate nohighlight">\(\tau(.)\)</span> functions, as indeed they <em>are</em> factors. Because at every step, one variable is <em>eliminated</em> from the maximization, the max-product algorithm is in fact an instance of the <strong>elimination algorithm</strong>, which we will see pop up in many different guises.</p>
<p>We proceed from left to right, i.e. we start with state <span class="math notranslate nohighlight">\(X_1\)</span> and proceed until we
processed all states. We will tackle the three steps one by one in ths subsections below:</p>
<div class="section" id="eliminating-x-1">
<h3><span class="section-number">3.4.7.1. </span>Eliminating <span class="math notranslate nohighlight">\(X_1\)</span><a class="headerlink" href="#eliminating-x-1" title="Permalink to this headline">¶</a></h3>
<figure>
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/max-product-1.png?raw=1" style="width:60.0%" alt="">
<figcaption></figcaption>
</figure>
<p>We start by considering the first state <span class="math notranslate nohighlight">\(X_1\)</span>, and we form a <strong>product
factor</strong> <span class="math notranslate nohighlight">\(\phi(X_1, X_2)\)</span> that collects <em>only</em> the factors connected
to <span class="math notranslate nohighlight">\(X_1\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\phi(X_1, X_2)=\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2).
\]</div>
<p>When we use a factor in a product, we <em>remove</em> it from the original
factor graph. Note that because one of those factors, the state
transition model <span class="math notranslate nohighlight">\(\phi_3(X_1, X_2)\doteq P(X_2|X_1)\)</span>, is also
connected to the second state <span class="math notranslate nohighlight">\(X_2\)</span>, the product factor is a function
of <em>both</em> <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span>, i.e., it is a binary factor.</p>
<p>The key observation in the max-product algorithm is that we can now
<em>eliminate</em> <span class="math notranslate nohighlight">\(X_1\)</span> from the problem, by looking at all possible values
<span class="math notranslate nohighlight">\(x_2\)</span> of <span class="math notranslate nohighlight">\(X_2\)</span>, and creating a lookup table <span class="math notranslate nohighlight">\(g_1\)</span> for the best
possible value of <span class="math notranslate nohighlight">\(X_1\)</span>:</p>
<div class="math notranslate nohighlight">
\[
g_1(X_2)=\arg \max_{x_1}\phi(x_1, X_2).
\]</div>
<p>The size of this lookup table is equal to the number of possible outcomes for <span class="math notranslate nohighlight">\(X_2\)</span>:
in our vacuum-world example this is 5, as there are 5 rooms.</p>
<p>We also record the value of the product factor for that maximum, so we
can use it down the line for taking into account the consequence of each
choice:</p>
<div class="math notranslate nohighlight">
\[
\tau(X_2)=\max_{x_1}\phi(x_1, X_2).
\]</div>
<p>In practice both steps can be implemented in a single function.
We then put this new factor <span class="math notranslate nohighlight">\(\tau(X_2)\)</span> back into the graph, essentially
summarizing the result of eliminating <span class="math notranslate nohighlight">\(X_1\)</span> from the problem entirely,
obtaining the <strong>reduced graph</strong></p>
<div class="math notranslate nohighlight">
\[
\Phi_{2:3}=\tau(X_2)\phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3).
\]</div>
<p>Let us reflect on what happened above, because it is significant: we
eliminated <span class="math notranslate nohighlight">\(X_1\)</span> from consideration, and obtained a reduced problem
that only depends on the remaining states <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(X_3\)</span>. You can
intuitively see that this algorithm will terminate after <span class="math notranslate nohighlight">\(n\)</span> steps, and
in fact you could prove it by induction. In addition, the lookup table
<span class="math notranslate nohighlight">\(g_1\)</span> gives us a way that, once we know what the optimal value for
<span class="math notranslate nohighlight">\(X_2\)</span> is, we can just read off the optimal value for <span class="math notranslate nohighlight">\(X_1\)</span>. This is
what we will do, in <em>reverse</em> elimination order, after the algorithm
terminates.</p>
</div>
<div class="section" id="eliminating-x-2">
<h3><span class="section-number">3.4.7.2. </span>Eliminating <span class="math notranslate nohighlight">\(X_2\)</span><a class="headerlink" href="#eliminating-x-2" title="Permalink to this headline">¶</a></h3>
<figure>
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/max-product-2.png?raw=1" style="width:50.0%" alt=""><em>X</em><sub>2</sub></span>.</figcaption>
</figure>
<p>We now perform exactly the same steps for the state <span class="math notranslate nohighlight">\(X_2\)</span>. In this
case, the product factor <span class="math notranslate nohighlight">\(\phi(X_2, X_3)\)</span> has only factors connected
to <span class="math notranslate nohighlight">\(X_2\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\phi(X_2, X_3)=\tau(X_2)\phi_4(X_2)\phi_5(X_2, X_3), 
\]</div>
<p>which now includes the factor <span class="math notranslate nohighlight">\(\tau(X_2)\)</span> from the previous step.
Note that since we started from the reduced graph,
the product factor is guaranteed to not depend on the first state
<span class="math notranslate nohighlight">\(X_1\)</span>: that was eliminated! In fact, we can now in turn eliminate
<span class="math notranslate nohighlight">\(X_2\)</span> from the problem, by looking at all possible values <span class="math notranslate nohighlight">\(x_3\)</span> of
<span class="math notranslate nohighlight">\(X_3\)</span>, and creating a lookup table <span class="math notranslate nohighlight">\(g_2\)</span> for the best possible value
of <span class="math notranslate nohighlight">\(X_2\)</span>, given <span class="math notranslate nohighlight">\(X_3\)</span>,</p>
<div class="math notranslate nohighlight">
\[
g_2(X_3)=\arg \max_{x_2}\phi(x_2, X_3), 
\]</div>
<p>and as above we also
record the value of the product factor for that maximum in a new factor
<span class="math notranslate nohighlight">\(\tau(X_3)\)</span>:
$<span class="math notranslate nohighlight">\(
\tau(X_3)=\max_{x_2}\phi(x_2, X_3).
\)</span>$</p>
<p>We then put this new factor <span class="math notranslate nohighlight">\(\tau(X_3)\)</span> back into the graph, which is now reduced even more:</p>
<div class="math notranslate nohighlight">
\[
\Phi_{3:3}=\tau(X_3)\phi_6(X_3).
\]</div>
</div>
<div class="section" id="eliminating-x-3">
<h3><span class="section-number">3.4.7.3. </span>Eliminating <span class="math notranslate nohighlight">\(X_3\)</span><a class="headerlink" href="#eliminating-x-3" title="Permalink to this headline">¶</a></h3>
<figure>
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/max-product-3.png?raw=1" style="width:50.0%" alt="">
<figcaption></figcaption>
</figure>
<p>Finally, we eliminate <span class="math notranslate nohighlight">\(X_3\)</span>, where the product factor is now the
entire remaining graph and only depends on <span class="math notranslate nohighlight">\(X_3\)</span>, as all other states
have already been eliminated:</p>
<div class="math notranslate nohighlight">
\[
\phi(X_3)=\tau(X_3)\phi_6(X_3).
\]</div>
<p>We again obtain a lookup
table,
$<span class="math notranslate nohighlight">\(
g_3(\emptyset)=\arg \max_{x_3}\phi(x_3), 
\)</span>$</p>
<p>and a new
factor:
$<span class="math notranslate nohighlight">\(
\tau(\emptyset)=\max_{x_3}\phi(x_3).
\)</span>$</p>
<p>Note however that
now the value does not depend on any arguments! This is indicated by
making the argument list equal to the empty set <span class="math notranslate nohighlight">\(\emptyset\)</span>. Indeed,
<span class="math notranslate nohighlight">\(g_3\)</span> just tells us what the best value for <span class="math notranslate nohighlight">\(X_3\)</span> is, and <span class="math notranslate nohighlight">\(\tau\)</span>
tells us the corresponding value. Because it incorporates the factors
from the previous elimination steps, this will in fact be exactly the
MPE solution.</p>
</div>
<div class="section" id="back-substitution">
<h3><span class="section-number">3.4.7.4. </span>Back-substitution<a class="headerlink" href="#back-substitution" title="Permalink to this headline">¶</a></h3>
<p>Once we know the value for <span class="math notranslate nohighlight">\(X_3\)</span>, we can simply plug it into the
lookup table <span class="math notranslate nohighlight">\(g_2(X_3)\)</span> to get the value for <span class="math notranslate nohighlight">\(X_2\)</span>, which we can
then plug into the lookup table <span class="math notranslate nohighlight">\(g_1\)</span> to get the value for <span class="math notranslate nohighlight">\(X_1\)</span>,
and we recover the MPE in one single backward pass.</p>
</div>
<div class="section" id="summary-max-product">
<h3><span class="section-number">3.4.7.5. </span>Summary: Max-Product<a class="headerlink" href="#summary-max-product" title="Permalink to this headline">¶</a></h3>
<p>The complete HMM max-product algorithm for any value of <span class="math notranslate nohighlight">\(n\)</span> is given below,
where we used the shorthand notation <span class="math notranslate nohighlight">\(\Phi_{j:n}\doteq\phi(X_{j}, \ldots, X_{n})\)</span>
to denote a reduced factor graph.
The algorithm proceeds by eliminating one hidden state <span class="math notranslate nohighlight">\(X_{j}\)</span> at
a time, starting with the complete HMM factor graph <span class="math notranslate nohighlight">\(\Phi_{1:n}\)</span>. As we
eliminate each variable <span class="math notranslate nohighlight">\(X_{j}\)</span>, the function produces a single lookup
table <span class="math notranslate nohighlight">\(g_{j}(X_{j+1})\)</span>, as well as a reduced factor graph <span class="math notranslate nohighlight">\(\Phi_{j+1:n}\)</span>
on the remaining variables. After all variables have been eliminated,
the algorithm returns a chain of lookup tables that can be used to
recover the MPE in reverse elimination order.</p>
<hr class="docutils" />
<p><code class="docutils literal notranslate"><span class="pre">MaxProductHMM</span></code> (<span class="math notranslate nohighlight">\(\Phi_{1:n}\)</span>):</p>
<ul class="simple">
<li><p>for <span class="math notranslate nohighlight">\(j=1...n\)</span>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(g_{j}(X_{j+1}), \Phi_{j+1:n}\gets \text{CreateLookupTable}(\Phi_{j:n}, X_{j})\)</span></p></li>
</ul>
</li>
<li><p>return <span class="math notranslate nohighlight">\(g_1(X_1)g(X_2)\ldots g_{n}(\emptyset)\)</span></p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">CreateLookupTable</span></code> (<span class="math notranslate nohighlight">\(\Phi_{j:n}, X_{j}\)</span>):</p>
<ul class="simple">
<li><p>Remove all factors <span class="math notranslate nohighlight">\(\phi_{i}(\mathcal{X}_{i})\)</span> that contain <span class="math notranslate nohighlight">\(X_{j}\)</span></p></li>
<li><p>Form the product factor <span class="math notranslate nohighlight">\(\phi(X_{j}, X_{j+1})\gets\prod_{i}\phi_{i}(\mathcal{X}_{i})\)</span></p></li>
<li><p>Eliminate <span class="math notranslate nohighlight">\(X_j\)</span>: <span class="math notranslate nohighlight">\(g_{j}(X_{j+1}), \tau(X_{j+1})\gets\phi(X_{j}, X_{j+1})\)</span></p></li>
<li><p>Add new factor <span class="math notranslate nohighlight">\(\tau(X_{j+1})\)</span> back into the graph <span class="math notranslate nohighlight">\(\Phi_{j+1:n}\)</span></p></li>
<li><p>return <span class="math notranslate nohighlight">\(g_{j}(X_{j+1}), \Phi_{j+1:n}\)</span></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="complexity">
<h3><span class="section-number">3.4.7.6. </span>Complexity<a class="headerlink" href="#complexity" title="Permalink to this headline">¶</a></h3>
<p>The complexity of max-product is <em>linear</em> in the number of nodes, which is a nice improvement over exponential. The complexity of every elimination step is quadratic in the number of states, because we have to form the product factors and then maximize over them.</p>
</div>
<div class="section" id="max-product-in-gtsam">
<h3><span class="section-number">3.4.7.7. </span>Max-product in GTSAM<a class="headerlink" href="#max-product-in-gtsam" title="Permalink to this headline">¶</a></h3>
<p>GTSAM’s bread and butter is factor graphs, and finding the MPE is easy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mpe</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">mpe</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Hallway</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="the-sum-product-algorithm-for-hmms">
<h2><span class="section-number">3.4.8. </span>The Sum-Product Algorithm for HMMs<a class="headerlink" href="#the-sum-product-algorithm-for-hmms" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Sum-product on HMMs, also known as the Forward-Backward algorithm algorithm, is a dynamic-programming algorithm for doing full posterior inference.</p>
</div></blockquote>
<p>The sum-product algorithm for HMMs is a slight tweak on the max-product
algorithm that instead produces a Bayes net that calculates the
posterior probability <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>. Whereas the
max-product produces a DAG of lookup tables, the sum-product produces a
DAG of conditionals, i.e., a Bayes net. This is particularly interesting
if one is not content with a maximum probable explanation or MPE, but
instead wants the <strong>full Bayesian probability distribution</strong> of which
assignments to the states are more probable than others. The fact that
we recover this distribution in the form of a Bayes net again is
satisfying, because as we saw that is an economical representation of a
probability distribution.</p>
<p>One might wonder about the wisdom of all this: we started with a Bayes
net, converted to a factor graph, and now end up with a Bayes net again?
Indeed, but there are two important differences: the first Bayes net
represents the joint distribution <span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z})\)</span> and is
very useful for modeling. However, the second Bayes represents the
posterior <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>, and only has nodes for the
random variables in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, hence it is much smaller. Finally, in
many practical cases we do not even bother with the modeling step, but
construct the factor graph directly from the measurements.</p>
<p>Again, the key is that we can compute the posterior recursively from the product of factors, in dynamic programming style:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
P(\mathcal{X}|\mathcal{Z}) &amp;\propto \prod\phi_{i}(\mathcal{X}_{i})
\\&amp;\propto \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\&amp;\propto \{\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)\} ~~ \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\ &amp;\propto \{P(X_1|X_2, \mathcal{Z}) \tau(X_2)\} ~~ \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\ &amp;= P(X_1|X_2, \mathcal{Z}) ~~ P(X_2, X_3|\mathcal{Z})
\end{align*}
\end{split}\]</div>
<p>where the last equality invoked recursion to calculate the posterior <span class="math notranslate nohighlight">\(P(X_2, X_3|\mathcal{Z})\)</span> on the remaining variables from the remain factors. Above we defined the factor <span class="math notranslate nohighlight">\(\tau\)</span> obtained by summing</p>
<div class="math notranslate nohighlight">
\[
\tau(X_2)\doteq \sum_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)
\]</div>
<p>and, from the definition of conditional probability:</p>
<div class="math notranslate nohighlight">
\[
P(X_1|X_2, \mathcal{Z}) = \frac{\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)}{\tau(X_2)}.
\]</div>
<p>Hence, the only tweak necessary to the max-product is to replace the maximization and <span class="math notranslate nohighlight">\(\arg \max\)</span> in the elimination step with the chain rule.
Indeed, we factor each product
factor <span class="math notranslate nohighlight">\(\phi(X_{j}, X_{j+1})\)</span> into a conditional <span class="math notranslate nohighlight">\(P(X_{j}|X_{j+1})\)</span> and
an (unnormalized) marginal <span class="math notranslate nohighlight">\(\tau(X_{j+1})\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(X_{j}|X_{j+1})\tau(X_{j+1})\gets\phi(X_{j}, X_{j+1})
\]</div>
<p>The algorithm is called the <strong>sum-product algorithm</strong> because the
marginal is obtained by summing over all values of the state <span class="math notranslate nohighlight">\(X_{j}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\tau(X_{j+1})=\sum_{x_{j}}\phi(x_{j}, X_{j+1})
\]</div>
<p>We do not bother normalizing this into a proper distribution, as these
marginals are just intermediate steps in the algorithm. However, when
computing the conditional, we do normalize, and is it so happens the
normalization constant is simply equal to <span class="math notranslate nohighlight">\(1/\tau(X_{j+1})\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(X_{j}|X_{j+1})=\frac{\phi(X_{j}, X_{j+1})}{\tau(X_{j+1})}
\]</div>
<p>The entire algorithm is is listed below:</p>
<hr class="docutils" />
<p><code class="docutils literal notranslate"><span class="pre">SumProductHMM</span></code> (<span class="math notranslate nohighlight">\(\Phi_{1:n}\)</span>):</p>
<ul class="simple">
<li><p>for {<span class="math notranslate nohighlight">\(j=1...n\)</span>}:</p>
<ul>
<li><p>Eliminate <span class="math notranslate nohighlight">\(X_{j}\)</span>: <span class="math notranslate nohighlight">\(P(X_{j}|X_{j+1}),\Phi_{j+1:n}\gets \text{ApplyChainRule}(\Phi_{j:n},X_{j})\)</span>
return Bayes net <span class="math notranslate nohighlight">\(P(X_1|X_2)P(X_2|X_3)\ldots P(X_{n})\)</span></p></li>
</ul>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">ApplyChainRule</span></code> (<span class="math notranslate nohighlight">\(\Phi_{j:n}, X_{j}\)</span>):</p>
<ul class="simple">
<li><p>Remove all factors <span class="math notranslate nohighlight">\(\phi_{i}(\mathcal{X}_{i})\)</span> that contain <span class="math notranslate nohighlight">\(X_{j}\)</span></p></li>
<li><p>Create product factor <span class="math notranslate nohighlight">\(\phi(X_{j}, X_{j+1})\gets\prod_{i}\phi_{i}(\mathcal{X}_{i})\)</span></p></li>
<li><p>Factorize the product <span class="math notranslate nohighlight">\(P(X_{j}|X_{j+1})\tau(X_{j+1})\gets\phi(X_{j}, X_{j+1})\)</span></p></li>
<li><p>Add the new factor <span class="math notranslate nohighlight">\(\tau(X_{j+1})\)</span> back into the graph</p></li>
<li><p>return the conditional <span class="math notranslate nohighlight">\(P(X_{j}|X_{j+1})\)</span> and reduced graph <span class="math notranslate nohighlight">\(\Phi_{j+1:n}\)</span></p></li>
</ul>
<hr class="docutils" />
<p>Note that after we recover the Bayes net the algorithm terminates: there
is no back-substitution step. However, one might consider ancestral
sampling as a type of back-substitution: the reverse elimination order
is always a topological sort of the resulting Bayes net! Hence, after
the sum-product algorithm, we can sample as many realizations from the
posterior as we want: rather than just one MPE, we now have thousands of
plausible explanations, and ancestral sampling will yield them in
exactly the correct frequencies.</p>
<div class="section" id="sidebar">
<h3><span class="section-number">3.4.8.1. </span>Sidebar<a class="headerlink" href="#sidebar" title="Permalink to this headline">¶</a></h3>
<p>When we can produce samples <span class="math notranslate nohighlight">\(\mathcal{X}^{(s)}\)</span> from a posterior
<span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>, we can calculate empirical means of any
real-valued function <span class="math notranslate nohighlight">\(f(\mathcal{X})\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[
E_{P(\mathcal{X}|\mathcal{Z})}[f(x)]\approx\sum f(\mathcal{X}^{(s)})
\]</div>
<p>For example, we can calculate the posterior mean of how far the robot
traveled, either in Euclidean or Manhattan distance. These estimators
will have less variability than just calculating the distance for the
MPE, as they average over the entire probability distribution.</p>
</div>
<div class="section" id="sum-product-in-gtsam">
<h3><span class="section-number">3.4.8.2. </span>Sum-Product in GTSAM<a class="headerlink" href="#sum-product-in-gtsam" title="Permalink to this headline">¶</a></h3>
<p>In GTSAM, calling <code class="docutils literal notranslate"><span class="pre">sumProduct</span></code> yields a Bayes net, which encodes the full posterior:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">sumProduct</span><span class="p">()</span>
<span class="n">show</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S34_vacuum_perception_48_0.svg" src="_images/S34_vacuum_perception_48_0.svg" /></div>
</div>
<p>We can then sample from it, and calculate approximate marginals for <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, and <span class="math notranslate nohighlight">\(X_3\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">room_index</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="n">counts</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">room_index</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># base 0!</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="mi">100</span><span class="o">*</span><span class="n">counts</span><span class="o">/</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Living Room</th>
      <th>Kitchen</th>
      <th>Office</th>
      <th>Hallway</th>
      <th>Dining Room</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>3.2</td>
      <td>1.4</td>
      <td>3.8</td>
      <td>80.6</td>
      <td>11.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.8</td>
      <td>3.8</td>
      <td>0.8</td>
      <td>5.0</td>
      <td>89.6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.8</td>
      <td>90.8</td>
      <td>0.8</td>
      <td>0.0</td>
      <td>2.6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The marginals say how probable it is that the robot was in a particular room at a partical time step. This is much richer information that what is available in the MPE, which is just a point estimate for the trajectory.</p>
</div>
</div>
<div class="section" id="gtsam-101">
<h2><span class="section-number">3.4.9. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>The GTSAM concepts used in this section, explained.</p>
</div></blockquote>
<p>We created, for the first time, an instance of the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteFactorGraph</span></code> class. The constructor is trivial - takes no arguments.
To add factors, we can use the following methods:</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">j:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">j:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">spec:</span> <span class="pre">List[float])</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">keys:</span> <span class="pre">List[Tuple[int,</span> <span class="pre">int]],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
</ol>
<p>These are very similar to the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteBayesNet</span></code> methods, but in factor graphs distinction between frontal and parent values, so we just have a key, or a list of keys as in the last method.</p>
<p>Two key factor graph methods we used above are <code class="docutils literal notranslate"><span class="pre">optimize</span></code>, <code class="docutils literal notranslate"><span class="pre">maxProduct</span></code> and <code class="docutils literal notranslate"><span class="pre">sumProduct</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="n">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gtsam</span><span class="p">::</span><span class="n">DiscreteValues</span>
<span class="o">-</span> <span class="n">sumProduct</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span>
</pre></div>
</div>
<p>The first one returns the MPE as an assignment to discrete variables, whereas the second returns an entire Bayes net, encoding the posterior.</p>
<p>There is actually a method `maxProduct as well, which we have not discussed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="n">maxProduct</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteLookupDAG</span>
</pre></div>
</div>
<p>It returns a <code class="docutils literal notranslate"><span class="pre">DiscreteLookupDAG</span></code> instance, which, similarly to a Besy net is a DAG, but instead contains lookup tables, not conditionals:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dag</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">maxProduct</span><span class="p">()</span>
<span class="nb">type</span><span class="p">(</span><span class="n">dag</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>gtsam.gtsam.DiscreteLookupDAG
</pre></div>
</div>
</div>
</div>
<p>It’s mostly an internal data structure, and is not yet very “inspectable” in python. However, you can ask it to <code class="docutils literal notranslate"><span class="pre">argmax</span></code>, which is exactly what happens <em>inside</em> <code class="docutils literal notranslate"><span class="pre">optimize</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pretty</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">argmax</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Hallway</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="S33_vacuum_sensing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3.3. </span>Dynamic Bayes Nets</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="S35_vacuum_decision.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.5. </span>Markov Decision Processes</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Frank Dellaert and Seth Hutchinson<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>