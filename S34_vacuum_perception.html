

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>3.4. Perception with Graphical Models &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-312077-7"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-312077-7');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S34_vacuum_perception';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3.5. Markov Decision Processes" href="S35_vacuum_decision.html" />
    <link rel="prev" title="3.3. Dynamic Bayes Nets" href="S33_vacuum_sensing.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Introduction to Robotics and Perception - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction to Robotics and Perception
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_intro_state.html">1.1. Representing State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_intro_actions.html">1.2. Robot Actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_intro_sensing.html">1.3. Sensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="S14_intro_perception.html">1.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S15_intro_decision.html">1.5. Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S16_intro_learning.html">1.6. Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayes Nets</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Reinforcement Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gtbook/robotics" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS34_vacuum_perception.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S34_vacuum_perception.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Perception with Graphical Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-in-bayes-nets">3.4.1. Inference in Bayes Nets</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-posterior-inference">3.4.1.1. Full Posterior Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#most-probable-explanation">3.4.1.2. Most Probable Explanation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#efficiency-not">3.4.1.3. Efficiency (Not!)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-a-posteriori-estimation">3.4.1.4. Maximum a Posteriori estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">3.4.1.5. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hidden-markov-models">3.4.2. Hidden Markov Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-robot-hmm">3.4.2.1. Example: Robot HMM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-inference-in-hmms">3.4.3. Naive Inference in HMMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-graphs">3.4.4. Factor Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-bayes-nets-into-factor-graphs">3.4.5. Converting Bayes Nets into Factor Graphs.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">3.4.5.1. Exercise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-graphs-in-gtsam">3.4.5.2. Factor Graphs in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-with-factor-graphs">3.4.6. Computing with Factor Graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-mpe-with-gtsam">3.4.6.1. Naive MPE with GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-max-product-algorithm-for-hmms">3.4.7. The Max-Product Algorithm for HMMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminating-x-1">3.4.7.1. Eliminating <span class="math notranslate nohighlight">\(X_1\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminating-x-2">3.4.7.2. Eliminating <span class="math notranslate nohighlight">\(X_2\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminating-x-3">3.4.7.3. Eliminating <span class="math notranslate nohighlight">\(X_3\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#back-substitution">3.4.7.4. Back-substitution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-max-product">3.4.7.5. Summary: Max-Product</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.4.7.5.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complexity">3.4.7.6. Complexity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#max-product-in-gtsam">3.4.7.7. Max-product in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sum-product-algorithm-for-hmms">3.4.8. The Sum-Product Algorithm for HMMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sidebar">3.4.8.1. Sidebar</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-product-in-gtsam">3.4.8.2. Sum-Product in GTSAM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.4.8.3. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">3.4.9. GTSAM 101</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S34_vacuum_perception.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="cell tag_hide-cell tag_no-tex docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From section 3.2:</span>
<span class="n">wxyz</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;W&quot;</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">Z1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="p">[</span><span class="n">X1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="p">[</span><span class="n">Y1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="p">[</span><span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="s2">&quot;1/1&quot;</span><span class="p">)</span>

<span class="c1"># From Section 3.3:</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">light_levels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="perception-with-graphical-models">
<h1><span class="section-number">3.4. </span>Perception with Graphical Models<a class="headerlink" href="#perception-with-graphical-models" title="Permalink to this heading">#</a></h1>
<blockquote>
<div><p>Perception for dynamic Bayes nets is equivalent to inference in hidden Markov models (HMMs).</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S34-iRobot_vacuuming_robot-05.jpg"><img alt="Splash image with deeply contemplative robot" class="align-center" src="_images/S34-iRobot_vacuuming_robot-05.jpg" style="width: 40%;" /></a>
<p>Bayes nets are great for <em>modeling</em>, but for inferring the state of the robot over time we need better data structures.
In this section, we more formally define what we mean by inference, and introduce MAP and MPE inference.
We then define hidden Markov models, and highlight their connection with robot
localization over time.
Finally, we show how to efficiently perform inference by converting any Bayes net (with evidence) to a factor graph
and performing full posterior inference, MPE, and MAP estimation for HMMs.</p>
<section id="inference-in-bayes-nets">
<h2><span class="section-number">3.4.1. </span>Inference in Bayes Nets<a class="headerlink" href="#inference-in-bayes-nets" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>Inference can mean full posterior inference, most probable explanation, or maximum a posteriori inference.</p>
</div></blockquote>
<p><strong>Inference</strong> is the process of determining knowledge about a subset of
variables given the known values for another subset of variables. In
this section we will talk about how to do inference when the joint
distribution is specified using a Bayes net, but we will not take
advantage of the specific sparse structure of the network. Hence, the algorithms
below are completely general, for any (discrete) joint probability
distribution, as long as you can evaluate the joint distribution.</p>
<section id="full-posterior-inference">
<h3><span class="section-number">3.4.1.1. </span>Full Posterior Inference<a class="headerlink" href="#full-posterior-inference" title="Permalink to this heading">#</a></h3>
<p>The simplest case occurs when we can <em>partition</em> the variables into two
sets: the hidden variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and the observed values
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>. Then we can simply apply Bayes’ rule, but now applied to
<em>sets</em> of variables, to obtain an expression for the posterior over the
hidden variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Using the “easy” version of Bayes’ law
we obtain</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})\propto P(\mathcal{X}, \mathcal{Z}=\mathfrak{z}), \]</div>
<p>where <span class="math notranslate nohighlight">\(\mathfrak{z}\)</span> is the set of observed values for all variables in
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">show</span><span class="p">(</span><span class="n">wxyz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/293c7a7b79ef0d22d2343e0267cd0a8f01ebfd5e77c35487dfc2ea11588e0519.svg" src="_images/293c7a7b79ef0d22d2343e0267cd0a8f01ebfd5e77c35487dfc2ea11588e0519.svg" /></div>
</div>
<p>There is an easy algorithm to calculate the posterior distribution
above: simply enumerate all tuples <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> in a table, evaluate
<span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z}=\mathfrak{z})\)</span> for each one, and then
normalize. As an example, let us consider the Bayes net on W, X, Y, Z above,
and take <span class="math notranslate nohighlight">\(\mathcal{X}=(X, Y)\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Z}=(W, Z)\)</span>.
As before, let us assume that each variable can take on 10 different outcomes, and that
<span class="math notranslate nohighlight">\(\mathfrak{z}=(2, 7)\)</span>. The resulting table for
<span class="math notranslate nohighlight">\(P(X, Y|W=2, Z=7)\propto P(W=2, X, Y, Z=7)\)</span> is shown in the table below:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p><em>x</em></p></th>
<th class="head text-center"><p><em>y</em></p></th>
<th class="head text-center"><p><em>P(W=2, X=x, Y=y, Z=7)</em></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p><em>P(W=2|X=1, Z=7)P(X=1|Y=1, Z=7)P(Y=1|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p><em>P(W=2|X=1, Z=7)P(X=1|Y=2, Z=7)P(Y=2|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>…</p></td>
<td class="text-center"><p>…</p></td>
<td class="text-center"><p>…</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>10</p></td>
<td class="text-center"><p>9</p></td>
<td class="text-center"><p><em>P(W=2|X=10, Z=7)P(X=10|Y=9, Z=7)P(Y=9|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>10</p></td>
<td class="text-center"><p>10</p></td>
<td class="text-center"><p><em>P(W=2|X=10, Z=7)P(X=10|Y=10, Z=7)P(Y=10|Z=7)P(Z=7)</em></p></td>
</tr>
</tbody>
</table>
<p>We normalize by calculating <span class="math notranslate nohighlight">\(\sum_{x, y} P(W=2, X=x, Y=y, Z=7)\)</span> by summing over all these entries, and subsequently dividing all entries by the sum.</p>
</section>
<section id="most-probable-explanation">
<h3><span class="section-number">3.4.1.2. </span>Most Probable Explanation<a class="headerlink" href="#most-probable-explanation" title="Permalink to this heading">#</a></h3>
<p>A common inference problem associated with Bayes nets is determining the <strong>most
probable explanation</strong> or MPE for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>: given the values
<span class="math notranslate nohighlight">\(\mathfrak{z}\)</span> for <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, what is the most probable joint
assignment to the other variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>? While the posterior
gives us the complete picture, the MPE is different in nature: it is a
single assignment of values to <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>:</p>
<div class="math notranslate nohighlight">
\[x^*_{MPE} = \arg \max_x P(\mathcal{X}|\mathcal{Z}=\mathfrak{z}).\]</div>
<p>For example, given
<span class="math notranslate nohighlight">\(\mathfrak{z}=(2, 7)\)</span>, the MPE for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> could be <span class="math notranslate nohighlight">\(X=3\)</span> and
<span class="math notranslate nohighlight">\(Y=6\)</span>. Note that to compute the MPE, we need not bother with
normalizing: we can simply find the maximum entry in the unnormalized
posterior values.</p>
</section>
<section id="efficiency-not">
<h3><span class="section-number">3.4.1.3. </span>Efficiency (Not!)<a class="headerlink" href="#efficiency-not" title="Permalink to this heading">#</a></h3>
<p>In both the full posterior and MPE inference problems, the simple algorithms outlined above are
<em>not</em> efficient. In the example the table contains 100 entries, and in
general the number of entries is exponential in the size of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. However, when inspecting the entries in the table
there are already some obvious ways to save: for example, <span class="math notranslate nohighlight">\(P(Z=7)\)</span> is a
common factor in all entries, so clearly we need not bother
multiplying it in. Below we will discuss methods to fully
exploit the structure of the Bayes net to perform efficient inference.</p>
<p>If we had an efficient way to do inference, an MPE estimate would be a
great way to estimate the trajectory of a robot over time. For example,
using the “robot” dynamic Bayes net example from the last section, let us
assume that we are given the value of all observations and actions.
Then the MPE would simply be a trajectory of robot states.
This is an example of robot localization over time, and is a
key capability of a mobile robot.</p>
</section>
<section id="maximum-a-posteriori-estimation">
<h3><span class="section-number">3.4.1.4. </span>Maximum a Posteriori estimation<a class="headerlink" href="#maximum-a-posteriori-estimation" title="Permalink to this heading">#</a></h3>
<p>Finally, another well known inference problem is determining the <strong>maximum a
posteriori</strong> or MAP estimate: given the values of some variables
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, what joint assignment to a <em>subset</em>
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> of the other variables maximizes the posterior
<span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})\)</span>?
In this case the variables are
partitioned into three sets: the variables of interest <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>,
the nuisance variables <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, and the observed variables
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})=\sum_{\mathfrak{y}}P(\mathcal{X}, \mathcal{Y}=\mathfrak{y}|\mathcal{Z}=\mathfrak{z})\propto\sum_{\mathfrak{y}}P(\mathcal{X}, \mathcal{Y}=\mathfrak{y}, \mathcal{Z}=\mathfrak{z}).
\]</div>
<p>Finding a MAP estimate is more expensive than finding the MPE, as in
addition to enumerating all possible combinations of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> values, we now need to calculate
a possibly large number of sums, each exponential in the size of
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. In addition, the <em>number</em> of sums is
exponential in the size of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Below we will see that
while we can still exploit the Bayes net structure, MAP estimates are
fundamentally more expensive even in that case.</p>
</section>
<section id="exercises">
<h3><span class="section-number">3.4.1.5. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Show that in the example above, if we condition on known values for <span class="math notranslate nohighlight">\(\mathcal{Z}=(X,Z)\)</span>, the
posterior <span class="math notranslate nohighlight">\(P(W,Z|X,Y)\)</span> factors, and as a consequence we only have to
enumerate two tables of length 10, instead of a large table of
size 100.</p></li>
<li><p>Calculate the size of the table needed to enumerate the posterior
over the states <span class="math notranslate nohighlight">\(S\)</span> the robot dynamic Bayes net from the previous section,
given the value of all observations <span class="math notranslate nohighlight">\(Z\)</span> and actions <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>Show that if we are given the states, inferring the actions is
actually quite efficient, even with the brute force enumeration.
Hint: this is similar to the first exercise above.</p></li>
</ol>
</section>
</section>
<section id="hidden-markov-models">
<h2><span class="section-number">3.4.2. </span>Hidden Markov Models<a class="headerlink" href="#hidden-markov-models" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>HMMs provide a general framework for perception over time.</p>
</div></blockquote>
<p>In the previous section we discussed dynamic Bayes networks to model how a robot state evolves over time by taking actions, and how measurements result in a particular state. In this section we will ask <em>how we can recover the state of the robot given only the observations</em>, i.e. without knowing the states: the state is “hidden”. Here we will consider a general framework to answer this question.</p>
<p>A <strong>hidden Markov model</strong> or HMM is a dynamic Bayes net that has two
types of variables: states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.
The states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> are connected sequentially and satisfy the what
is called the <strong>Markov property</strong>: the probability of a state <span class="math notranslate nohighlight">\(X_{t}\)</span> is
only dependent on the value of the previous state <span class="math notranslate nohighlight">\(X_{t-1}\)</span>. As we saw before, we call a sequence of random variables with this property a <strong>Markov chain.</strong>
In addition, in an HMM we refer to the states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> as <em>hidden</em>
states, as typically we cannot directly observe their values. Instead,
they are indirectly observed through the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>,
where we have one measurement per hidden state. When these two
properties are satisfied, we call this probabilistic model a hidden
Markov model.</p>
<figure id="fig:unrolledHMM"> 
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/hmm-v2.png?raw=1" style="width:14cm" alt="">
<figcaption>An HMM, unrolled over three time-steps, represented by a Bayes net.</figcaption>
</figure>
<p>Figure
<a href="#fig:unrolledHMM" data-reference-type="ref" data-reference="fig:unrolledHMM">1</a>
shows an example of an HMM for three time steps, i.e..,
<span class="math notranslate nohighlight">\(\mathcal{X}=\{X_1, X_2, X_3\}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Z}=\{Z_1, Z_2, Z_3\}\)</span>. As discussed above, in a Bayes net
each node is associated with a conditional distribution: the Markov
chain has the prior <span class="math notranslate nohighlight">\(P(X_1)\)</span> and transition probabilities
<span class="math notranslate nohighlight">\(P(X_2|X_1)\)</span> and <span class="math notranslate nohighlight">\(P(X_3|X_2)\)</span>, whereas the measurements <span class="math notranslate nohighlight">\(Z_{t}\)</span>
depend only on the state <span class="math notranslate nohighlight">\(X_{t}\)</span>, modeled by measurement models
<span class="math notranslate nohighlight">\(P(Z_{t}|X_{t})\)</span>. In other words, the Bayes net encodes the following
joint distribution <span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z})\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X}, \mathcal{Z})=P(X_1)P(Z_1|X_1)P(X_2|X_1)P(Z_2|X_2)P(X_3|X_2)P(Z_3|X_3)\]</div>
<p>Note that we can also write this more succinctly as</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X}, \mathcal{Z})=P(\mathcal{Z}|\mathcal{X})P(\mathcal{X})\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X})=P(X_1, X_2, X_3)=P(X_1)P(X_2|X_1)P(X_3|X_2)\]</div>
<p>is the prior over state <em>trajectories</em>.</p>
<section id="example-robot-hmm">
<h3><span class="section-number">3.4.2.1. </span>Example: Robot HMM<a class="headerlink" href="#example-robot-hmm" title="Permalink to this heading">#</a></h3>
<p>Let us re-create the dynamic Bayes net from the previous section here, with 3 time steps:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dbn</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">sensor_spec</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)):</span>
    <span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
<span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1/1/1/1/1&quot;</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">dbn</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)}</span><span class="o">.</span><span class="n">union</span><span class="p">({</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)}))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7613d311c5ee778ab500412be75a0102e704fc024f686d28af14d28a591465e4.svg" src="_images/7613d311c5ee778ab500412be75a0102e704fc024f686d28af14d28a591465e4.svg" /></div>
</div>
</section>
</section>
<section id="naive-inference-in-hmms">
<h2><span class="section-number">3.4.3. </span>Naive Inference in HMMs<a class="headerlink" href="#naive-inference-in-hmms" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>Inference is easy to implement naively, but hopelessly inefficient.</p>
</div></blockquote>
<p>As we saw above,
one way to perform inference is to apply Bayes’ rule to obtain an expression for the <em>posterior</em> probability distribution over
the state trajectory <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, given the measurements
<span class="math notranslate nohighlight">\(\mathcal{Z}=\mathfrak{z}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
P(\mathcal{X}|\mathcal{Z}) &amp; \propto P(\mathcal{Z}=\mathfrak{z}|\mathcal{X})P(\mathcal{X}) \\
&amp; =L(\mathcal{X}; \mathcal{Z}=\mathfrak{z})P(\mathcal{X})\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(P(\mathcal{X})\)</span> is the trajectory prior
and the <strong>likelihood</strong> <span class="math notranslate nohighlight">\(L(\mathcal{X}; \mathcal{Z}=\mathfrak{z})\)</span> of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> given <span class="math notranslate nohighlight">\(\mathcal{Z}=\mathfrak{z}\)</span> is defined as before as a function of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\mathcal{X}; \mathcal{Z}=\mathfrak{z}) &amp; \doteq P(\mathcal{Z}=\mathfrak{z}|\mathcal{X})\\
&amp; =P(z_1|X_1)P(z_2|X_2)P(z_3|X_3)\\
&amp; =L(X_1; Z_1)L(X_2; Z_2)L(X_3; Z_3)\end{aligned}
\end{split}\]</div>
<p>Hence, a naive implementation for finding the <strong>most probable
explanation</strong> (MPE) for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> would tabulate all possible
trajectories <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and calculate the posterior <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span> for each one.
Unfortunately the number of entries in this giant table is
<em>exponential</em> in the number of states. Not only is this computationally
prohibitive for long trajectories, but intuitively it is clear that for
many of these trajectories we are computing the same values over and
over again. There are three different approaches to improve on
this:</p>
<ol class="arabic simple">
<li><p>Branch &amp; bound</p></li>
<li><p>Dynamic programming</p></li>
<li><p>Inference using factor graphs</p></li>
</ol>
<p>Branch and bound is a powerful technique but will not generalize to
continuous variables; the other two approaches will. And, we will
see that dynamic programming, which underlies the classical inference
algorithms in the HMM literature, is just a special case of the last
approach. Hence, here we will dive in and immediately go for the most
general approach: inference in factor graphs.</p>
</section>
<section id="factor-graphs">
<h2><span class="section-number">3.4.4. </span>Factor Graphs<a class="headerlink" href="#factor-graphs" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>Factor graphs are an excellent representation in which do inference.</p>
</div></blockquote>
<p>We first introduce the notion of factors.
Again referring to the example from Figure
<a href="#fig:unrolledHMM" data-reference-type="ref" data-reference="fig:unrolledHMM">1</a>,
let us consider the posterior.
Since the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> are <em>known</em>, the posterior is
proportional to the product of six <strong>factors</strong>, three of which derive
from the Markov chain, and three of which are likelihood factors as defined
above:</p>
<div class="math notranslate nohighlight">
\[
P(\mathcal{X}|\mathcal{Z})\propto P(X_1)L(X_1; z_1)P(X_2|X_1)L(X_2; z_2)P(X_3|X_2)L(X_3; z_3)
\]</div>
<p>Some of these factors are unary factors, and some are binary factors.
In particular, above some of the factors depend on just one hidden variable,
for example <span class="math notranslate nohighlight">\(L(X_2; z_2)\)</span>, whereas others depend on two variables, e.g., the
transition model <span class="math notranslate nohighlight">\(P(X_3|X_2)\)</span>.
Measurements are not counted here,
because once we are <em>given</em> the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, they merely
function as known parameters in the likelihoods <span class="math notranslate nohighlight">\(L(X_{t}; z_{t})\)</span>, which
are seen as functions of <em>just</em> the state <span class="math notranslate nohighlight">\(X_{t}\)</span>.</p>
<figure id="fig:HMM-FG">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/fg-v2.png?raw=1" style="width:60%" alt="">
<figcaption>An HMM with observed measurements, unrolled over time, represented as a factor graph.</figcaption>
</figure>
<p>This motivates a different graphical model, a <strong>factor graph</strong>, in which
we only represent the <em>hidden</em> variables <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, and <span class="math notranslate nohighlight">\(X_3\)</span>,
connected to factors that encode probabilistic information. For
our example with three hidden states, the corresponding factor graph is
shown in Figure
<a href="#fig:HMM-FG" data-reference-type="ref" data-reference="fig:HMM-FG">2</a> above.
It should be clear from the figure that the connectivity of a factor
graph encodes, for each factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span>, which subset of variables
<span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span> it depends on. We write:</p>
<div class="math notranslate nohighlight">
\[
\phi(\mathcal{X})=\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)\phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\]</div>
<p>where the factors above are defined to correspond one-to-one to the six factors in the posterior,
e.g.,</p>
<div class="math notranslate nohighlight">
\[\phi_6(X_3)\doteq L(X_3; z_3).\]</div>
<p>All measurements are associated with unary factors, whereas the Markov chain is
associated mostly with binary factors, with the exception of the unary
factor <span class="math notranslate nohighlight">\(\phi_1(X_1)\)</span>. Note that in defining the factors we can omit
any normalization factors, which in many cases results in computational
savings.</p>
<p>Formally a factor graph is a bipartite graph
<span class="math notranslate nohighlight">\(F=(\mathcal{U}, \mathcal{V}, \mathcal{E})\)</span> with two types of nodes:
<strong>factors</strong> <span class="math notranslate nohighlight">\(\phi_{i}\in\mathcal{U}\)</span> and <strong>variables</strong>
<em><span class="math notranslate nohighlight">\(X_{j}\in\mathcal{V}\)</span>.</em> Edges <span class="math notranslate nohighlight">\(e_{ij}\in\mathcal{E}\)</span> are always between
factor nodes and variables nodes. The set of random variable nodes
adjacent to a factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span> is written as <span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span>. With
these definitions, a factor graph <span class="math notranslate nohighlight">\(F\)</span> defines the factorization of a
global function <span class="math notranslate nohighlight">\(\phi(\mathcal{X})\)</span> as</p>
<div class="math notranslate nohighlight">
\[\phi(\mathcal{X})=\prod_{i}\phi_{i}(\mathcal{X}_{i}).\]</div>
<p>In other words, the independence relationships are encoded by the edges
<span class="math notranslate nohighlight">\(e_{ij}\)</span> of the factor graph, with each factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span> a function of
<em>only</em> the variables <span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span> in its adjacency set. As example,
for the factor graph in Figure
<a href="#fig:HMM-FG" data-reference-type="ref" data-reference="fig:HMM-FG">2</a>
we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{X}_1 &amp; =\{X_1\}\\
\mathcal{X}_2 &amp; =\{X_1\}\\
\mathcal{X}_3 &amp; =\{X_1, X_2\}\\
\mathcal{X}_4 &amp; =\{X_2\}\\
\mathcal{X}_5 &amp; =\{X_2, X_3\}\\
\mathcal{X}_6 &amp; =\{X_3\}\end{aligned}
\end{split}\]</div>
</section>
<section id="converting-bayes-nets-into-factor-graphs">
<h2><span class="section-number">3.4.5. </span>Converting Bayes Nets into Factor Graphs.<a class="headerlink" href="#converting-bayes-nets-into-factor-graphs" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>It is trivial to convert Bayes nets into factor graphs.</p>
</div></blockquote>
<figure id="fig:conversion">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/hmm-v2.png?raw=1" style="width:12cm" alt="">
<figcaption>Bayes net representation of an HMM.</figcaption>
</figure>
<figure id="fig:conversion-2">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/fg-v2.png?raw=1"  style="width:14cm" alt="">
<figcaption>Conversion of HMM above to a factor graph, where measurements are known.</figcaption>
</figure>
<p>Every Bayes net can be trivially converted to a factor graph, as shown above.
Recall that every node in a Bayes net denotes a conditional density on the
corresponding variable and its parent nodes. Hence, the conversion is
quite simple: every Bayes net node maps to <em>both</em> a variable node and
a factor node in the corresponding factor graph. The factor is connected
to the variable node, as well as the variable nodes corresponding to the
parent nodes in the Bayes net. If some nodes in the Bayes net are
evidence nodes, i.e., they are given as known variables, we omit the
corresponding variable nodes: the known variable simply becomes a fixed
parameter in the corresponding factor.</p>
<section id="exercise">
<h3><span class="section-number">3.4.5.1. </span>Exercise<a class="headerlink" href="#exercise" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Convert the dynamic Bayes net from the previous section into a factor graph, assuming <em>no</em> known variables.</p></li>
<li><p>Finally, do the same again, but now assume the states are given. Reflect on the remarkable phenomenon that happens.</p></li>
</ol>
</section>
<section id="factor-graphs-in-gtsam">
<h3><span class="section-number">3.4.5.2. </span>Factor Graphs in GTSAM<a class="headerlink" href="#factor-graphs-in-gtsam" title="Permalink to this heading">#</a></h3>
<p>Let us create the factor graph directly using GTSAM. Before we do, however, we need to instantiate the given actions and measurements, both of which are assumed known:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actions</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="s1">&#39;R&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="s1">&#39;U&#39;</span><span class="p">})</span>
<span class="n">measurements</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dark&#39;</span><span class="p">,</span> <span class="s1">&#39;medium&#39;</span><span class="p">,</span> <span class="s1">&#39;light&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now we create the factor graph, first adding the prior <span class="math notranslate nohighlight">\(\phi(X_1)=P(X_1)\)</span> on <span class="math notranslate nohighlight">\(X_1\)</span>, then the binary factors <span class="math notranslate nohighlight">\(\phi(X_k, X_{k+1}) = P(X_{k+1}|X_k, A_k=a_k)\)</span>,
and finally, the measurement likelihood factors <span class="math notranslate nohighlight">\(\phi(X_k; Z_k=z_k) \propto P(Z_k=z_k|X_k)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">graph</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteFactorGraph</span><span class="p">()</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1 1 1 1 1&quot;</span><span class="p">)</span>  <span class="c1"># \phi(X_1) = P(X_1)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">conditional</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
    <span class="n">conditional_a_k</span> <span class="o">=</span> <span class="n">conditional</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>  <span class="c1"># \phi(X,X+) = P(X+|X,A=a)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">conditional_a_k</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">measurement</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">measurements</span><span class="p">):</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">conditional</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">sensor_spec</span><span class="p">)</span>
    <span class="n">z_k</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">light_levels</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">measurement</span><span class="p">)</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="n">conditional</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">z_k</span><span class="p">)</span>  <span class="c1"># \phi(X) = P(Z=z|X)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f32e9c2472cd645146e56d47c36421ff0dca4a65057a6808a22dbb5eb8262fd1.svg" src="_images/f32e9c2472cd645146e56d47c36421ff0dca4a65057a6808a22dbb5eb8262fd1.svg" /></div>
</div>
<p>Note that discrete distributions like <span class="math notranslate nohighlight">\(P(X_1)\)</span> and conditionals, above, are perfectly fine factors, and in fact <em>derive</em> from the factor type in GTSAM. This is what allows us to add them directly the graph as is. Note that in a real implementation we might not take the detour to first construct the conditionals as above: we did so because they were conveniently available here, but typically we would construct factors directly.</p>
</section>
</section>
<section id="computing-with-factor-graphs">
<h2><span class="section-number">3.4.6. </span>Computing with Factor Graphs<a class="headerlink" href="#computing-with-factor-graphs" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>We can evaluate, optimize, and sample from factor graphs.</p>
</div></blockquote>
<p>Once we convert a Bayes net with evidence into a factor graph where the
evidence is all implicit in the factors, we can support a number of
different computations. First, given any factor graph defining an
unnormalized density <span class="math notranslate nohighlight">\(\phi(X)\)</span>, we can easily <strong>evaluate</strong> it for any
given value, by simply evaluating every factor and multiplying the
results. The factor graph represents the unnormalized posterior, i.e.,
<span class="math notranslate nohighlight">\(\phi(\mathcal{X})\propto P(\mathcal{X}|\mathcal{Z})\)</span>.</p>
<p>Evaluation opens up the way to <strong>optimization</strong>, e.g., finding the most probable
explanation or MPE, as we will do below. In the case of discrete
variables, graph search methods can be applied, but we will use a
different approach.</p>
<p>While finding the maximum of the posterior is often of most
interest, <strong>sampling</strong> from a probability distribution can be used to
visualize, explore, and compute statistics and expected values
associated with the posterior. However, the ancestral sampling method we
discussed earlier only applies to directed acyclic graphs. There are
however more general sampling algorithms that can be used for factor
graphs, more specifically Markov chain Monte Carlo (MCMC) methods. One
such method is Gibbs sampling, which proceeds by sampling one variable
at a time from its conditional density given all other variables it is
connected to via factors. This assumes that this conditional density can
be easily obtained, which is in fact true for discrete variables.</p>
<p>In this book, we use factor graphs as the organizing structure for probabilistic
inference. In later chapters we will expand their use to continuous
variables, and will see that factor graphs aptly describe the
independence assumptions and sparse nature of the large nonlinear
least-squares problems arising in robotics. But their usefulness extends
far beyond that: they are at the core of the sparse linear solvers we
use as building blocks, they clearly show the nature of filtering and
incremental inference, and lead naturally to distributed and/or parallel
versions of robotics.</p>
<section id="naive-mpe-with-gtsam">
<h3><span class="section-number">3.4.6.1. </span>Naive MPE with GTSAM<a class="headerlink" href="#naive-mpe-with-gtsam" title="Permalink to this heading">#</a></h3>
<p>Because our factor graph is so small, it does not hurt to show off how easy it is to implement the naive algorithm to find the MPE. We just loop over all possible state trajectories, and keep track of the one with the highest value:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mpe_value</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">mpe_trajectory</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">for</span> <span class="n">x1</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">x2</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x3</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
            <span class="n">trajectory</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">x1</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">x2</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">x3</span><span class="p">})</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">graph</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">mpe_value</span><span class="p">:</span>
                <span class="n">mpe_value</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">mpe_trajectory</span> <span class="o">=</span> <span class="n">trajectory</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;found MPE solution with value </span><span class="si">{</span><span class="n">mpe_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">mpe_trajectory</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>found MPE solution with value 0.3277:
</pre></div>
</div>
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Hallway</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Remember that this MPE is <em>for a given action and measurement sequence</em>. All those fixed values are implicit in the factors that we have added to the factor graph in <code class="docutils literal notranslate"><span class="pre">graph</span></code> above.</p>
</section>
</section>
<section id="the-max-product-algorithm-for-hmms">
<h2><span class="section-number">3.4.7. </span>The Max-Product Algorithm for HMMs<a class="headerlink" href="#the-max-product-algorithm-for-hmms" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>Max-product on HMMs, also known as the Viterbi algorithm, is a dynamic-programming algorithm for finding the MPE.</p>
</div></blockquote>
<p>In this section we discuss an algorithm that is much faster than the naive algorithm to find the MPE.
Given a factor graph of size <span class="math notranslate nohighlight">\(n\)</span>, the <strong>max-product algorithm</strong> is an <span class="math notranslate nohighlight">\(O(n)\)</span> algorithm
to find the maximum probable explanation or MPE.
We will use the example from Figure
<a href="#fig:HMM-FG" data-reference-type="ref" data-reference="fig:HMM-FG">2</a>
to give the intuition. To find the MPE for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> we need to
<em>maximize</em> the product</p>
<div class="math notranslate nohighlight">
\[\phi(X_1, X_2, X_3)=\prod\phi_{i}(\mathcal{X}_{i})\]</div>
<p>i.e., the <strong>value</strong> of the factor graph.</p>
<p>Because the value of the factor graph is a product of factor values, we can compute its maximum recursively, dynamic programming style. We start by writing out the maximization over the product explicitly:</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathcal{X}} \prod\phi_{i}(\mathcal{X}_{i}) = 
\max_{X_1, X_2, X_3} ~~~\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3) 
\]</div>
<p>The key to our recursion will be to consider each variable in turn, starting with <span class="math notranslate nohighlight">\(X_1\)</span>. In particular, let us group all the factors connected to <span class="math notranslate nohighlight">\(X_1\)</span></p>
<div class="math notranslate nohighlight">
\[
\max_{\mathcal{X}} \prod\phi_{i}(\mathcal{X}_{i}) = 
\max_{X_1, X_2, X_3} ~~~ \{ \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \} ~~~ \phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3)
\]</div>
<p>which allows us to move the <em>max</em> operator inside:</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathcal{X}} \prod\phi_{i}(\mathcal{X}_{i}) = 
\max_{X_2, X_3} ~~~ \{ \max_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \} ~~~ \phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3)
\]</div>
<p>The key to the recursion is that we can simply consider the expression inside the curly braces as new factor on <span class="math notranslate nohighlight">\(X_2\)</span>:</p>
<div class="math notranslate nohighlight">
\[\tau(X_2)\doteq \max_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)\]</div>
<p>which records the maximum value resulting from <em>only</em> maximizing <span class="math notranslate nohighlight">\(X_1\)</span>. The value of the computation depends on the value of <span class="math notranslate nohighlight">\(X_2\)</span>, because <span class="math notranslate nohighlight">\(X_2\)</span> was involved in factor <span class="math notranslate nohighlight">\(\phi_3\)</span>. However, crucially, the variable <span class="math notranslate nohighlight">\(X_3\)</span> is not involved in the maximization.</p>
<p>Substituting the new factor into the maximization, we now need to maximize over a <em>reduced</em> factor graph that no longer is a function of <span class="math notranslate nohighlight">\(X_1\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathcal{X}} \prod\phi_{i}(\mathcal{X}_{i}) =
\max_{X_2, X_3} ~~~\tau(X_2) \phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3)
\]</div>
<p>and this allows us to recurse, which we will do so explicitly below. After we recursively find the optimal values for <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(X_3\)</span>, we can recover <span class="math notranslate nohighlight">\(X_1\)</span> as a function of <span class="math notranslate nohighlight">\(X_2\)</span> by</p>
<div class="math notranslate nohighlight">
\[
g_1(X_2) = \arg \max_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)
\]</div>
<p>where a <em>lookup table</em> can be created at the same time that we compute <span class="math notranslate nohighlight">\(\tau(X_2)\)</span>.</p>
<p>The above shows the general principle for max-product by <em>eliminating</em> <span class="math notranslate nohighlight">\(X_1\)</span>. We must do the same computation for all other variables as well.
Below we use the factor graph to illustrate how the max-product algorithm
proceeds one variable at a time, using “Bayes-net-style” directed edges to represent the lookup tables <span class="math notranslate nohighlight">\(g_k(X_{k+1})\)</span>, and factors to represent the <span class="math notranslate nohighlight">\(\tau(\cdot)\)</span> functions, as indeed they <em>are</em> factors. Because at every step, one variable is eliminated from the maximization, the max-product algorithm is in fact an instance of the <strong>elimination algorithm</strong>, which we will see pop up in many different guises.</p>
<p>We proceed from left to right, i.e. we start with state <span class="math notranslate nohighlight">\(X_1\)</span> and proceed until we have
processed all states. We will tackle the three steps one by one in ths subsections below:</p>
<section id="eliminating-x-1">
<h3><span class="section-number">3.4.7.1. </span>Eliminating <span class="math notranslate nohighlight">\(X_1\)</span><a class="headerlink" href="#eliminating-x-1" title="Permalink to this heading">#</a></h3>
<figure id="fig:eliminating-x1">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/max-product-1.png?raw=1" style="width:60.0%" alt="Eliminating X1">
</figure>
<p>We start by considering the first state <span class="math notranslate nohighlight">\(X_1\)</span>, and we form a <strong>product
factor</strong> <span class="math notranslate nohighlight">\(\phi(X_1, X_2)\)</span> that collects <em>only</em> the factors connected
to <span class="math notranslate nohighlight">\(X_1\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\phi(X_1, X_2)=\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2).
\]</div>
<p>When we use a factor in a product, we <em>remove</em> it from the original
factor graph. Note that because one of those factors, the state
transition model <span class="math notranslate nohighlight">\(\phi_3(X_1, X_2)\doteq P(X_2|X_1)\)</span>, is also
connected to the second state <span class="math notranslate nohighlight">\(X_2\)</span>, the product factor is a function
of <em>both</em> <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span>, i.e., it is a binary factor.</p>
<p>The key observation in the max-product algorithm is that we can now
<em>eliminate</em> <span class="math notranslate nohighlight">\(X_1\)</span> from the problem, by looking at all possible values
<span class="math notranslate nohighlight">\(x_2\)</span> of <span class="math notranslate nohighlight">\(X_2\)</span>, and creating a lookup table <span class="math notranslate nohighlight">\(g_1\)</span> for the best
possible value of <span class="math notranslate nohighlight">\(X_1\)</span>:</p>
<div class="math notranslate nohighlight">
\[
g_1(X_2)=\arg \max_{x_1}\phi(x_1, X_2).
\]</div>
<p>The size of this lookup table is equal to the number of possible outcomes for <span class="math notranslate nohighlight">\(X_2\)</span>:
in our vacuum-world example this is 5, as there are 5 rooms.</p>
<p>We also record the value of the product factor for that maximum, so we
can use it down the line for taking into account the consequence of each
choice:</p>
<div class="math notranslate nohighlight">
\[
\tau(X_2)=\max_{x_1}\phi(x_1, X_2).
\]</div>
<p>In practice both steps can be implemented in a single “eliminate” function.
We then put this new factor <span class="math notranslate nohighlight">\(\tau(X_2)\)</span> back into the graph, essentially
summarizing the result of eliminating <span class="math notranslate nohighlight">\(X_1\)</span> from the problem entirely,
obtaining the <strong>reduced graph</strong></p>
<div class="math notranslate nohighlight">
\[
\Phi_{2:3}=\tau(X_2)\phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3).
\]</div>
<p>Let us reflect on what happened above, because it is significant: we
eliminated <span class="math notranslate nohighlight">\(X_1\)</span> from consideration, and obtained a reduced problem
that only depends on the remaining states <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(X_3\)</span>. You can
intuitively see that this algorithm will terminate after <span class="math notranslate nohighlight">\(n\)</span> steps, and
in fact you could prove this by induction. In addition, the lookup table
<span class="math notranslate nohighlight">\(g_1\)</span> gives us a way that, once we know what the optimal value for
<span class="math notranslate nohighlight">\(X_2\)</span> is, we can just read off the optimal value for <span class="math notranslate nohighlight">\(X_1\)</span>. This is
what we will do, in <em>reverse</em> elimination order, after the algorithm
terminates.</p>
</section>
<section id="eliminating-x-2">
<h3><span class="section-number">3.4.7.2. </span>Eliminating <span class="math notranslate nohighlight">\(X_2\)</span><a class="headerlink" href="#eliminating-x-2" title="Permalink to this heading">#</a></h3>
<figure id="fig:eliminating-x2">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/max-product-2.png?raw=1" style="width:50.0%" alt="Eliminating X2">
</figure>
<p>We now perform exactly the same steps for the state <span class="math notranslate nohighlight">\(X_2\)</span>. In this
case, the product factor <span class="math notranslate nohighlight">\(\phi(X_2, X_3)\)</span> has only factors connected
to <span class="math notranslate nohighlight">\(X_2\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\phi(X_2, X_3)=\tau(X_2)\phi_4(X_2)\phi_5(X_2, X_3), 
\]</div>
<p>which now includes the factor <span class="math notranslate nohighlight">\(\tau(X_2)\)</span> from the previous step.
Note that since we started from the reduced graph,
the product factor is guaranteed to not depend on the first state
<span class="math notranslate nohighlight">\(X_1\)</span>: the state <span class="math notranslate nohighlight">\(X_1\)</span> was already eliminated! In fact, we can now in turn eliminate
<span class="math notranslate nohighlight">\(X_2\)</span>, by looking at all possible values <span class="math notranslate nohighlight">\(x_3\)</span> of
<span class="math notranslate nohighlight">\(X_3\)</span>, and creating a lookup table <span class="math notranslate nohighlight">\(g_2\)</span> for the best possible value
of <span class="math notranslate nohighlight">\(X_2\)</span>, given <span class="math notranslate nohighlight">\(X_3\)</span>,</p>
<div class="math notranslate nohighlight">
\[
g_2(X_3)=\arg \max_{x_2}\phi(x_2, X_3), 
\]</div>
<p>and as above we also
record the value of the product factor for that maximum in a new factor
<span class="math notranslate nohighlight">\(\tau(X_3)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\tau(X_3)=\max_{x_2}\phi(x_2, X_3).
\]</div>
<p>We then put this new factor <span class="math notranslate nohighlight">\(\tau(X_3)\)</span> back into the graph, which is now reduced even more:</p>
<div class="math notranslate nohighlight">
\[
\Phi_{3:3}=\tau(X_3)\phi_6(X_3).
\]</div>
</section>
<section id="eliminating-x-3">
<h3><span class="section-number">3.4.7.3. </span>Eliminating <span class="math notranslate nohighlight">\(X_3\)</span><a class="headerlink" href="#eliminating-x-3" title="Permalink to this heading">#</a></h3>
<figure id="fig:eliminating-x3">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/max-product-3.png?raw=1" style="width:50.0%" alt="Eliminating X3">
</figure>
<p>Finally, we eliminate <span class="math notranslate nohighlight">\(X_3\)</span>, where the product factor is now the
entire remaining graph and only depends on <span class="math notranslate nohighlight">\(X_3\)</span>, as all other states
have already been eliminated:</p>
<div class="math notranslate nohighlight">
\[
\phi(X_3)=\tau(X_3)\phi_6(X_3).
\]</div>
<p>We again obtain a lookup table,</p>
<div class="math notranslate nohighlight">
\[
g_3(\emptyset)=\arg \max_{x_3}\phi(x_3), 
\]</div>
<p>and a new factor:</p>
<div class="math notranslate nohighlight">
\[
\tau(\emptyset)=\max_{x_3}\phi(x_3).
\]</div>
<p>Note however that now the value does not depend on any arguments!
This is indicated by making the argument list equal to the empty set <span class="math notranslate nohighlight">\(\emptyset\)</span>.
Indeed, <span class="math notranslate nohighlight">\(g_3\)</span> just tells us what the best value for <span class="math notranslate nohighlight">\(X_3\)</span> is, and <span class="math notranslate nohighlight">\(\tau\)</span>
tells us the corresponding value. Because it incorporates the factors
from the previous elimination steps, this will in fact be exactly the
MPE solution, and the recursion ends!</p>
</section>
<section id="back-substitution">
<h3><span class="section-number">3.4.7.4. </span>Back-substitution<a class="headerlink" href="#back-substitution" title="Permalink to this heading">#</a></h3>
<p>Once we know the value for <span class="math notranslate nohighlight">\(X_3\)</span>, we can simply plug it into the
lookup table <span class="math notranslate nohighlight">\(g_2(X_3)\)</span> to get the value for <span class="math notranslate nohighlight">\(X_2\)</span>, which we can
then plug into the lookup table <span class="math notranslate nohighlight">\(g_1\)</span> to get the value for <span class="math notranslate nohighlight">\(X_1\)</span>,
and we recover the MPE in one single backward pass.</p>
</section>
<section id="summary-max-product">
<h3><span class="section-number">3.4.7.5. </span>Summary: Max-Product<a class="headerlink" href="#summary-max-product" title="Permalink to this heading">#</a></h3>
<p>The complete HMM max-product algorithm for any value of <span class="math notranslate nohighlight">\(n\)</span> is given in the pseudocode below,
where we used the shorthand notation <span class="math notranslate nohighlight">\(\Phi_{j:n}\doteq\phi(X_{j}, \ldots, X_{n})\)</span>
to denote a reduced factor graph.
The algorithm proceeds by eliminating one hidden state <span class="math notranslate nohighlight">\(X_{j}\)</span> at
a time, starting with the complete HMM factor graph <span class="math notranslate nohighlight">\(\Phi_{1:n}\)</span>. As we
eliminate each variable <span class="math notranslate nohighlight">\(X_{j}\)</span>, the function produces a single lookup
table <span class="math notranslate nohighlight">\(g_{j}(X_{j+1})\)</span>, as well as a reduced factor graph <span class="math notranslate nohighlight">\(\Phi_{j+1:n}\)</span>
on the remaining variables. After all variables have been eliminated,
the algorithm returns a chain of lookup tables that can be used to
recover the MPE in reverse elimination order.</p>
<hr class="docutils" />
<p><code class="docutils literal notranslate"><span class="pre">MaxProductHMM</span></code> (<span class="math notranslate nohighlight">\(\Phi_{1:n}\)</span>):</p>
<ul class="simple">
<li><p>for <span class="math notranslate nohighlight">\(j=1...n\)</span>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(g_{j}(X_{j+1}), \Phi_{j+1:n}\gets \text{CreateLookupTable}(\Phi_{j:n}, X_{j})\)</span></p></li>
<li><p>return <span class="math notranslate nohighlight">\(g_1(X_2)g_2(X_3)\ldots g_{n}(\emptyset)\)</span></p></li>
</ul>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">CreateLookupTable</span></code> (<span class="math notranslate nohighlight">\(\Phi_{j:n}, X_{j}\)</span>):</p>
<ul class="simple">
<li><p>Remove all factors <span class="math notranslate nohighlight">\(\phi_{i}(\mathcal{X}_{i})\)</span> that contain <span class="math notranslate nohighlight">\(X_{j}\)</span></p></li>
<li><p>Form the product factor <span class="math notranslate nohighlight">\(\phi(X_{j}, X_{j+1})\gets\prod_{i}\phi_{i}(\mathcal{X}_{i})\)</span></p></li>
<li><p>Eliminate <span class="math notranslate nohighlight">\(X_j\)</span>: <span class="math notranslate nohighlight">\(g_{j}(X_{j+1}), \tau(X_{j+1})\gets\phi(X_{j}, X_{j+1})\)</span></p></li>
<li><p>Add new factor <span class="math notranslate nohighlight">\(\tau(X_{j+1})\)</span> back into the graph <span class="math notranslate nohighlight">\(\Phi_{j+1:n}\)</span></p></li>
<li><p>return the lookup table <span class="math notranslate nohighlight">\(g_{j}(X_{j+1})\)</span> and reduced graph <span class="math notranslate nohighlight">\(\Phi_{j+1:n}\)</span></p></li>
</ul>
<hr class="docutils" />
<p>In the HMM literature, the max-product algorithm is known as the <em>Viterbi</em> algorithm. However, we will see that max-product (and sum-product below) can be applied in more general settings than the linear chains one finds in HMMs.</p>
<section id="id1">
<h4><span class="section-number">3.4.7.5.1. </span>Exercise<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h4>
<p>In the above, the lookup table <span class="math notranslate nohighlight">\(g_{j}(X_{j+1})\)</span> resulting from eliminating <span class="math notranslate nohighlight">\(X_j\)</span> is a function of only <span class="math notranslate nohighlight">\(X_{j+1}\)</span>, because an HMM is a <em>chain</em> of variables. Think about the more general case: what would <span class="math notranslate nohighlight">\(g\)</span> be a function of, in that case?</p>
</section>
</section>
<section id="complexity">
<h3><span class="section-number">3.4.7.6. </span>Complexity<a class="headerlink" href="#complexity" title="Permalink to this heading">#</a></h3>
<p>The complexity of max-product is <em>linear</em> in the number of nodes, which is a nice improvement over exponential complexity. The complexity of every elimination step is quadratic in the number of states, because we have to form the product factors and then maximize over them.</p>
</section>
<section id="max-product-in-gtsam">
<h3><span class="section-number">3.4.7.7. </span>Max-product in GTSAM<a class="headerlink" href="#max-product-in-gtsam" title="Permalink to this heading">#</a></h3>
<p>GTSAM’s bread and butter is factor graphs, and finding the MPE is easy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mpe</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">mpe</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Hallway</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="the-sum-product-algorithm-for-hmms">
<h2><span class="section-number">3.4.8. </span>The Sum-Product Algorithm for HMMs<a class="headerlink" href="#the-sum-product-algorithm-for-hmms" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>Sum-product on HMMs, also known as the Forward-Backward algorithm, is a dynamic-programming algorithm for doing full posterior inference.</p>
</div></blockquote>
<p>The sum-product algorithm for HMMs is a slight tweak on the max-product
algorithm that instead produces a Bayes net that calculates the
posterior probability <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>. Whereas the
max-product produces a DAG of lookup tables, the sum-product produces a
DAG of conditionals, i.e., a Bayes net. This is particularly interesting
if one is not content with a most probable explanation or MPE, but
instead wants the <strong>full Bayesian probability distribution</strong>.
The fact that we recover this distribution in the form of a Bayes net again is
satisfying, because, as we have seen, that is an economical representation of a
probability distribution.</p>
<p>One might wonder about the wisdom of all this: we started with a Bayes
net, converted to a factor graph, and now end up with a Bayes net again?
There are two important differences: the first Bayes net
represents the joint distribution <span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z})\)</span> and is
very useful for modeling. However, the second Bayes represents the
posterior <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>, and only has nodes for the
random variables in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, hence it is much smaller. Finally, in
many practical cases we do not even bother with the modeling step, but
construct the factor graph directly from the measurements.</p>
<p>Again, the key is that we can compute the posterior recursively from the product of factors, in dynamic programming style.
For the example above, this gives</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
P(\mathcal{X}|\mathcal{Z}) &amp;\propto \prod\phi_{i}(\mathcal{X}_{i})
\\&amp;\propto \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\&amp;\propto \{\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)\} ~~ \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\ &amp;\propto \{P(X_1|X_2, \mathcal{Z}) \tau(X_2)\} ~~ \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\ &amp;= P(X_1|X_2, \mathcal{Z}) ~~ P(X_2, X_3|\mathcal{Z})
\end{aligned}
\end{split}\]</div>
<p>where the last equality invoked recursion to calculate the posterior <span class="math notranslate nohighlight">\(P(X_2, X_3|\mathcal{Z})\)</span> on the remaining variables from the remaining factors. Below we assume the dependence on the given measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> (and actions, if appropriate) as implied, and drop <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> from the equations to simplify notation.</p>
<p>In contrast to max-product, we now define the factor <span class="math notranslate nohighlight">\(\tau\)</span> obtained by <em>summing</em> over the variable that is being eliminated</p>
<div class="math notranslate nohighlight">
\[
\tau(X_2)\doteq \sum_{x_1} \phi_1(X_1=x_1)\phi_2(X_1=x_1)\phi_3(X_1=x_1, X_2)
\]</div>
<p>and, from the definition of conditional probability:</p>
<div class="math notranslate nohighlight">
\[
P(X_1|X_2) = \frac{\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)}{\tau(X_2)}.
\]</div>
<p>Hence, the only tweak necessary to the max-product is to replace the maximization and <span class="math notranslate nohighlight">\(\arg \max\)</span> in the elimination step with the chain rule.
Indeed, we factor each product
factor <span class="math notranslate nohighlight">\(\phi(X_{j}, X_{j+1})\)</span> into a conditional <span class="math notranslate nohighlight">\(P(X_{j}|X_{j+1})\)</span> and
an (unnormalized) marginal <span class="math notranslate nohighlight">\(\tau(X_{j+1})\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(X_{j}|X_{j+1})\tau(X_{j+1})\gets\phi(X_{j}, X_{j+1})
\]</div>
<p>The algorithm is called the <strong>sum-product algorithm</strong> because the
marginal is obtained by summing over all values of the state <span class="math notranslate nohighlight">\(X_{j}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\tau(X_{j+1})=\sum_{x_{j}}\phi(x_{j}, X_{j+1})
\]</div>
<p>We do not bother normalizing this into a proper distribution, as these
marginals are just intermediate steps in the algorithm. However, when
computing the conditional, we do normalize, and is it so happens the
normalization constant is simply equal to <span class="math notranslate nohighlight">\(1/\tau(X_{j+1})\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(X_{j}|X_{j+1})=\frac{\phi(X_{j}, X_{j+1})}{\tau(X_{j+1})}
\]</div>
<p>The entire algorithm in pseudocode is listed below:</p>
<hr class="docutils" />
<p><code class="docutils literal notranslate"><span class="pre">SumProductHMM</span></code> (<span class="math notranslate nohighlight">\(\Phi_{1:n}\)</span>):</p>
<ul class="simple">
<li><p>for <span class="math notranslate nohighlight">\(j=1...n\)</span>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(P(X_{j}|X_{j+1}),\Phi_{j+1:n}\gets \text{ApplyChainRule}(\Phi_{j:n},X_{j})\)</span></p></li>
<li><p>return Bayes net <span class="math notranslate nohighlight">\(P(X_1|X_2)P(X_2|X_3)\ldots P(X_{n})\)</span></p></li>
</ul>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">ApplyChainRule</span></code> (<span class="math notranslate nohighlight">\(\Phi_{j:n}, X_{j}\)</span>):</p>
<ul class="simple">
<li><p>Remove all factors <span class="math notranslate nohighlight">\(\phi_{i}(\mathcal{X}_{i})\)</span> that contain <span class="math notranslate nohighlight">\(X_{j}\)</span></p></li>
<li><p>Create product factor <span class="math notranslate nohighlight">\(\phi(X_{j}, X_{j+1})\gets\prod_{i}\phi_{i}(\mathcal{X}_{i})\)</span></p></li>
<li><p>Factorize the product <span class="math notranslate nohighlight">\(P(X_{j}|X_{j+1})\tau(X_{j+1})\gets\phi(X_{j}, X_{j+1})\)</span></p></li>
<li><p>Add the new factor <span class="math notranslate nohighlight">\(\tau(X_{j+1})\)</span> back into the graph <span class="math notranslate nohighlight">\(\Phi_{j+1:n}\)</span></p></li>
<li><p>return the conditional <span class="math notranslate nohighlight">\(P(X_{j}|X_{j+1})\)</span> and reduced graph <span class="math notranslate nohighlight">\(\Phi_{j+1:n}\)</span></p></li>
</ul>
<hr class="docutils" />
<p>Note that after we recover the Bayes net the algorithm terminates: there
is no back-substitution step. However, one might consider ancestral
sampling as a type of back-substitution: the reverse elimination order
is always a topological sort of the resulting Bayes net! Hence, after
applying the sum-product algorithm, we can sample as many realizations from the
posterior as we want: rather than just one MPE, we now have access to all
plausible explanations, and ancestral sampling will yield them in
exactly the correct frequencies.</p>
<section id="sidebar">
<h3><span class="section-number">3.4.8.1. </span>Sidebar<a class="headerlink" href="#sidebar" title="Permalink to this heading">#</a></h3>
<p>When we can produce samples <span class="math notranslate nohighlight">\(\mathcal{X}^{(s)}\)</span> from a posterior
<span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>, we can calculate empirical means of any
real-valued function <span class="math notranslate nohighlight">\(f(\mathcal{X})\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[
E_{P(\mathcal{X}|\mathcal{Z})}[f(x)]\approx\sum f(\mathcal{X}^{(s)})
\]</div>
<p>For example, we can calculate the posterior mean of how far the robot
traveled, either in Euclidean or Manhattan distance, using this approach.
Doing this will provide a more reliable estiate than merely
calculating the distance for the MPE,
since this approach averages over the entire probability distribution rather
than just using a single (albeit most probable) estimate.</p>
</section>
<section id="sum-product-in-gtsam">
<h3><span class="section-number">3.4.8.2. </span>Sum-Product in GTSAM<a class="headerlink" href="#sum-product-in-gtsam" title="Permalink to this heading">#</a></h3>
<p>In GTSAM, calling <code class="docutils literal notranslate"><span class="pre">sumProduct</span></code> yields a Bayes net, which encodes the full posterior distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">posterior</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">sumProduct</span><span class="p">()</span>
<span class="n">show</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b47b43ecc9b1139aa5b102545c47245491ba1b3d965b2ef1bd9f51c4cea873a9.svg" src="_images/b47b43ecc9b1139aa5b102545c47245491ba1b3d965b2ef1bd9f51c4cea873a9.svg" /></div>
</div>
<p>One of the things we can do with this <em>exact</em> posterior is sample from it, which is one possible state history conditioned on the available sensor measurements <em>and</em> the known action sequence:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Dining Room</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can go even further: the code below samples 1000 alternate state histories, parallel universes of what <em>could</em> have happened:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">room_index</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="n">counts</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">room_index</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># base 0!</span>
</pre></div>
</div>
</div>
</div>
<p>Could we summarize these 1000 alternate histories some way other than printing all of them out? One idea is to summarize, for every time step, what the probability is to be in a particular room. It turns out we can do this with a one-liner, because we kept track of counts in the code above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="mi">100</span><span class="o">*</span><span class="n">counts</span><span class="o">/</span><span class="n">num_samples</span><span class="p">,</span>
             <span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Living Room</th>
      <th>Kitchen</th>
      <th>Office</th>
      <th>Hallway</th>
      <th>Dining Room</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>3.3</td>
      <td>1.4</td>
      <td>3.8</td>
      <td>80.6</td>
      <td>10.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.9</td>
      <td>3.8</td>
      <td>0.8</td>
      <td>5.0</td>
      <td>89.5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.9</td>
      <td>90.7</td>
      <td>0.8</td>
      <td>0.0</td>
      <td>2.6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>These approximate marginals say how probable it is that the robot was in a particular room at a particular time step. This is much richer information that what is available in the MPE, which is just a point estimate for the trajectory.</p>
</section>
<section id="id2">
<h3><span class="section-number">3.4.8.3. </span>Exercise<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>Execute the code above multiple times and observe that you <em>do</em> get different realizations (almost) every time, but that the approximate marginals stay roughly the same.</p>
</section>
</section>
<section id="gtsam-101">
<h2><span class="section-number">3.4.9. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>The GTSAM concepts used in this section, explained.</p>
</div></blockquote>
<p>We created, for the first time, an instance of the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteFactorGraph</span></code> class. The constructor is trivial - takes no arguments.
To add factors, we can use the following methods:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">j:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">j:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">spec:</span> <span class="pre">List[float])</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">keys:</span> <span class="pre">List[Tuple[int,</span> <span class="pre">int]],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
</ol>
<p>These are very similar to the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteBayesNet</span></code> methods, but in factor graphs there is a
distinction between frontal and parent values, so we just have a key, or a list of keys as in the last method.</p>
<p>Two key factor graph methods we used above are <code class="docutils literal notranslate"><span class="pre">optimize</span></code>, <code class="docutils literal notranslate"><span class="pre">maxProduct</span></code> and <code class="docutils literal notranslate"><span class="pre">sumProduct</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="n">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gtsam</span><span class="p">::</span><span class="n">DiscreteValues</span>
<span class="o">-</span> <span class="n">sumProduct</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span>
</pre></div>
</div>
<p>The first one returns the MPE as an assignment to discrete variables, whereas the second returns an entire Bayes net, encoding the posterior.</p>
<p>There is actually a method <code class="docutils literal notranslate"><span class="pre">maxProduct</span></code> as well, which we have not discussed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="n">maxProduct</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteLookupDAG</span>
</pre></div>
</div>
<p>It returns a <code class="docutils literal notranslate"><span class="pre">DiscreteLookupDAG</span></code> instance, which, similarly to a Bayes net is a DAG, but instead contains lookup tables, not conditionals:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dag</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">maxProduct</span><span class="p">()</span>
<span class="nb">type</span><span class="p">(</span><span class="n">dag</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>gtsam.gtsam.DiscreteLookupDAG
</pre></div>
</div>
</div>
</div>
<p>It’s mostly an internal data structure, and is not yet very “inspectable” in python. However, you can ask it to compute the <code class="docutils literal notranslate"><span class="pre">argmax</span></code>, which is exactly what happens <em>inside</em> <code class="docutils literal notranslate"><span class="pre">optimize</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pretty</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">argmax</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Hallway</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S33_vacuum_sensing.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3.3. </span>Dynamic Bayes Nets</p>
      </div>
    </a>
    <a class="right-next"
       href="S35_vacuum_decision.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.5. </span>Markov Decision Processes</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-in-bayes-nets">3.4.1. Inference in Bayes Nets</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-posterior-inference">3.4.1.1. Full Posterior Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#most-probable-explanation">3.4.1.2. Most Probable Explanation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#efficiency-not">3.4.1.3. Efficiency (Not!)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-a-posteriori-estimation">3.4.1.4. Maximum a Posteriori estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">3.4.1.5. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hidden-markov-models">3.4.2. Hidden Markov Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-robot-hmm">3.4.2.1. Example: Robot HMM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-inference-in-hmms">3.4.3. Naive Inference in HMMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-graphs">3.4.4. Factor Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-bayes-nets-into-factor-graphs">3.4.5. Converting Bayes Nets into Factor Graphs.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">3.4.5.1. Exercise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-graphs-in-gtsam">3.4.5.2. Factor Graphs in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-with-factor-graphs">3.4.6. Computing with Factor Graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-mpe-with-gtsam">3.4.6.1. Naive MPE with GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-max-product-algorithm-for-hmms">3.4.7. The Max-Product Algorithm for HMMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminating-x-1">3.4.7.1. Eliminating <span class="math notranslate nohighlight">\(X_1\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminating-x-2">3.4.7.2. Eliminating <span class="math notranslate nohighlight">\(X_2\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eliminating-x-3">3.4.7.3. Eliminating <span class="math notranslate nohighlight">\(X_3\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#back-substitution">3.4.7.4. Back-substitution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-max-product">3.4.7.5. Summary: Max-Product</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.4.7.5.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complexity">3.4.7.6. Complexity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#max-product-in-gtsam">3.4.7.7. Max-product in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sum-product-algorithm-for-hmms">3.4.8. The Sum-Product Algorithm for HMMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sidebar">3.4.8.1. Sidebar</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-product-in-gtsam">3.4.8.2. Sum-Product in GTSAM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.4.8.3. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">3.4.9. GTSAM 101</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>