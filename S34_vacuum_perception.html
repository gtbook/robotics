
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>3.4. Perception with Graphical Models &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-312077-7"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-312077-7');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-312077-7');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S34_vacuum_perception';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3.5. Markov Decision Processes" href="S35_vacuum_decision.html" />
    <link rel="prev" title="3.3. Dynamic Bayes Nets" href="S33_vacuum_sensing.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Introduction to Robotics and Perception - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction to Robotics and Perception
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S27_sorter_summary.html">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayes Nets</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gtbook/robotics" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS34_vacuum_perception.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S34_vacuum_perception.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Perception with Graphical Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-in-bayes-nets">3.4.1. Inference in Bayes Nets</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-posterior-inference">3.4.1.1. Full Posterior Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">3.4.1.2. Exercises</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-a-posteriori-estimation">3.4.1.3. Maximum a Posteriori Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.4.1.4. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hidden-markov-models">3.4.2. Hidden Markov Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-robot-hmm">3.4.2.1. Example: Robot HMM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-inference-in-hmms">3.4.3. Naive Inference in HMMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-graphs">3.4.4. Factor Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-bayes-nets-into-factor-graphs">3.4.5. Converting Bayes Nets into Factor Graphs.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">3.4.5.1. Exercise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-graphs-in-gtsam">3.4.5.2. Factor Graphs in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-with-factor-graphs">3.4.6. Computing with Factor Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-max-product-algorithm-for-hmms">3.4.7. The Max-Product Algorithm for HMMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#max-product-in-gtsam">3.4.7.1. Max-product in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sum-product-algorithm-for-hmms">3.4.8. The Sum-Product Algorithm for HMMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-product-in-gtsam">3.4.8.1. Sum-Product in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-and-posterior-means">3.4.9. Sampling and Posterior Means*</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.4.9.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">3.4.10. GTSAM 101</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S34_vacuum_perception.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="cell tag_hide-cell tag_no-tex docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From section 3.2:</span>
<span class="n">wxyz</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;W&quot;</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">Z1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="p">[</span><span class="n">X1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="p">[</span><span class="n">Y1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="p">[</span><span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="s2">&quot;1/1&quot;</span><span class="p">)</span>

<span class="c1"># From Section 3.3:</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">light_levels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="perception-with-graphical-models">
<h1><span class="section-number">3.4. </span>Perception with Graphical Models<a class="headerlink" href="#perception-with-graphical-models" title="Link to this heading">#</a></h1>
<blockquote>
<div><p>Perception for dynamic Bayes nets is equivalent to inference in hidden Markov models (HMMs).</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S34-iRobot_vacuuming_robot-05.jpg"><img alt="Splash image with deeply contemplative robot" class="align-center" src="_images/S34-iRobot_vacuuming_robot-05.jpg" style="width: 40%;" /></a>
<p>Now that we have a solid mathematical framework to work in, in the remainder of this chapter we will tackle perception, decision-making based on this, and learning to improve both. We used the vacuum cleaning robot as an example system that has discrete states, with actions that mediate discrete-time state transitions, and emitting noisy measurements at every step. The key mathematical concept that tied all this together was the language of dynamic Bayes nets.</p>
<p>In this section we tackle <em>perception</em> in this setting: can we, by remembering which actions we took and what measurements we observed, infer what states we were in and are likely to be in now?
We more formally define what we mean by inference, building on the methods introduced in Section 2.4.
Just as we did there, we will characterize what we know and don’t know using probability distributions, leaning into the Bayesian view even more.
However, here we will consider probability distributions over <em>sequences</em> of states, rather than just the current state.</p>
<p>To this end, we introduce one of the most important tools used throughout this book: <strong>factor graphs</strong>. Bayes nets are great for <em>modeling</em>, but for inferring the state of the robot over time <em>efficiently</em> we need a better data structure.
We first introduce hidden Markov models (HMMs), and highlight their connection with robot localization over time. We then show how to efficiently perform inference by converting an HMM into a factor graph, and performing full posterior inference and MAP estimation in linear time.</p>
<section id="inference-in-bayes-nets">
<h2><span class="section-number">3.4.1. </span>Inference in Bayes Nets<a class="headerlink" href="#inference-in-bayes-nets" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Inference begets the full posterior or a single maximum a posteriori estimate.</p>
</div></blockquote>
<p><strong>Inference</strong> is the process of determining knowledge about a set of
variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> given the known values for another set of variables <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.
In this section we will describe inference when the joint
distribution is specified using a Bayes net, but we will not take
advantage of the specific sparse structure of the network.
Hence, the algorithms
below are completely general, for any (discrete) joint probability
distribution, as long as we can evaluate the joint distribution.</p>
<section id="full-posterior-inference">
<h3><span class="section-number">3.4.1.1. </span>Full Posterior Inference<a class="headerlink" href="#full-posterior-inference" title="Link to this heading">#</a></h3>
<blockquote>
<div><p>Naive full posterior inference is <em>easy</em> but probably expensive.</p>
</div></blockquote>
<p>The simplest kind of inference occurs when we can <em>partition</em> the variables into two
sets: the <strong>hidden variables</strong> <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and the <strong>observations</strong>
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>. First, let us recall what a Bayes net looks like in this case.
From Section 3.2, we have that a general Bayes net over any set of variables is defined as a product of conditionals, hence in our case we would have</p>
<div class="math notranslate nohighlight">
\[
P(\mathcal{X}, \mathcal{Z}) = \prod_{i=1}P(X_{i}|\Pi_{X_i}) \prod_{j=1}P(Z_{j}|\Pi_{Z_j})
\]</div>
<p>where there is no restriction on the parent sets <span class="math notranslate nohighlight">\(\Pi\)</span>, just that the directed graph is acyclic. Of course, we will be most interested here in dynamic Bayes nets as defined previously, but for now what follows applies to generic Bayes nets.</p>
<p>The workhorse in inference is Bayes’ law, which we encountered in the perception section of the previous chapter, Section 2.4.
Let us define <span class="math notranslate nohighlight">\(\mathfrak{z}\)</span> as the set of observed <em>values</em> for all variables in
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.
We then are interested, <em>given</em> the values <span class="math notranslate nohighlight">\(\mathfrak{z}\)</span> for the observed values <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, in calculating the posterior probability distribution <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})\)</span>.
To calculate this we apply Bayes’ law, but now applied to
<em>sets</em> of variables, to obtain an expression for the posterior over the
hidden variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Using the “easy” version of Bayes’ theorem from Section 2.4,
we just re-write the posterior as the joint, but with the values <span class="math notranslate nohighlight">\(\mathfrak{z}\)</span> for all variables in
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> instantiated:</p>
<div class="math notranslate nohighlight">
\[
P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})\propto P(\mathcal{X}, \mathcal{Z}=\mathfrak{z}).
\]</div>
<p>This seems almost too simple, but it really works, as shown in a small generic Bayes net example below. Let us recall the 4-variable Bayes net example on variables <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>, <span class="math notranslate nohighlight">\(W\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span>, and let us take <span class="math notranslate nohighlight">\(\mathcal{X}=(X, Y)\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Z}=(W, Z)\)</span> - which we indicate in the figure by rendering <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> as boxes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Bayes net for the 4-variable model, again.</span>
<span class="c1">#| label: fig:bayesnet_4</span>
<span class="n">show</span><span class="p">(</span><span class="n">wxyz</span><span class="p">,</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">Z1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">W1</span><span class="p">[</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0d17836b7e3b810215e982441e5c9ef7210e1fbc58c3492108ea38e53b2e86c8.svg" src="_images/0d17836b7e3b810215e982441e5c9ef7210e1fbc58c3492108ea38e53b2e86c8.svg" /></div>
</div>
<p>Bayes’ law as applied above suggests an easy algorithm to calculate the posterior distribution
above: simply enumerate all tuples <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> in a table, evaluate
<span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z}=\mathfrak{z})\)</span> for each one, and then
normalize. Note we need <em>only</em> enumerate the variables in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, as all variables in <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> are fixed.</p>
<p>Applying this to our example entails evaluating 100 probabilities, if we assume -as before - that each variable can take on 10 different outcomes. We show the resulting table for the case that <span class="math notranslate nohighlight">\(\mathfrak{z}=(2, 7)\)</span>, i.e., every entry in the table is a value for <span class="math notranslate nohighlight">\(P(X, Y|W=2, Z=7)\propto P(W=2, X, Y, Z=7)\)</span>. Below we show the factorized joint probability, to make a point:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p><em>x</em></p></th>
<th class="head text-center"><p><em>y</em></p></th>
<th class="head text-center"><p><em>P(W=2, X=x, Y=y, Z=7)</em></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p><em>P(W=2|X=1, Z=7)P(X=1|Y=1, Z=7)P(Y=1|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p><em>P(W=2|X=1, Z=7)P(X=1|Y=2, Z=7)P(Y=2|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>10</p></td>
<td class="text-center"><p>9</p></td>
<td class="text-center"><p><em>P(W=2|X=10, Z=7)P(X=10|Y=9, Z=7)P(Y=9|Z=7)P(Z=7)</em></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>10</p></td>
<td class="text-center"><p>10</p></td>
<td class="text-center"><p><em>P(W=2|X=10, Z=7)P(X=10|Y=10, Z=7)P(Y=10|Z=7)P(Z=7)</em></p></td>
</tr>
</tbody>
</table>
</div>
<p>We normalize by calculating <span class="math notranslate nohighlight">\(\sum_{x, y} P(W=2, X=x, Y=y, Z=7)\)</span> by summing over all these entries, and subsequently dividing all entries by the sum.</p>
<p>Estimating the full posterior using this approach is, obviously, <em>not</em> efficient.
In this example the table contains 100 entries, and in
general the number of entries is <em>exponential</em> in the size of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span>.
However, when inspecting the entries in the table
there are already some obvious ways to save: for example, <span class="math notranslate nohighlight">\(P(Z=7)\)</span> is a
common factor in all entries, so clearly we need not bother
multiplying it in. Below we will discuss methods to fully
exploit the structure of the Bayes net to perform efficient inference.</p>
</section>
<section id="exercises">
<h3><span class="section-number">3.4.1.2. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Think more deeply about which other factors get repeatedly (and redundantly) calculated, and how you might organize the computation to avoid this.</p></li>
<li><p>Show that in the example above, if we instead condition on known values for <span class="math notranslate nohighlight">\(\mathcal{Z}=(X,Z)\)</span>, the posterior <span class="math notranslate nohighlight">\(P(W,Z|X,Y)\)</span> factors, and as a consequence we only have to enumerate two tables of length 10, instead of a large table of size 100.</p></li>
</ol>
</section>
<section id="maximum-a-posteriori-estimation">
<h3><span class="section-number">3.4.1.3. </span>Maximum a Posteriori Estimation<a class="headerlink" href="#maximum-a-posteriori-estimation" title="Link to this heading">#</a></h3>
<blockquote>
<div><p>MAP saves a bit on compute, but is still expensive when done naively.</p>
</div></blockquote>
<p>For the purpose of decision making,
it is often the case that we do not require the full posterior distribution.
In these cases, we could rely on methods introduced in Section 2.4,
such as Maximum Likelihood Estimation (MLE)
or Maximum a posteriori (MAP) estimation.
Here, we consider MAP estimation.</p>
<p>Suppose we are given the values
<span class="math notranslate nohighlight">\(\mathfrak{z}\)</span> for <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.
The MAP estimate of the
joint assignment to the other variables <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[x^*_{MAP} = \arg \max_x P(\mathcal{X}|\mathcal{Z}=\mathfrak{z}).\]</div>
<p>For example, given
<span class="math notranslate nohighlight">\(\mathfrak{z}=(2, 7)\)</span>, the MAP estimate for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> could be <span class="math notranslate nohighlight">\(x^*=3\)</span> and
<span class="math notranslate nohighlight">\(y^*=6\)</span>. Note that to compute the MAP estimate, we need not bother with
normalizing: we can simply find the maximum entry in a table of <em>unnormalized</em>
posterior values.</p>
<p><strong>Robot localization</strong> is a capability for autonomous mobile robots that can be achieved via MAP estimation.
For example, using the “robot” dynamic Bayes net example from the last section, let us
assume that we are given the value of all observations and actions.
Then the MAP estimate would simply be a trajectory of robot states.
Hence, if we had an efficient way to do inference, a MAP estimate would be a
great way to estimate the trajectory of a robot over time, i.e., robot localization.</p>
<p>We can extend the idea of MAP to estimate only a subset of the unknown variables.
This can be useful when there are unknown variables that are not relevant
for the decision at hand.
We will refer to these unknown and irrelevant variables as <strong>nuisance variables</strong>.
In this case, we partition the variables into three sets:
the variables of interest <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>,
the nuisance variables <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, and the observed variables
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.
Now, the posterior <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})\)</span>
can be determined by marginalizing (Section 2.4.7) over
the nuisance variables:</p>
<div class="math notranslate nohighlight">
\[
P(\mathcal{X}|\mathcal{Z}=\mathfrak{z})=\sum_{\mathfrak{y}}P(\mathcal{X}, \mathcal{Y}=\mathfrak{y}|\mathcal{Z}=\mathfrak{z})\propto\sum_{\mathfrak{y}}P(\mathcal{X}, \mathcal{Y}=\mathfrak{y}, \mathcal{Z}=\mathfrak{z}).
\]</div>
<p>This approach to dealing with nuisance variables
increases the computational cost of finding the MAP estimate.
In
addition to enumerating all possible combinations of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> values, we now need to calculate
a possibly large number of sums, each exponential in the size of
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. In addition, the <em>number</em> of sums is
exponential in the size of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Below we will see that
while we can still exploit the Bayes net structure,
this computation can still be quite expensive.</p>
</section>
<section id="id1">
<h3><span class="section-number">3.4.1.4. </span>Exercises<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Calculate the size of the table needed to enumerate the posterior
over the states <span class="math notranslate nohighlight">\(S\)</span> the robot dynamic Bayes net from the previous section,
given the value of all observations <span class="math notranslate nohighlight">\(Z\)</span> and actions <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>Show that if we are given the states, inferring the actions is
actually quite efficient, even with the brute force enumeration.
Hint: this is similar to the first exercise above.</p></li>
</ol>
</section>
</section>
<section id="hidden-markov-models">
<h2><span class="section-number">3.4.2. </span>Hidden Markov Models<a class="headerlink" href="#hidden-markov-models" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>HMMs provide a general framework for perception over time.</p>
</div></blockquote>
<p>In the previous section we discussed dynamic Bayes networks to model how a robot state evolves over time by taking actions, and how measurements correlate to a particular state. In this section we will ask <em>how we can recover the state of the robot given only the observations</em>, i.e. without knowing the states: the state is “hidden”. Here we will consider a general framework to answer this question.</p>
<p>A <strong>hidden Markov model</strong> or HMM is a dynamic Bayes net that has two
types of variables: states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>.
The states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> are connected sequentially and satisfy the Markov property:
the probability of a state <span class="math notranslate nohighlight">\(X_k\)</span> is
only dependent on the value of the previous state <span class="math notranslate nohighlight">\(X_{k-1}\)</span>. As we saw before, we call a sequence of random variables with this property a <strong>Markov chain.</strong>
In addition, in an HMM we refer to the states <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> as <em>hidden</em>
states, as typically we cannot directly observe their values. Instead,
they are indirectly observed through the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>,
where we have one measurement per hidden state. When these two
properties are satisfied, we call this probabilistic model a hidden
Markov model.</p>
<figure id="fig:unrolledHMM"> 
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/hmm-v2.png?raw=1" style="width:14cm" alt="">
<figcaption>An HMM for three time-steps, represented as a Bayes net.</figcaption>
</figure>
<p>Figure
<a href="#fig:unrolledHMM" data-reference-type="ref" data-reference="fig:unrolledHMM">3.9</a>
shows an example of an HMM for three time steps, i.e..,
<span class="math notranslate nohighlight">\(\mathcal{X}=\{X_1, X_2, X_3\}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Z}=\{Z_1, Z_2, Z_3\}\)</span>. As discussed above, in a Bayes net
each node is associated with a conditional distribution: the Markov
chain has the prior <span class="math notranslate nohighlight">\(P(X_1)\)</span> and transition probabilities
<span class="math notranslate nohighlight">\(P(X_2|X_1)\)</span> and <span class="math notranslate nohighlight">\(P(X_3|X_2)\)</span>, whereas the measurements <span class="math notranslate nohighlight">\(Z_k\)</span>
depend only on the state <span class="math notranslate nohighlight">\(X_k\)</span>, modeled by measurement models
<span class="math notranslate nohighlight">\(P(Z_k|X_k)\)</span>. In other words, the Bayes net associated with this HMM encodes the following
joint distribution <span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z})\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X}, \mathcal{Z})=P(X_1)P(Z_1|X_1)P(X_2|X_1)P(Z_2|X_2)P(X_3|X_2)P(Z_3|X_3)\]</div>
<p>Note that we can also write this more succinctly as</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X}, \mathcal{Z})=P(\mathcal{Z}|\mathcal{X})P(\mathcal{X})\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{X})=P(X_1, X_2, X_3)=P(X_1)P(X_2|X_1)P(X_3|X_2)\]</div>
<p>is the prior over state <em>trajectories</em>.</p>
<section id="example-robot-hmm">
<h3><span class="section-number">3.4.2.1. </span>Example: Robot HMM<a class="headerlink" href="#example-robot-hmm" title="Link to this heading">#</a></h3>
<p>Let us re-create the dynamic Bayes net from the previous section here, with 3 time steps. However, we now also add conditionals on the three measurements <span class="math notranslate nohighlight">\(Z_1\)</span>, <span class="math notranslate nohighlight">\(Z_2\)</span>, and <span class="math notranslate nohighlight">\(Z_3\)</span>. We show the measurement variables as boxes, as they are <em>given</em>. The only variables that are unknown or <em>hidden</em> are the three robots states <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, and <span class="math notranslate nohighlight">\(X_3\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dbn</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">sensor_spec</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)):</span>
    <span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
<span class="n">dbn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1/1/1/1/1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A hidden Markov model.</span>
<span class="c1">#| label: fig:hmm_vacuum</span>
<span class="n">show</span><span class="p">(</span><span class="n">dbn</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)}</span><span class="o">.</span><span class="n">union</span><span class="p">({</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)}))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5a48b9c6fe8e88114ef9ec5cc49a75871f1dc7d7589baa007b990d0c2fd311ca.svg" src="_images/5a48b9c6fe8e88114ef9ec5cc49a75871f1dc7d7589baa007b990d0c2fd311ca.svg" /></div>
</div>
</section>
</section>
<section id="naive-inference-in-hmms">
<h2><span class="section-number">3.4.3. </span>Naive Inference in HMMs<a class="headerlink" href="#naive-inference-in-hmms" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Inference is easy to implement naively, but hopelessly inefficient.</p>
</div></blockquote>
<p>As we saw above,
one way to perform inference is to apply Bayes’ rule to obtain an expression for the <em>posterior</em> probability distribution over
the state trajectory <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, given the measurements
<span class="math notranslate nohighlight">\(\mathcal{Z}=\mathfrak{z}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
P(\mathcal{X}|\mathcal{Z}) &amp; \propto P(\mathcal{Z}=\mathfrak{z}|\mathcal{X})P(\mathcal{X}) \\
&amp; =L(\mathcal{X}; \mathcal{Z}=\mathfrak{z})P(\mathcal{X})\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(P(\mathcal{X})\)</span> is the trajectory prior
and the <strong>likelihood</strong> <span class="math notranslate nohighlight">\(L(\mathcal{X}; \mathcal{Z}=\mathfrak{z})\)</span> of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> given <span class="math notranslate nohighlight">\(\mathcal{Z}=\mathfrak{z}\)</span> is defined as before as a function of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\mathcal{X}; \mathcal{Z}=\mathfrak{z}) &amp; \propto P(\mathcal{Z}=\mathfrak{z}|\mathcal{X})\\
&amp; =P(z_1|X_1)P(z_2|X_2)P(z_3|X_3)\\
&amp; \propto L(X_1; Z_1)L(X_2; Z_2)L(X_3; Z_3)\end{aligned}
\end{split}\]</div>
<p>Hence, a naive implementation for finding the MAP estimate
for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> would tabulate all possible
trajectories <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and calculate the posterior <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span> for each one.
Unfortunately the number of entries in this giant table is
<em>exponential</em> in the number of states. Not only is this computationally
prohibitive for long trajectories, but intuitively it is clear that for
many of these trajectories we are computing the same values over and
over again. There are three different approaches to improve on
this:</p>
<ol class="arabic simple">
<li><p>Branch &amp; bound</p></li>
<li><p>Dynamic programming</p></li>
<li><p>Inference using factor graphs</p></li>
</ol>
<p>Branch and bound is a powerful technique but will not generalize to
continuous variables; the other two approaches will. And, we will
see that dynamic programming, which underlies the classical inference
algorithms in the HMM literature, is just a special case of the last
approach. Hence, here we will dive in and immediately go for the most
general approach: inference in factor graphs.</p>
</section>
<section id="factor-graphs">
<h2><span class="section-number">3.4.4. </span>Factor Graphs<a class="headerlink" href="#factor-graphs" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Factor graphs are an excellent representation in which to do inference.</p>
</div></blockquote>
<p>We first introduce the notion of factors.
Again referring to the example from Figure
<a href="#fig:unrolledHMM" data-reference-type="ref" data-reference="fig:unrolledHMM">1</a>,
let us consider the posterior.
Since the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> are <em>known</em>, the posterior is
proportional to the product of six <strong>factors</strong>, three of which derive
from the Markov chain, and three of which are likelihood factors as defined
above:</p>
<div class="math notranslate nohighlight">
\[
P(\mathcal{X}|\mathcal{Z})\propto P(X_1)L(X_1; z_1)P(X_2|X_1)L(X_2; z_2)P(X_3|X_2)L(X_3; z_3)
\]</div>
<p>Some of these factors are <strong>unary factors</strong>, and some are <strong>binary factors</strong>.
By which we mean: some of the factors depend on just <em>one</em> hidden variable,
for example <span class="math notranslate nohighlight">\(L(X_2; z_2)\)</span>, whereas others depend on <em>two</em> variables, e.g., the
transition model <span class="math notranslate nohighlight">\(P(X_3|X_2)\)</span>.
Measurements are not counted here,
because once we are <em>given</em> the measurements <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, they merely
function as known parameters in the likelihoods <span class="math notranslate nohighlight">\(L(X_k; z_k)\)</span>, which
are seen as functions of <em>just</em> the state <span class="math notranslate nohighlight">\(X_k\)</span>, i.e., they will yield unary factors in the unknowns.</p>
<figure id="fig:HMM-FG">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/fg-v2.png?raw=1" style="width:60%" alt="">
<figcaption>An HMM with observed measurements for three time steps, represented as a factor graph.</figcaption>
</figure>
<p>This motivates a different graphical model, a <strong>factor graph</strong>, in which
we only represent the <em>hidden</em> variables <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, and <span class="math notranslate nohighlight">\(X_3\)</span>,
connected to factors that encode probabilistic information. For
our example with three hidden states, the corresponding factor graph is
shown in Figure
<a href="#fig:HMM-FG" data-reference-type="ref" data-reference="fig:HMM-FG">2</a> above.
It should be clear from the figure that the connectivity of a factor
graph encodes, for each factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span>, which subset of variables
<span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span> it depends on. We write:</p>
<div class="math notranslate nohighlight">
\[
\phi(\mathcal{X})=\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)\phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\]</div>
<p>where the factors above are defined to correspond one-to-one to the six factors in the posterior,
e.g.,</p>
<div class="math notranslate nohighlight">
\[\phi_6(X_3)\doteq L(X_3; z_3).\]</div>
<p>All measurements are associated with unary factors, whereas the Markov chain is
associated mostly with binary factors, with the exception of the unary
factor <span class="math notranslate nohighlight">\(\phi_1(X_1)\)</span>. Note that in defining the factors we can omit
any normalization factors, which in many cases results in computational
savings.</p>
<p>Formally a factor graph is a bipartite graph
<span class="math notranslate nohighlight">\(F=(\mathcal{U}, \mathcal{V}, \mathcal{E})\)</span> with two types of nodes:
<strong>factors</strong> <span class="math notranslate nohighlight">\(\phi_{i}\in\mathcal{U}\)</span> and <strong>variables</strong>
<em><span class="math notranslate nohighlight">\(X_{j}\in\mathcal{V}\)</span>.</em> Edges <span class="math notranslate nohighlight">\(e_{ij}\in\mathcal{E}\)</span> are always between
factor nodes and variables nodes, never between variables or between factors.
The set of random variable nodes
adjacent to a factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span> is written as <span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span>. With
these definitions, a factor graph <span class="math notranslate nohighlight">\(F\)</span> defines the factorization of a
global function <span class="math notranslate nohighlight">\(\phi(\mathcal{X})\)</span> as</p>
<div class="math notranslate nohighlight">
\[\phi(\mathcal{X})=\prod_{i}\phi_{i}(\mathcal{X}_{i}).\]</div>
<p>In other words, the independence relationships are encoded by the edges
<span class="math notranslate nohighlight">\(e_{ij}\)</span> of the factor graph, with each factor <span class="math notranslate nohighlight">\(\phi_{i}\)</span> a function of
<em>only</em> the variables <span class="math notranslate nohighlight">\(\mathcal{X}_{i}\)</span> in its adjacency set. As example,
for the factor graph in Figure
<a href="#fig:HMM-FG" data-reference-type="ref" data-reference="fig:HMM-FG">2</a>
we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{X}_1 &amp; =\{X_1\}\\
\mathcal{X}_2 &amp; =\{X_1\}\\
\mathcal{X}_3 &amp; =\{X_1, X_2\}\\
\mathcal{X}_4 &amp; =\{X_2\}\\
\mathcal{X}_5 &amp; =\{X_2, X_3\}\\
\mathcal{X}_6 &amp; =\{X_3\}\end{aligned}
\end{split}\]</div>
</section>
<section id="converting-bayes-nets-into-factor-graphs">
<h2><span class="section-number">3.4.5. </span>Converting Bayes Nets into Factor Graphs.<a class="headerlink" href="#converting-bayes-nets-into-factor-graphs" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>It is trivial to convert Bayes nets into factor graphs.</p>
</div></blockquote>
<figure id="fig:conversion">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/hmm-v2.png?raw=1" style="width:12cm" alt="">
<figcaption>Bayes net representation of an HMM.</figcaption>
</figure>
<figure id="fig:conversion-2">
<img src="https://raw.githubusercontent.com/gtbook/robotics/main/Figures3/fg-v2.png?raw=1"  style="width:14cm" alt="">
<figcaption>Conversion of HMM above to a factor graph, where measurements are known.</figcaption>
</figure>
<p>Every Bayes net can be trivially converted to a factor graph, as shown above.
Recall that every node in a Bayes net denotes a conditional density on the
corresponding variable and its parent nodes. Hence, the conversion is
quite simple: every Bayes net node maps to <em>both</em> a variable node and
a factor node in the corresponding factor graph. The factor is connected
to the variable node, as well as the variable nodes corresponding to the
parent nodes in the Bayes net. If some nodes in the Bayes net are
evidence nodes, i.e., they are given as known variables, we omit the
corresponding variable nodes: the known variable simply becomes a fixed
parameter in the corresponding factor.</p>
<section id="exercise">
<h3><span class="section-number">3.4.5.1. </span>Exercise<a class="headerlink" href="#exercise" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Convert the dynamic Bayes net from the previous section into a factor graph, assuming <em>no</em> known variables.</p></li>
<li><p>Finally, do the same again, but now assume the states are given. Reflect on the remarkable phenomenon that happens.</p></li>
</ol>
</section>
<section id="factor-graphs-in-gtsam">
<h3><span class="section-number">3.4.5.2. </span>Factor Graphs in GTSAM<a class="headerlink" href="#factor-graphs-in-gtsam" title="Link to this heading">#</a></h3>
<p>Let us create the factor graph directly using GTSAM. Before we do, however, we need to instantiate the given actions and measurements, both of which are assumed known:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actions</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="s1">&#39;R&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="s1">&#39;U&#39;</span><span class="p">})</span>
<span class="n">measurements</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dark&#39;</span><span class="p">,</span> <span class="s1">&#39;medium&#39;</span><span class="p">,</span> <span class="s1">&#39;light&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now we create the factor graph, first adding the prior <span class="math notranslate nohighlight">\(\phi(X_1)=P(X_1)\)</span> on <span class="math notranslate nohighlight">\(X_1\)</span>, then the binary factors <span class="math notranslate nohighlight">\(\phi(X_k, X_{k+1}) = P(X_{k+1}|X_k, A_k=a_k)\)</span>,
and finally, the measurement likelihood factors <span class="math notranslate nohighlight">\(\phi(X_k; Z_k=z_k) \propto P(Z_k=z_k|X_k)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">graph</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteFactorGraph</span><span class="p">()</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1 1 1 1 1&quot;</span><span class="p">)</span>  <span class="c1"># \phi(X_1) = P(X_1)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">conditional</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
    <span class="n">conditional_a_k</span> <span class="o">=</span> <span class="n">conditional</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>  <span class="c1"># \phi(X,X+) = P(X+|X,A=a)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">conditional_a_k</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">measurement</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">measurements</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">conditional</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">sensor_spec</span><span class="p">)</span>
    <span class="n">z_k</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">light_levels</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">measurement</span><span class="p">)</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="n">conditional</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">z_k</span><span class="p">)</span>  <span class="c1"># \phi(X) = P(Z=z|X)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A three-variable factor graph for when measurements are *given*</span>
<span class="c1">#| label: fig:factor_graph_vacuum</span>
<span class="n">show</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0ed1dc1e2bfffe9b4bad143b03c2443278823bda1718796525bc17e82cb36893.svg" src="_images/0ed1dc1e2bfffe9b4bad143b03c2443278823bda1718796525bc17e82cb36893.svg" /></div>
</div>
<p>Note that discrete distributions like <span class="math notranslate nohighlight">\(P(X_1)\)</span> and conditionals <span class="math notranslate nohighlight">\(P(X_{k+1}|X_k)\)</span>, above, are perfectly fine factors, and in fact <em>derive</em> from the factor type in GTSAM. This is what allows us to add them directly the graph as is. Note that in a real implementation we might not take the detour to first construct the conditionals as above: we did so because they were conveniently available here, but typically we would construct factors directly.</p>
</section>
</section>
<section id="computing-with-factor-graphs">
<h2><span class="section-number">3.4.6. </span>Computing with Factor Graphs<a class="headerlink" href="#computing-with-factor-graphs" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>We can evaluate, optimize, and sample from factor graphs.</p>
</div></blockquote>
<p>Once we convert a Bayes net with evidence into a factor graph where the
evidence is all implicit in the factors, we can support a number of
different computations. First, given any factor graph defining an
unnormalized density <span class="math notranslate nohighlight">\(\phi(X)\)</span>, we can easily <strong>evaluate</strong> it for any
given value, by simply evaluating every factor and multiplying the
results. The factor graph represents the unnormalized posterior, i.e.,
<span class="math notranslate nohighlight">\(\phi(\mathcal{X})\propto P(\mathcal{X}|\mathcal{Z})\)</span>.</p>
<p>Evaluation opens up the way to <strong>optimization</strong>, e.g., finding the MAP estimate,
as we will do below.
The naive optimization method of enumerating and
evaluating all possible assignments for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is of course always available,
but just as inefficient.
In the case of discrete variables, graph search methods can be applied, but we will discuss a
different approach in the next sub-section.</p>
<p>Because our factor graph is so small, it does not hurt to show off how easy it is to implement the naive algorithm to find the MAP estimate. We just loop over all possible state trajectories, and keep track of the one with the highest value:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">map_value</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">map_trajectory</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">for</span> <span class="n">x1</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">x2</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x3</span> <span class="ow">in</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">:</span>
            <span class="n">trajectory</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">x1</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">x2</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">x3</span><span class="p">})</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">graph</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">map_value</span><span class="p">:</span>
                <span class="n">map_value</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">map_trajectory</span> <span class="o">=</span> <span class="n">trajectory</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;found MAP solution with value </span><span class="si">{</span><span class="n">map_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">map_trajectory</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>found MAP solution with value 0.3277:
</pre></div>
</div>
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Hallway</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note that this MAP estimate is <em>for a given action and measurement sequence</em>. All those fixed values are implicit in the factors that we have added to the factor graph in <code class="docutils literal notranslate"><span class="pre">graph</span></code> above.</p>
<p>Finally, while finding the maximum of the posterior (MAP) is often of most
interest, <strong>sampling</strong> from a probability distribution can be used to
visualize, explore, and compute statistics and expected values
associated with the posterior. The ancestral sampling method we
discussed earlier only applies to Bayes bets, however.
There are more general sampling algorithms that can be used for factor
graphs.
One such method is <strong>Gibbs sampling</strong>, which proceeds by sampling one variable
at a time from its conditional density given all other variables it is
connected to via factors. This assumes that this conditional density can
be easily obtained, which is true for discrete variables.</p>
</section>
<section id="the-max-product-algorithm-for-hmms">
<h2><span class="section-number">3.4.7. </span>The Max-Product Algorithm for HMMs<a class="headerlink" href="#the-max-product-algorithm-for-hmms" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Max-product on HMMs, also known as the Viterbi algorithm, is a dynamic-programming algorithm for finding a
MAP estimate.</p>
</div></blockquote>
<p>In this section we discuss an algorithm that is much faster than the naive algorithm to find the MAP estimate.
Given an HMM factor graph of size <span class="math notranslate nohighlight">\(n\)</span>, the <strong>max-product algorithm</strong> is an <span class="math notranslate nohighlight">\(O(n)\)</span> algorithm
to find the MAP estimate, which is used by GTSAM under the hood.</p>
<p>Let us use the example from Figure
<a href="#fig:HMM-FG" data-reference-type="ref" data-reference="fig:HMM-FG">2</a>
to understand the main idea behind it. To find the MAP estimate for <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> we need to
<em>maximize</em> the product</p>
<div class="math notranslate nohighlight">
\[\phi(X_1, X_2, X_3)=\prod\phi_{i}(\mathcal{X}_{i})\]</div>
<p>i.e., the value of the factor graph.
Because this is a product of factor values, we can compute its maximum recursively - dynamic programming style. We start by writing out the maximization over the product explicitly:</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathcal{X}} \prod\phi_{i}(\mathcal{X}_{i}) = 
\max_{X_1, X_2, X_3} ~~~\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3) 
\]</div>
<p>The key to our recursion will be to consider each variable in turn, starting with <span class="math notranslate nohighlight">\(X_1\)</span>. In particular, let us group all the factors connected to <span class="math notranslate nohighlight">\(X_1\)</span></p>
<div class="math notranslate nohighlight">
\[
\max_{\mathcal{X}} \prod\phi_{i}(\mathcal{X}_{i}) = 
\max_{X_1, X_2, X_3} ~~~ \{ \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \} ~~~ \phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3)
\]</div>
<p>which allows us to move the <em>max</em> operator over <span class="math notranslate nohighlight">\(X_1\)</span> inside:</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathcal{X}} \prod\phi_{i}(\mathcal{X}_{i}) = 
\max_{X_2, X_3} ~~~ \{ \max_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \} ~~~ \phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3)
\]</div>
<p>The key to the recursion is that we can simply consider the expression inside the curly braces as new factor on <span class="math notranslate nohighlight">\(X_2\)</span>, defined as</p>
<div class="math notranslate nohighlight">
\[\tau(X_2)\doteq \max_{X_1} \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2),\]</div>
<p>which records the maximum value resulting from <em>only</em> maximizing <span class="math notranslate nohighlight">\(X_1\)</span>. The value of the computation depends on the value of <span class="math notranslate nohighlight">\(X_2\)</span>, because <span class="math notranslate nohighlight">\(X_2\)</span> was involved in factor <span class="math notranslate nohighlight">\(\phi_3\)</span>. However, crucially, the variable <span class="math notranslate nohighlight">\(X_3\)</span> is not involved in the maximization.</p>
<p>Substituting the new factor into the maximization, we now need to maximize over a <em>reduced</em> factor graph that no longer is a function of <span class="math notranslate nohighlight">\(X_1\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathcal{X}} \prod\phi_{i}(\mathcal{X}_{i}) =
\max_{X_2, X_3} ~~~\tau(X_2) \phi_4(X_2)\phi_5(X_2, X_3)\phi_6(X_3)
\]</div>
<p>and this allows us to recurse until no more variables are left!</p>
<p>For hidden Markov models this dynamics programming approach is known as the <strong>Viterbi Algorithm</strong>. Note that the algorithmic sketch above only yields the <em>value</em> of the factor graph at the maximum. A key part of the Viterbi algorithm is adding some book-keeping that after the recursion terminates, we can recover the actual variable assignments that make the factor graph attain its maximum value.
Also, the complexity of max-product for HMMs is <em>linear</em> in the number of nodes, which is a nice improvement over exponential complexity. The complexity of every elimination step is quadratic in the number of states, because we have to form the product factors and then maximize over them.</p>
<p>Because at every step, one variable is eliminated from the maximization, the max-product algorithm is in fact an instance of the <strong>elimination algorithm</strong>, which works for <em>arbitrary</em> factor graphs, albeit not necessarily in <span class="math notranslate nohighlight">\(O(n)\)</span> time. Indeed, the max-product (and sum-product below) can be applied in more general settings than the linear chains one finds in HMMs.</p>
<section id="max-product-in-gtsam">
<h3><span class="section-number">3.4.7.1. </span>Max-product in GTSAM<a class="headerlink" href="#max-product-in-gtsam" title="Link to this heading">#</a></h3>
<p>GTSAM’s bread and butter is factor graphs, and finding the MAP value is done via a single <code class="docutils literal notranslate"><span class="pre">optimize</span></code> call, which implements the max-product algorithm internally, book-keeping and all:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">map_value</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">map_value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Hallway</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The resulting <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteValues</span></code> instance corresponds to the MAP trajectory given the actions and measurements at every step. And, of course, this generalizes to much larger sequences, scaling only linearly in complexity with the number of time-steps.</p>
</section>
</section>
<section id="the-sum-product-algorithm-for-hmms">
<h2><span class="section-number">3.4.8. </span>The Sum-Product Algorithm for HMMs<a class="headerlink" href="#the-sum-product-algorithm-for-hmms" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Sum-product on HMMs is a dynamic-programming algorithm for doing full posterior inference.</p>
</div></blockquote>
<p>The sum-product algorithm for HMMs is a slight tweak on the max-product
algorithm that instead calculates the posterior probability <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>.
Whereas the max-product results in a single variable assignment, the sum-product produces a Bayes net that represents the <em>full Bayesian probability distribution</em>.
The fact that we recover this distribution in the form of a Bayes net again is
satisfying, because, as we have seen, that is an economical representation of a
probability distribution.</p>
<p>One might wonder about the wisdom of all this: we started with a Bayes
net, converted to a factor graph, and now end up with a Bayes net again?
There are two important differences.
First, in many practical cases we do not even bother with the modeling step, but
construct the factor graph directly from the measurements.
Second, even if we did, this first Bayes represents the joint
distribution <span class="math notranslate nohighlight">\(P(\mathcal{X}, \mathcal{Z})\)</span>, useful for modeling and simulation.
However, the second, “posterior Bayes net” represents just <span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>, and only has nodes for the random variables in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and is only half the size. Below we show how to compute it.</p>
<p>Again, the key is that we can compute the posterior recursively from the product of factors, in dynamic programming style.
For the example above, this gives</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
P(\mathcal{X}|\mathcal{Z}) &amp;\propto \prod\phi_{i}(\mathcal{X}_{i})
\\&amp;\propto \phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\\&amp;\propto \{\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2)\} ~~ \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)
\end{aligned}
\end{split}\]</div>
<p>where we once again grouped the factors connected to <span class="math notranslate nohighlight">\(X_1\)</span> inside the curly braces. Using the chain rule, we can those as the product of a conditional (which will end up in the Bayes net) and a new factor <span class="math notranslate nohighlight">\(\tau(X_2)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\phi_1(X_1)\phi_2(X_1)\phi_3(X_1, X_2) = P(X_1|X_2, \mathcal{Z}) \tau(X_2).
\]</div>
<p>Note that above we explicitly indicate the dependence on <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> in <span class="math notranslate nohighlight">\(P(X_1|X_2, \mathcal{Z})\)</span>, which was left implicit in the factor graph. Substituting this back in, we get a conditional multiplied with a smaller factor graph that no longer involves <span class="math notranslate nohighlight">\(X_1\)</span>, and we can recurse:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
P(\mathcal{X}|\mathcal{Z}) &amp;\propto P(X_1|X_2, \mathcal{Z}) ~~ \{ \tau(X_2) \phi_4(X_2)\phi_5(X_2, X_{3})\phi_6(X_3)\}
\\ &amp;\propto P(X_1|X_2, \mathcal{Z}) P(X_2 | X_{3}, \mathcal{Z}) ~~ \{\tau(X_{3})\phi_6(X_3)\}
\\ &amp;\propto P(X_1|X_2, \mathcal{Z}) P(X_2 | X_{3}, \mathcal{Z}) P(X_3| \mathcal{Z}).
\end{aligned}
\end{split}\]</div>
<p>Each of the three conditionals above was computed by implementing the chain rule, which is a simple calculation in the case of discrete factors.</p>
<section id="sum-product-in-gtsam">
<h3><span class="section-number">3.4.8.1. </span>Sum-Product in GTSAM<a class="headerlink" href="#sum-product-in-gtsam" title="Link to this heading">#</a></h3>
<p>In GTSAM, once again the sum-product is but a simple call to the <code class="docutils literal notranslate"><span class="pre">sumProduct</span></code> method of a factor graph. It yields a <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteBayes</span></code> net which encodes the full posterior distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: The full posterior encoded as a Bayes net.</span>
<span class="c1">#| label: fig:posterior_bn</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">sumProduct</span><span class="p">()</span>
<span class="n">show</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/138d456a04a5421a1d8398c1b06f646066b004edb9a930868f5cb7adebee2895.svg" src="_images/138d456a04a5421a1d8398c1b06f646066b004edb9a930868f5cb7adebee2895.svg" /></div>
</div>
<p>One of the things we can do with this <em>exact</em> posterior is sample from it, which is one possible state history conditioned on the available sensor measurements <em>and</em> the known action sequence:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='DiscreteValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>X1</th><td>Dining Room</td></tr>
    <tr><th>X2</th><td>Dining Room</td></tr>
    <tr><th>X3</th><td>Kitchen</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="sampling-and-posterior-means">
<h2><span class="section-number">3.4.9. </span>Sampling and Posterior Means*<a class="headerlink" href="#sampling-and-posterior-means" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Bayesian reasoning at its best</p>
</div></blockquote>
<p>When we can produce samples <span class="math notranslate nohighlight">\(\mathcal{X}^{(s)}\)</span> from a posterior
<span class="math notranslate nohighlight">\(P(\mathcal{X}|\mathcal{Z})\)</span>, we can calculate the empirical mean of any
real-valued function <span class="math notranslate nohighlight">\(f(\mathcal{X})\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[
E_{P(\mathcal{X}|\mathcal{Z})}[f(x)]\approx\sum f(\mathcal{X}^{(s)})
\]</div>
<p>For example, we can calculate the posterior mean of how far the robot
traveled, either in Euclidean or Manhattan distance, using this approach.
Doing this will provide a more reliable estimate than merely
calculating the distance for the MAP value,
since this approach averages over the entire probability distribution rather
than just using a single (albeit most probable) estimate.</p>
<p>For example, the code below samples 1000 alternate state histories, parallel universes of what <em>could</em> have happened:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">room_index</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="n">counts</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">room_index</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># base 0!</span>
</pre></div>
</div>
</div>
</div>
<p>Posterior means gives us a way to summarize these 1000 alternate histories some other way other than just printing them all out. One idea is to summarize, for every time step, what the probability is to be in a particular room. It turns out we can do this with a one-liner, because we kept track of counts in the code above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="mi">100</span><span class="o">*</span><span class="n">counts</span><span class="o">/</span><span class="n">num_samples</span><span class="p">,</span>
             <span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Living Room</th>
      <th>Kitchen</th>
      <th>Office</th>
      <th>Hallway</th>
      <th>Dining Room</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>3.3</td>
      <td>1.4</td>
      <td>3.8</td>
      <td>80.6</td>
      <td>10.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.9</td>
      <td>3.8</td>
      <td>0.8</td>
      <td>5.0</td>
      <td>89.5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.9</td>
      <td>90.7</td>
      <td>0.8</td>
      <td>0.0</td>
      <td>2.6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>These approximate marginals say how probable it is that the robot was in a particular room at a particular time step. This is much richer information that what is available in the MAP value, which is just a point estimate for the trajectory.</p>
<section id="id2">
<h3><span class="section-number">3.4.9.1. </span>Exercise<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>Execute the code above multiple times and observe that you <em>do</em> get different realizations (almost) every time, but that the approximate marginals stay roughly the same.</p>
</section>
</section>
<section id="gtsam-101">
<h2><span class="section-number">3.4.10. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>The GTSAM concepts used in this section, explained.</p>
</div></blockquote>
<p>We created, for the first time, an instance of the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteFactorGraph</span></code> class. The constructor is trivial - takes no arguments.
To add factors, we can use the following methods:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">j:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">j:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">spec:</span> <span class="pre">List[float])</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add(self,</span> <span class="pre">keys:</span> <span class="pre">List[Tuple[int,</span> <span class="pre">int]],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code></p></li>
</ol>
<p>These are very similar to the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteBayesNet</span></code> methods, but in factor graphs there is a
distinction between frontal and parent values, so we just have a key, or a list of keys as in the last method.</p>
<p>Two key factor graph methods we used above are <code class="docutils literal notranslate"><span class="pre">optimize</span></code> and <code class="docutils literal notranslate"><span class="pre">sumProduct</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="n">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gtsam</span><span class="p">::</span><span class="n">DiscreteValues</span>
<span class="o">-</span> <span class="n">sumProduct</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span>
</pre></div>
</div>
<p>The first one returns the MAP value as an assignment to discrete variables, whereas the second returns an entire Bayes net, encoding the posterior.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S33_vacuum_sensing.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3.3. </span>Dynamic Bayes Nets</p>
      </div>
    </a>
    <a class="right-next"
       href="S35_vacuum_decision.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.5. </span>Markov Decision Processes</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-in-bayes-nets">3.4.1. Inference in Bayes Nets</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-posterior-inference">3.4.1.1. Full Posterior Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">3.4.1.2. Exercises</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-a-posteriori-estimation">3.4.1.3. Maximum a Posteriori Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.4.1.4. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hidden-markov-models">3.4.2. Hidden Markov Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-robot-hmm">3.4.2.1. Example: Robot HMM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-inference-in-hmms">3.4.3. Naive Inference in HMMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-graphs">3.4.4. Factor Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-bayes-nets-into-factor-graphs">3.4.5. Converting Bayes Nets into Factor Graphs.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">3.4.5.1. Exercise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-graphs-in-gtsam">3.4.5.2. Factor Graphs in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-with-factor-graphs">3.4.6. Computing with Factor Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-max-product-algorithm-for-hmms">3.4.7. The Max-Product Algorithm for HMMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#max-product-in-gtsam">3.4.7.1. Max-product in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sum-product-algorithm-for-hmms">3.4.8. The Sum-Product Algorithm for HMMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-product-in-gtsam">3.4.8.1. Sum-Product in GTSAM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-and-posterior-means">3.4.9. Sampling and Posterior Means*</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.4.9.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">3.4.10. GTSAM 101</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>