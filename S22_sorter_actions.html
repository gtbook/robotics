
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2.2. Actions for Sorting Trash &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S22_sorter_actions';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2.3. Sensors for Sorting Trash" href="S23_sorter_sensing.html" />
    <link rel="prev" title="2.1. Modeling the World State" href="S21_sorter_state.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Introduction to Robotics and Perception - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S27_sorter_summary.html">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S22_sorter_actions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Actions for Sorting Trash</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-actions-and-their-effects">2.2.1. Modeling Actions and Their Effects</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-random-variables">2.2.2. Discrete Random Variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation">2.2.3. Expectation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-by-sampling">2.2.4. Simulation by Sampling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-theory-vs-statistics">2.2.5. Probability Theory vs. Statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">2.2.6. Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="actions-for-sorting-trash">
<h1><span class="section-number">2.2. </span>Actions for Sorting Trash<a class="headerlink" href="#actions-for-sorting-trash" title="Link to this heading">#</a></h1>
<p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S22_sorter_actions.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<blockquote id="index-0">
<div><p>Robots change the world through their actions. Action models capture their salient aspects.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S22-Trash_sorting_robot_with_gripper-10.jpg"><img alt="Splash image with rusty robot ferrying a mountain of trash" class="align-center" src="_images/S22-Trash_sorting_robot_with_gripper-10.jpg" style="width: 40%;" /></a>
<p>Robots decide how to act in the world by reasoning about how their actions can be used to achieve their goals, given the current state of the world.
At a high level, actions can be represented by symbolic descriptions of their effects (changes that will occur in the world state when the action is executed)
and by their preconditions (things that must be true in the current state in order to execute the action).
The robot’s goals can be encoded as a symbolic description of the desired world state, or, as we will do now,
by assigning a cost executing an action in a particular world state.
Note that assigning a cost to an action is equivalent to assigning a reward (merely multiply the cost by -1 to obtain a reward).
If we use a cost-based approach, we generally frame the planning problem as a decision problem: choose the action that minimizes cost.
If we are interested in long time horizons, we would choose the sequence of actions that minimize cost over the chosen time period.
If there are uncertainties, either in the world state or in the effects of actions, we would minimize the expected value of the cost.</p>
<p>In this section, we will consider only the problem of evaluating
the cost of a single action based on limited knowledge of the world.
In particular, we will assume that the robot has only the prior probability distribution
on categories described in the previous section.
We will address the more general problem of planning (i.e., choosing which actions to apply in the
current context) later in the chapter.</p>
<section id="modeling-actions-and-their-effects">
<h2><span class="section-number">2.2.1. </span>Modeling Actions and Their Effects<a class="headerlink" href="#modeling-actions-and-their-effects" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>For a trash sorting robot, the destination bin is the most important aspect of an action.</p>
</div></blockquote>
<p>For our trash sorting robot, we will define four actions, each of which can be executed when
there is an item of trash in the work space (i.e., there are no preconditions for the actions).
The first three actions use the robot manipulator to move an item of trash
to one of three bins: glass, metal, or mixed paper.
The fourth action is a nop,
which corresponds to the robot simply allowing the item to
pass through the work space, to be processed, for example, by a human worker
(note that “nop” is a shorthand used in many programming languages
to denote “no operation”).</p>
<p>We assign labels to these actions as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(a_1\)</span>: put in glass bin</p></li>
<li><p><span class="math notranslate nohighlight">\(a_2\)</span>: put in metal bin</p></li>
<li><p><span class="math notranslate nohighlight">\(a_3\)</span>: put in mixed paper bin</p></li>
<li><p><span class="math notranslate nohighlight">\(a_4\)</span>: nop (let the object continue, unsorted)</p></li>
</ul>
<p>and each of these actions can be applied at any stage of execution.</p>
<p>If the robot had perfect knowledge of the world state (i.e., if the robot always knew
exactly the category of the item in the work space), choosing an action would be simple:
place paper and scrap cardboard in the paper bin; place cans and scrap metal in the metal bin;
place bottles in the glass bin. The nop action would never be used.
But what if the robot’s knowledge of the world state is uncertain?
Suppose, for example, that it sometimes mistakes scrap metal for cardboard.
Placing scrap metal in the paper bin could lead to significant damage to
trash processing equipment, possibly requiring the facility to shut down completely
while repairs are made.
In contrast, if the robot places paper into the metal bin, serious damage is unlikely, and the cost of this wrong decision would likely be much smaller.</p>
<p>In order to make informed decisions about which action to take,
the robot needs to have some quantitative way to evaluate the cost of
executing the wrong actions.
This begins by assigning a cost to each action, depending on the world
state when the action is executed.</p>
<p>For this example, we will assign zero cost when the robot executes the correct action,
and positive value costs when wrong actions are executed, depending on the severity
of the consequence.  We can encode these costs into a table using the following code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cardboard&quot;</span><span class="p">,</span> <span class="s2">&quot;paper&quot;</span><span class="p">,</span> <span class="s2">&quot;can&quot;</span><span class="p">,</span> <span class="s2">&quot;scrap metal&quot;</span><span class="p">,</span> <span class="s2">&quot;bottle&quot;</span><span class="p">]</span>
<span class="n">actions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;glass bin&quot;</span><span class="p">,</span> <span class="s2">&quot;metal bin&quot;</span><span class="p">,</span> <span class="s2">&quot;paper bin&quot;</span><span class="p">,</span> <span class="s2">&quot;nop&quot;</span><span class="p">]</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
                 <span class="p">[</span><span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">]])</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">actions</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cardboard</th>
      <th>paper</th>
      <th>can</th>
      <th>scrap metal</th>
      <th>bottle</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>glass bin</th>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>6</td>
      <td>0</td>
    </tr>
    <tr>
      <th>metal bin</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>paper bin</th>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>10</td>
      <td>3</td>
    </tr>
    <tr>
      <th>nop</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note that the cost of making the correct decision (e.g., placing cardboard into the paper bin) is zero, and the cost of wrong decisions is a positive number that reflects the damage done to processing machinery for the specific cases. Furthermore, we have assigned a unit cost to executing the nop action (i.e., letting the trash item pass, unsorted). This latter cost assignment depends, of course, of what happens at the downstream sorting stages, but we ignore such effects here.</p>
<p>If the robot knew the state of the world with certainty, planning would amount to merely choosing at each
moment the action that minimizes the cost. For our trash sorting problem, this approach would uniquely
define which action to take as a function of the world state.
When the state of the world is uncertain, we can use probability theory
to define a solution strategy.</p>
</section>
<section id="discrete-random-variables">
<h2><span class="section-number">2.2.2. </span>Discrete Random Variables<a class="headerlink" href="#discrete-random-variables" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>If the category is not known with certainty, then the cost of an action will be a random variable.</p>
</div></blockquote>
<p>Suppose the robot takes the naive decision to always place trash in the paper bin.
What can we say about the cost associated to this action?
We can immediately conclude that the cost will take its value from the set
<span class="math notranslate nohighlight">\(\{ 0, 3, 5, 10\}\)</span>, since these are the only values that appear in the table of costs
for this action.
In the absence of any other information, this is really all that can be said about the
cost that will be incurred by placing a newly arrived item of trash in the paper bin.
But in our case, we have additional information in the form of the prior distribution
on trash categories.
Thus, we can view the cost of moving an item to the paper bin as a random quantity
that takes its values from a finite set of numbers.</p>
<p>We can compute the probabilities for the various values of cost by examining the outcomes
that lead to those costs.
The probability of paper is 0.2 and the probability of cardboard is 0.3. In each of these cases,
the cost is zero. Therefore, we can conclude that the probability of zero cost is 0.5.
Similarly, since the probability of a can is 0.25, the probability is 0.25 that the cost will be 5;
the probability that the cost will be 10 is 0.2; and the probability that the cost will be 3
is 0.05.  And voilà, we have determined the complete probability distribution on cost, given
that the robot always places items in the paper bin!</p>
<p id="index-1">In probability theory, a <strong>random variable</strong> is defined as a mapping from the sample space
to real numbers, <span class="math notranslate nohighlight">\(X : \Omega \rightarrow \mathbb{R}\)</span>.
We typically use upper case letters to denote random variables, and we typically
write <span class="math notranslate nohighlight">\(X\)</span> instead of <span class="math notranslate nohighlight">\(X(\omega)\)</span>.
In this way, we deal directly with <span class="math notranslate nohighlight">\(X\)</span>, treating <span class="math notranslate nohighlight">\(X\)</span> as a random quantity
whose probability distribution is induced by the probability distribution on <span class="math notranslate nohighlight">\(\Omega\)</span>.
This is exactly what we did above, when we used the probability distribution on
categories to infer the distribution on costs.</p>
<p id="index-3"><span id="index-2"></span>A <strong>discrete random variable</strong> is defined as a random variable that takes values
from a finite (or even countably infinite) set. The probability distribution
for a discrete random variable is called a <strong>probability mass function</strong> or <strong>PMF</strong>.
The pmf for random variable <span class="math notranslate nohighlight">\(X\)</span> is typically denoted by <span class="math notranslate nohighlight">\(p_X\)</span> or simply by <span class="math notranslate nohighlight">\(p\)</span>
when the context makes clear the random variable under consideration. Discrete random variables
and pmf’s are key concepts in the development of probability theory,
and they will be key in our treatment of uncertainty for robotics applications.</p>
<p>Let us denote by <span class="math notranslate nohighlight">\(X\)</span> the cost of moving an item of trash to the paper bin.
We use lower case letters to denote values that can be taken by random variables;
in this case <span class="math notranslate nohighlight">\(x\)</span> denotes a value taken by the random variable <span class="math notranslate nohighlight">\(X\)</span>.
The pmf <span class="math notranslate nohighlight">\(p_X\)</span> can be represented in tabular form as follows:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(x\)</span></p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(p_X(x)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td class="text-center"><p>0.50</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td class="text-center"><p>0.05</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td class="text-center"><p>0.25</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td class="text-center"><p>0.20</p></td>
</tr>
</tbody>
</table>
</div>
<p>We could apply this same approach for each of the possible actions, and then use the resulting
PMFs to make decisions about which actions to apply. We will discuss such an approach
to planning a bit later in this chapter.</p>
</section>
<section id="expectation">
<span id="index-4"></span><h2><span class="section-number">2.2.3. </span>Expectation<a class="headerlink" href="#expectation" title="Link to this heading">#</a></h2>
<p>For many robotics applications, we hope that the robot will operate for a long period of time.
We might hope for our trash sorting robot to operate for weeks, months, or longer, placing many pieces
of trash into bins over the course of its operation.
Suppose again that the robot merely always chooses to place trash in the paper bin.
What can we say about the cost that will accrue over the robot’s lifetime?
With probability theory, we are unable to say anything definitive about a particular outcome;
however, we <em>can</em> say things about average behavior over many trials.
This is the concept of <strong>expectation</strong> in probability theory.</p>
<p>Suppose that the random variable <span class="math notranslate nohighlight">\(X\)</span> takes its values from a finite set,
<span class="math notranslate nohighlight">\(X \in \{ x_1, \dots , x_n \}\)</span>.
The <strong>expected value</strong> of <span class="math notranslate nohighlight">\(X\)</span>, which we denote by <span class="math notranslate nohighlight">\(E[X]\)</span> is defined
by</p>
<div class="amsmath math notranslate nohighlight" id="equation-636442ac-ce9d-469e-bcb6-4c6a676a1565">
<span class="eqno">(2.6)<a class="headerlink" href="#equation-636442ac-ce9d-469e-bcb6-4c6a676a1565" title="Permalink to this equation">#</a></span>\[\begin{equation}
E[X] = \sum_{i=1}^n x_i p_X(x_i)
\end{equation}\]</div>
<p>For the example above, the expected value of cost, <span class="math notranslate nohighlight">\(E[X]\)</span>, is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-ec3c1319-8205-41d4-85bb-e9a9dd9c7575">
<span class="eqno">(2.7)<a class="headerlink" href="#equation-ec3c1319-8205-41d4-85bb-e9a9dd9c7575" title="Permalink to this equation">#</a></span>\[\begin{equation}
E[X] = (0 \times 0.2) + (0 \times 0.3)  + (5 \times 0.25) + (10 \times 0.2)  + (3 \times 0.05)  = 3.4
\end{equation}\]</div>
<p>Note that we never really <em>expect</em> to see the cost <span class="math notranslate nohighlight">\(3.4\)</span>. The term <em>expected value</em> is a technical term,
defined by the equation above. The expected value is related to what we would
expect to see if we took the average over many trials.
As an example, if we roll a fair, six-sided die
and let <span class="math notranslate nohighlight">\(X\)</span> denote the number of dots on the top face, it is easy to show that <span class="math notranslate nohighlight">\(E[X] = 3.5\)</span>.  Of course
we will never roll a <span class="math notranslate nohighlight">\(3.5\)</span>, but if we roll the die 100 times and take the average of those rolls, we would expect that average to be near <span class="math notranslate nohighlight">\(3.5\)</span>.
We will discuss this in more detail below.</p>
<p>In python, we can compute the expected cost for each action by merely multiplying the <span class="math notranslate nohighlight">\(4\times5\)</span> cost matrix with the <span class="math notranslate nohighlight">\(5\times1\)</span> PMF:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Category</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete</span><span class="p">(</span><span class="s2">&quot;Category&quot;</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
<span class="n">category_prior</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">Category</span><span class="p">,</span> <span class="s2">&quot;200/300/250/200/50&quot;</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">category_prior</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(Category):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>Category</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>cardboard</th><td>0.2</td></tr>
    <tr><th>paper</th><td>0.3</td></tr>
    <tr><th>can</th><td>0.25</td></tr>
    <tr><th>scrap metal</th><td>0.2</td></tr>
    <tr><th>bottle</th><td>0.05</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cost</span> <span class="o">@</span> <span class="n">category_prior</span><span class="o">.</span><span class="n">pmf</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([3.2, 0.6, 3.4, 1. ])
</pre></div>
</div>
</div>
</div>
<p>The result is an array in which each entry corresponds to the expected cost for a specific action.
Thus, this array encapsulates everything we know about the expected costs of applying the four possible
actions. We will use this later in the chapter to form a basis for simple planning.</p>
<p>If it is not clear to you why this works, write out the expression for the matrix multiplication
described above, and compare to the equations for the expected cost of each action.</p>
</section>
<section id="simulation-by-sampling">
<h2><span class="section-number">2.2.4. </span>Simulation by Sampling<a class="headerlink" href="#simulation-by-sampling" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>It is easy to demonstrate the relationship between expectation and the average
over many trials - simply sample and average!</p>
</div></blockquote>
<p>The code below computes the average cost over <span class="math notranslate nohighlight">\(N\)</span> samples for a specified action.
Try various values for <span class="math notranslate nohighlight">\(N\)</span>, and notice that as <span class="math notranslate nohighlight">\(N\)</span> increases, the average tends
to be an increasingly better approximation of the expected cost.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sample N times, and evaluate the cost of executing the given action:</span>
<span class="n">total_cost</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">action</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">category</span> <span class="o">=</span> <span class="n">category_prior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">total_cost</span> <span class="o">+=</span> <span class="n">cost</span><span class="p">[</span><span class="n">action</span><span class="p">,</span> <span class="n">category</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">total_cost</span><span class="o">/</span><span class="n">N</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.36
</pre></div>
</div>
</div>
</div>
<p>For example, one experiment with <span class="math notranslate nohighlight">\(100\)</span> samples yielded:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cost_estimate</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.14</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">4.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="probability-theory-vs-statistics">
<span id="index-5"></span><h2><span class="section-number">2.2.5. </span>Probability Theory vs. Statistics<a class="headerlink" href="#probability-theory-vs-statistics" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Probability theory is the study of certain mathematical functions, while statistics are functions of data. The two are related, but different.</p>
</div></blockquote>
<p>Probability theory and statistics seem to be concerned with the same kinds of ideas, but they are two very
different fields of study.</p>
<p><strong>Probability theory</strong> is the study of a certain class of mathematical functions (probability distributions).
The modern, axiomatic approach to probability theory begins with three axioms, from which
all other properties are derived:</p>
<ul class="simple">
<li><p>For <span class="math notranslate nohighlight">\(A\subseteq \Omega\)</span>, <span class="math notranslate nohighlight">\(P(A) \geq 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\Omega) = 1\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(A_i, A_j \subseteq \Omega\)</span>, if <span class="math notranslate nohighlight">\(A_i \cap A_j = \emptyset\)</span>, then <span class="math notranslate nohighlight">\(P(A_i \cup A_j) = P(A_i) + P(A_j)\)</span>.</p></li>
</ul>
<p>Probability theory does not consider the problem of how one might obtain the probability distribution <span class="math notranslate nohighlight">\(P\)</span>.
Probability theorists take this as a given, along with the axioms.</p>
<p>Expectation is a property of a probability distribution.
For a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> with <span class="math notranslate nohighlight">\(\Omega = \{ x_1 \dots x_n\}\)</span>,
<span class="math notranslate nohighlight">\(E[X]\)</span> (also called the mean, and often denoted by <span class="math notranslate nohighlight">\(\mu\)</span>)
can be computed as above</p>
<div class="amsmath math notranslate nohighlight" id="equation-295016eb-f8a7-4c69-a6d7-419b34909933">
<span class="eqno">(2.8)<a class="headerlink" href="#equation-295016eb-f8a7-4c69-a6d7-419b34909933" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mu = E[X] = \sum_{i=1}^n x_i p_X(x_i)
\end{equation}\]</div>
<p>The variance of a <em>random variable</em>,
typically denoted by <span class="math notranslate nohighlight">\(\sigma^2\)</span>, is merely the expected value of the squared difference between
the random variable <span class="math notranslate nohighlight">\(X\)</span> and the mean. The variance is also a property of probability distributions, and it can
be computed as</p>
<div class="amsmath math notranslate nohighlight" id="equation-7583d66e-d53a-4443-a4c0-f9f5a1283ce7">
<span class="eqno">(2.9)<a class="headerlink" href="#equation-7583d66e-d53a-4443-a4c0-f9f5a1283ce7" title="Permalink to this equation">#</a></span>\[\begin{equation}
\sigma^2 = E[(X-\mu)^2] = \sum_{i=1}^n p_X(x_i) (x_i - \mu)^2
\end{equation}\]</div>
<p>Note that the expressions for <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span> depend only on the probability distribution (in this case,
the pmf <span class="math notranslate nohighlight">\(p_X\)</span>) and the values taken by the random variable <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p id="index-6">A <strong>statistic</strong> is any function of data (including the identity function).
Consider a set of measurements <span class="math notranslate nohighlight">\(\{ z_1, \dots z_N \}\)</span>.
The average of these values, often denoted by <span class="math notranslate nohighlight">\(\bar{z}\)</span>, is a statistic, and it can be computed as</p>
<div class="amsmath math notranslate nohighlight" id="equation-adb8665c-d1e7-4e5a-b5d7-7b331693f5f3">
<span class="eqno">(2.10)<a class="headerlink" href="#equation-adb8665c-d1e7-4e5a-b5d7-7b331693f5f3" title="Permalink to this equation">#</a></span>\[\begin{equation}
\bar{z} = \frac{1}{N} \sum_{i=1}^{N} z_i
\end{equation}\]</div>
<p>Likewise, the variance of the <em>data</em>, often denoted by <span class="math notranslate nohighlight">\(\hat{\sigma}^2\)</span> can be computed as</p>
<div class="amsmath math notranslate nohighlight" id="equation-2fb545e6-762d-417c-8ce3-02a9b92aabb3">
<span class="eqno">(2.11)<a class="headerlink" href="#equation-2fb545e6-762d-417c-8ce3-02a9b92aabb3" title="Permalink to this equation">#</a></span>\[\begin{equation}
\hat{\sigma}^2 = \frac{1}{N-1} \sum_{i=1}^{N} (z_i- \bar{z})^2
\end{equation}\]</div>
<p>Note that the definitions of <span class="math notranslate nohighlight">\(\bar{z}\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}^2\)</span> depend <em>only</em> on the data itself.</p>
<p>Certain similarities are immediately obvious between these two sets of definitions.
The mean of a random variable seems similar to the average of a data set.
The variance of a random variable seems similar to the variance of a data set.</p>
<p>In fact, if it happens that certain probability distributions do a good job of describing how the world behaves,
then probability theory can provide a rigorous basis for a system of inference about data.
As an example, if the data we observe behave according to the probability distribution <span class="math notranslate nohighlight">\(p_X\)</span>,
then the average of the data will tend toward the expected value of <span class="math notranslate nohighlight">\(X\)</span>.
This property can be written formally as the <strong>weak law of large numbers</strong>, which
states that for any <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, if <span class="math notranslate nohighlight">\(\bar{z}_N\)</span> denotes the average of a data set of size <span class="math notranslate nohighlight">\(N\)</span>,
then</p>
<div class="amsmath math notranslate nohighlight" id="equation-8623deac-56d0-4478-afd1-ebbe03bb34f2">
<span class="eqno">(2.12)<a class="headerlink" href="#equation-8623deac-56d0-4478-afd1-ebbe03bb34f2" title="Permalink to this equation">#</a></span>\[\begin{equation}
\lim_{N \rightarrow \infty} P( \mid \bar{z}_N - \mu \mid &lt; \epsilon ) = 1
\end{equation}\]</div>
<p>i.e., the average of <span class="math notranslate nohighlight">\(N\)</span> data points will become arbitrarily close to <span class="math notranslate nohighlight">\(\mu\)</span> as <span class="math notranslate nohighlight">\(N\)</span> becomes
large. This occurs with probability one, a nuance that we will not discuss here.
This is one explanation for why simulation by sampling works, and why the results tend
to improve with an increasing number of samples.</p>
<p>The weak law of large numbers is only the first of many theorems that formalize the connections
between probability theory and statistics, but most all of these theorems express variations
on a simple concept: <em>as the size of a data set becomes large, the statistics of that data
set will become increasingly good approximations for various properties of
the underlying probability distribution from which the data set was generated.</em>
Therefore, using probability theory to reason about distributions can serve as a basis
for inferential reasoning about the real world.</p>
</section>
<section id="summary">
<h2><span class="section-number">2.2.6. </span>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<p>In ths section we considered the foundational concept of robot <em>actions</em>, focusing on how robot systems can use actions to intervene in the physical world. For our very abstracted world state, we considered discrete, symbolic actions, and introduced probability theory to model the uncertain outcomes associated with each action. We introduced the notion of <em>expectation</em> to think about the average outcome of actions over time. And, we ended by contrasting probability theory with statistics, and how the weak law of large numbers bridges the gap between these two formalisms.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S21_sorter_state.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2.1. </span>Modeling the World State</p>
      </div>
    </a>
    <a class="right-next"
       href="S23_sorter_sensing.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2.3. </span>Sensors for Sorting Trash</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-actions-and-their-effects">2.2.1. Modeling Actions and Their Effects</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-random-variables">2.2.2. Discrete Random Variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation">2.2.3. Expectation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-by-sampling">2.2.4. Simulation by Sampling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-theory-vs-statistics">2.2.5. Probability Theory vs. Statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">2.2.6. Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>