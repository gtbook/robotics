
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4.4. Localization &#8212; Introduction to Robotics and Perception</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4.5. Planning for Logistics" href="S45_logistics_planning.html" />
    <link rel="prev" title="4.3. Sensor Models with Continuous State" href="S43_logistics_sensing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-312077-7', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Robotics and Perception</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction to Robotics and Perception
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S10_introduction.html">
   1. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S11_intro_state.html">
     1.1. Representing State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S12_intro_actions.html">
     1.2. Robot Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S13_intro_sensing.html">
     1.3. Sensing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S14_intro_perception.html">
     1.4. Perception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S15_intro_decision.html">
     1.5. Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S16_intro_learning.html">
     1.6. Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S20_sorter_intro.html">
   2. A Trash Sorting Robot
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S21_sorter_state.html">
     2.1. Modeling the World State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S22_sorter_actions.html">
     2.2. Actions for Sorting Trash
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S23_sorter_sensing.html">
     2.3. Sensors for Sorting Trash
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S24_sorter_perception.html">
     2.4. Perception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S25_sorter_decision_theory.html">
     2.5. Decision Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S26_sorter_learning.html">
     2.6. Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S30_vacuum_intro.html">
   3. A Robot Vacuum Cleaner
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S31_vacuum_state.html">
     3.1. Modeling the State of the Vacuum Cleaning Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S32_vacuum_actions.html">
     3.2. Actions over time
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S33_vacuum_sensing.html">
     3.3. Dynamic Bayes Nets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S34_vacuum_perception.html">
     3.4. Perception with Graphical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S35_vacuum_decision.html">
     3.5. Markov Decision Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S36_vacuum_RL.html">
     3.6. Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="S40_logistics_intro.html">
   4. Warehouse Robots in 2D
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="S41_logistics_state.html">
     4.1. Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S42_logistics_actions.html">
     4.2. Moving in 2D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S43_logistics_sensing.html">
     4.3. Sensor Models with Continuous State
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     4.4. Localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S45_logistics_planning.html">
     4.5. Planning for Logistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S46_logistics_learning.html">
     4.6. Some System Identification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S50_diffdrive_intro.html">
   5. A Mobile Robot With Simple Kinematics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S51_diffdrive_state.html">
     5.1. State Space for a Differential Drive Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S52_diffdrive_actions.html">
     5.2. Motion Model for the Differential Drive Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S53_diffdrive_sensing.html">
     5.3. Robot Vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S54_diffdrive_perception.html">
     5.4. Computer Vision 101
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S55_diffdrive_planning.html">
     5.5. Path Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S56_diffdrive_learning.html">
     5.6. Deep Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S60_driving_intro.html">
   6. Autonomous Vehicles
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S61_driving_state.html">
     6.1. Planar Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S62_driving_actions.html">
     6.2. Kinematics for Driving
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S63_driving_sensing.html">
     6.3. Sensing for Autonomous Vehicles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S64_driving_perception.html">
     6.4. SLAM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S65_driving_planning.html">
     6.5. Planning for Autonomous Driving.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S66_driving_DRL.html">
     6.6. Deep Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S70_drone_intro.html">
   7. Autonomous Drones in 3D
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S71_drone_state.html">
     7.1. Moving in Three Dimensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S72_drone_actions.html">
     7.2. Multi-rotor Aircraft
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S73_drone_sensing.html">
     7.3. Sensing for Drones
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/S44_logistics_perception.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/gtbook/robotics"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS44_logistics_perception.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/gtbook/robotics/main?urlpath=tree/S44_logistics_perception.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#markov-localization">
   4.4.1. Markov Localization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-bayes-filter">
     4.4.1.1. The Bayes Filter
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-historically-meaningful-1d-example">
     4.4.1.2. A (historically meaningful) 1D Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#warehouse-example">
     4.4.1.3. Warehouse Example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercises">
       4.4.1.3.1. Exercises
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#monte-carlo-localization">
   4.4.2. Monte Carlo Localization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-prediction-step">
     4.4.2.1. The Prediction Step
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-the-likelihood">
     4.4.2.2. Evaluating the Likelihood
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mcl-warehouse-example">
     4.4.2.3. MCL Warehouse Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adding-range-sensing">
     4.4.2.4. Adding Range Sensing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kalman-smoothing-and-filtering">
   4.4.3. Kalman Smoothing and Filtering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#factor-graphs-and-least-squares">
     4.4.3.1. Factor Graphs and Least Squares
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-example">
     4.4.3.2. Numerical Example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercise">
       4.4.3.2.1. Exercise
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparse-least-squares">
     4.4.3.3. Sparse Least-Squares
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-with-gps-like-measurements">
     4.4.3.4. Example with GPS-Like Measurements
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gtsam-102">
   4.4.4. GTSAM 102
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Localization</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#markov-localization">
   4.4.1. Markov Localization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-bayes-filter">
     4.4.1.1. The Bayes Filter
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-historically-meaningful-1d-example">
     4.4.1.2. A (historically meaningful) 1D Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#warehouse-example">
     4.4.1.3. Warehouse Example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercises">
       4.4.1.3.1. Exercises
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#monte-carlo-localization">
   4.4.2. Monte Carlo Localization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-prediction-step">
     4.4.2.1. The Prediction Step
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-the-likelihood">
     4.4.2.2. Evaluating the Likelihood
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mcl-warehouse-example">
     4.4.2.3. MCL Warehouse Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adding-range-sensing">
     4.4.2.4. Adding Range Sensing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kalman-smoothing-and-filtering">
   4.4.3. Kalman Smoothing and Filtering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#factor-graphs-and-least-squares">
     4.4.3.1. Factor Graphs and Least Squares
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-example">
     4.4.3.2. Numerical Example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercise">
       4.4.3.2.1. Exercise
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparse-least-squares">
     4.4.3.3. Sparse Least-Squares
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-with-gps-like-measurements">
     4.4.3.4. Example with GPS-Like Measurements
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gtsam-102">
   4.4.4. GTSAM 102
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S44_logistics_perception.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="tex2jax_ignore mathjax_ignore section" id="localization">
<h1><span class="section-number">4.4. </span>Localization<a class="headerlink" href="#localization" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>We introduce three instances of Bayes filtering: Kalman filters, Markov localization, and Monte Carlo localization.</p>
</div></blockquote>
<p><strong>This Section is still in draft mode and was released for adventurous spirits (and TAs) only.</strong></p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<div align='center'>
<img src='https://github.com/gtbook/robotics/blob/main/Art/steampunk/S44-Warehouse%20robots-07.jpg?raw=1' style='height:256 width:100%'/>
</div>
</div></div>
</div>
<p>The first order of business is creating a small ground truth trajectory. Rather than using simulation we generate it deterministically here, so ew can easily assess the quality of our solution. In particular, let us start at and move to the right, then up between the middle two shelves:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">left</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">10</span><span class="o">+</span><span class="n">i</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span>
<span class="n">up</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">50</span><span class="p">,</span><span class="mi">6</span><span class="o">+</span><span class="n">i</span><span class="o">*</span><span class="mi">5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">)]</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">left</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">up</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">gtsam</span><span class="o">.</span><span class="n">symbol</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">}</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">VectorValues</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">left</span><span class="o">+</span><span class="n">up</span><span class="p">):</span> <span class="n">values</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">state</span><span class="p">)</span>
<span class="n">values</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='VectorValues'>
  <thead>
    <tr><th>Variable</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>x1</th><td>10  6</td></tr>
    <tr><th>x2</th><td>15  6</td></tr>
    <tr><th>x3</th><td>20  6</td></tr>
    <tr><th>x4</th><td>25  6</td></tr>
    <tr><th>x5</th><td>30  6</td></tr>
    <tr><th>x6</th><td>35  6</td></tr>
    <tr><th>x7</th><td>40  6</td></tr>
    <tr><th>x8</th><td>45  6</td></tr>
    <tr><th>x9</th><td>50  6</td></tr>
    <tr><th>x10</th><td>50 11</td></tr>
    <tr><th>x11</th><td>50 16</td></tr>
    <tr><th>x12</th><td>50 21</td></tr>
    <tr><th>x13</th><td>50 26</td></tr>
    <tr><th>x14</th><td>50 31</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note above we used a <code class="docutils literal notranslate"><span class="pre">gtsam.VectorValues</span></code> to store the ground truth trajectory, which will come in handy again when we simulate the measurements. Below we show this “ground truth” trajectory overlaid on the warehouse map we introduced before:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ground_truth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_8_0.png" src="_images/S44_logistics_perception_8_0.png" />
</div>
</div>
<div class="section" id="markov-localization">
<h2><span class="section-number">4.4.1. </span>Markov Localization<a class="headerlink" href="#markov-localization" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Complicated sensors necessitate expressive density representations.</p>
</div></blockquote>
<p>Through finite element discretization we can use the sum-product algorithm from the previous chapter, as is. When applied to robot localization, as we are using a discrete Markov chain representation, this approach has been called <strong>Markov Localization</strong>. However, because of the computational expense involved, we will not be able to run the sum-product algorithm over <em>multiple</em> times steps. Instead of asking for the full posterior over an entire sequence, we will have to be content with the posterior on the <em>current state</em> only. This approach is called <em>filtering</em>, and this is where we start below.</p>
<div class="section" id="the-bayes-filter">
<h3><span class="section-number">4.4.1.1. </span>The Bayes Filter<a class="headerlink" href="#the-bayes-filter" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>The Bayes filter is a recursive, ons-step sum-product algorithm.</p>
</div></blockquote>
<p>The <strong>Bayes filter</strong> is a simple inference scheme that recursively implements the sum-product algorithm.
In this case we present the discrete version, which will yield Markov localization.
However,  the same general scheme underlies the venerable Kalman filter, and Monte Carlo Localization, which is based on a sampling-based density representation.</p>
<p>We assume a finite element discretization such that a density <span class="math notranslate nohighlight">\(p(x_k)\)</span> over continuous states <span class="math notranslate nohighlight">\(x_k\)</span> is approximated by a discrete probability distribution <span class="math notranslate nohighlight">\(P(X_k)\)</span>. The only difference from the previous chapter, where we discussed discreet state spaces, is that in a finite element discretization the cardinality of the discrete states is typically much larger. Recall from section 4.1 that for our <span class="math notranslate nohighlight">\(100m \times 50m\)</span> warehouse example, even at a relatively course resolution of 1m by 1 m cells, our state space had a cardinality of 5000 finite elements. That is exactly what makes reasoning over multiple time steps computationally challenging. In other words, we have to give up on computing the joint posterior <span class="math notranslate nohighlight">\(P(X_1, X_2, ...X_k)\)</span>.</p>
<p>Instead, in the Bayes filter we are only interested in estimating the state of the
robot at the <em>current time</em> <span class="math notranslate nohighlight">\(t\)</span>, given all the measurements up to and
including time <span class="math notranslate nohighlight">\(t\)</span>.
In Bayesian fashion, we attempt at characterizing our complete knowledge of the state <span class="math notranslate nohighlight">\(X_k\)</span> by computing its posterior <span class="math notranslate nohighlight">\(P(X_k)\)</span>, which is also called the <strong>filtering distribution</strong>.
To be very clear, we indicate exactly what information we are
conditioning on when giving the formulas for the Bayes filter. To that
end, we introduce the notation
<span class="math notranslate nohighlight">\(\mathcal{Z}^{k}=\{z_{1},z_{2},\ldots z_{k}\}\)</span>, i.e., all measurements
<span class="math notranslate nohighlight">\(o\)</span> up to and including time <span class="math notranslate nohighlight">\(t\)</span>.
Similarly, we define the controls
<span class="math notranslate nohighlight">\(\mathcal{U}^{k}=\{u_{1},u_{2},\ldots u_{k-1}\}\)</span>.
Note there is always one less control variable than there are measurements, and we start off the algorithm with Bayes rule as applied to <span class="math notranslate nohighlight">\(k=1\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(X_1|\mathcal{Z}^1=\{z_1\}, \mathcal{U}^1=\{\}) \propto L(X_1;z_1)P(X_1)
\]</div>
<p>Given this, recursively assuming that we have a probability distribution
<span class="math notranslate nohighlight">\(P(x_{t-1}|\mathcal{Z}^{k-1},\mathcal{U}^{k-1})\)</span> over the previous state <span class="math notranslate nohighlight">\(X_{k-1}\)</span>, we proceed in two
phases:</p>
<ol class="simple">
<li><p>In the <strong>prediction phase</strong> we calculate a <strong>predictive distribution</strong>
<span class="math notranslate nohighlight">\(P(X_{k}|\mathcal{Z}^{k-1},\mathcal{U}^{k})\)</span> on the current state <span class="math notranslate nohighlight">\(X_{k}\)</span> given a control <span class="math notranslate nohighlight">\(u_{k-1}\)</span>. This is done by marginalizing out
the previous state <span class="math notranslate nohighlight">\(X_{k-1}\)</span>, by summing over all possible values
<span class="math notranslate nohighlight">\(x_{k-1}\)</span> for <span class="math notranslate nohighlight">\(X_{k-1}\)</span>:
$<span class="math notranslate nohighlight">\(
P(X_{k}|\mathcal{Z}^{k-1},\mathcal{U}^{k})=\sum_{x_{k-1}}P(X_{k}|x_{k-1},u_{k-1})P(x_{t-1}|\mathcal{Z}^{k-1},\mathcal{U}^{k-1}).
\)</span>$</p></li>
<li><p>In the <strong>measurement phase</strong> we upgrade this predictive density to the <strong>filtering distribution</strong> <span class="math notranslate nohighlight">\(P(X_{k}|\mathcal{Z}^{k},\mathcal{U}^{k})\)</span>
via Bayes’ rule, given the measurement <span class="math notranslate nohighlight">\(z_{k}\)</span>:
$<span class="math notranslate nohighlight">\(
P(X_{k}|\mathcal{Z}^{k},\mathcal{U}^{k}) \propto L(X_{k};z_{k})P(X_{k}|\mathcal{Z}^{k-1},\mathcal{U}^{k}).
\)</span>$</p></li>
</ol>
<p>A keen observer will see that step 1 and step 2 above implement one step of the sum-product algorithm, where in this case the previous state <span class="math notranslate nohighlight">\(X_{k-1}\)</span> is eliminated. Step 1 is a sum, and step 2 is a product.</p>
</div>
<div class="section" id="a-historically-meaningful-1d-example">
<h3><span class="section-number">4.4.1.2. </span>A (historically meaningful) 1D Example<a class="headerlink" href="#a-historically-meaningful-1d-example" title="Permalink to this headline">¶</a></h3>
<p>Figure
<a href="#fig:Markov-localization" data-reference-type="ref" data-reference="fig:Markov-localization">1</a> below
illustrates the measurement phase for a simple 1D example.
The example is historically meaningful as it was created by Sebastian Thrun to explain Markov Localization over 20 years ago, and we reuse it here again.</p>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures4/markov-localization.png?raw=1" id="fig:Markov-localization" style="width:14cm" alt="">
<figcaption>One-dimensional example of the measurement phase in Markov localization, the discrete version of the Bayes filter.</figcaption>
</figure>
<p>In this environment there are two doors, and the robot has a door sensor. The
predictive distribution <span class="math notranslate nohighlight">\(P(S)\)</span> encodes that we believe the robot to be
near the left door. The likelihood <span class="math notranslate nohighlight">\(L(S;o)\)</span>, where <span class="math notranslate nohighlight">\(o\)</span> indicates that we
<em>did</em> perceive a door, models the fact that we are more likely to be
near a door given <span class="math notranslate nohighlight">\(O=o\)</span>, but also allows for the fact that the door
sensor could misfire at any location. Note that the likelihood is
un-normalized and there is no need for it to sum up to 1. Finally, the
posterior <span class="math notranslate nohighlight">\(P(S|o)\)</span> is obtained, via Bayes’ rule, as the product of the
prediction <span class="math notranslate nohighlight">\(P(S)\)</span> and the likelihood <span class="math notranslate nohighlight">\(L(S;o)\)</span>, and is shown at the
bottom as a normalized probability distribution. As you can see, the
most probable explanation for the robot state is <span class="math notranslate nohighlight">\(S=5\)</span>, but there is a
second mode at <span class="math notranslate nohighlight">\(S=17\)</span> due to the bimodal nature of the likelihood.
However, that second mode is less probable because of our prior belief
over <span class="math notranslate nohighlight">\(S\)</span>.</p>
</div>
<div class="section" id="warehouse-example">
<h3><span class="section-number">4.4.1.3. </span>Warehouse Example<a class="headerlink" href="#warehouse-example" title="Permalink to this headline">¶</a></h3>
<p>Let us apply Markov localization to the warehouse example, using <em>just</em> the proximity sensor for now. We start by initializing the finite element density representation with a prior, centered around the ground truth location for <span class="math notranslate nohighlight">\(k=1\)</span>, but with a relatively large standard deviation of 5 meter:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior_mean</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">prior_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">])</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">logistics</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">map_coords</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="n">prior</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span><span class="o">+</span><span class="mf">0.1</span><span class="o">*</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_15_0.png" src="_images/S44_logistics_perception_15_0.png" />
</div>
</div>
<p>The hardest and most computationally demanding part in the Markov localization algorithm to implement is the prediction step. Recall the formula:</p>
<div class="math notranslate nohighlight">
\[
P(X_{k}|\mathcal{Z}^{k-1},\mathcal{U}^{k})=\sum_{x_{k-1}}P(X_{k}|x_{k-1},u_{k-1})P(x_{t-1}|\mathcal{Z}^{k-1},\mathcal{U}^{k-1}).
\]</div>
<p>Hence, for every cell in the predictive density approximation, we need to sum over <em>all</em> cells in the previous image. Not only that, but for every one of these <span class="math notranslate nohighlight">\(5000^2\)</span>, i.e., <em>25 million</em> cell combinations <span class="math notranslate nohighlight">\((X_k,x_{k-1})\)</span> we need to evaluate the Gaussian motion model <span class="math notranslate nohighlight">\(P(X_{k}|x_{k-1},u_{k-1})\)</span>. With python for-loops, this will be rather expensive, so in the code below build in two speedups:</p>
<ol class="simple">
<li><p>We make the outer loop over the previous image, and threshold on the density;</p></li>
<li><p>we make use of the fact that the <code class="docutils literal notranslate"><span class="pre">logistics.gaussian</span></code> function is vectorized, i.e., we can process an entire row of the predictive image at a time.</p></li>
</ol>
<p>The fast code looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prediction_step</span><span class="p">(</span><span class="n">previous</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="n">motion_model_sigma</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate predictive density given control and control stddev.&quot;&quot;&quot;</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">motion_model_sigma</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">predictive_density</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
            <span class="c1"># Speedup 1: threshold on previous[i,j]</span>
            <span class="k">if</span> <span class="n">previous</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">1e-5</span><span class="p">:</span>
                <span class="n">previous_xy</span> <span class="o">=</span> <span class="n">logistics</span><span class="o">.</span><span class="n">map_coords</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
                <span class="n">mean</span> <span class="o">=</span> <span class="n">previous_xy</span> <span class="o">+</span> <span class="n">control</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
                    <span class="c1"># Speedup 1: vectorize Gaussian evaluation over predictive row:</span>
                    <span class="n">motion_model</span> <span class="o">=</span> <span class="n">logistics</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">map_coords</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span>
                    <span class="n">predictive_density</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">motion_model</span> <span class="o">*</span> <span class="n">previous</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">predictive_density</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">predictive_density</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If we have <em>no</em> measurements at all, but have a perfect measurement model, our “control tape” just pushes the Gaussian density along:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">motion_model_sigma</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">current_density</span> <span class="o">=</span> <span class="n">prior</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="c1"># prediction phase</span>
    <span class="n">control</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="c1"># ground truth control</span>
    <span class="n">current_density</span> <span class="o">=</span> <span class="n">prediction_step</span><span class="p">(</span><span class="n">current_density</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="n">motion_model_sigma</span><span class="p">)</span>
<span class="c1"># logistics.show_map(current_density/np.max(current_density) + 0.1*logistics.base_map)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 15.5 s, sys: 7.17 ms, total: 15.5 s
Wall time: 15.5 s
</pre></div>
</div>
</div>
</div>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures4/predictive.gif?raw=1" id="fig:predictive" style="width:14cm" alt="">
<figcaption>Evolution of the predictive density (no measurements).</figcaption>
</figure>
<p>The figure above shows the result of purely predictive reasoning using a finite element discretization. As you can see, the density grows without bounds, and also goes <em>inside</em> the shelves. Without any measurements, we really do not know any better.</p>
<p>The measurement update step takes the predictive density <span class="math notranslate nohighlight">\(P(X_{k}|\mathcal{Z}^{k-1},\mathcal{U}^{k})\)</span> and <em>upgrades</em> it to the posterior density:</p>
<div class="math notranslate nohighlight">
\[
P(X_{k}|\mathcal{Z}^{k},\mathcal{U}^{k}) \propto L(X_{k};z_{k})P(X_{k}|\mathcal{Z}^{k-1},\mathcal{U}^{k}).
\]</div>
<p>Note that this is so much simpler! We just have to code a pointwise multiplication and we are done. Because the ground truth trajectory never comes near and of the shelves, the proximity sensor is always <code class="docutils literal notranslate"><span class="pre">OFF</span></code>, and hence we multiply the predictive density with the corresponding <code class="docutils literal notranslate"><span class="pre">proximity_map_off</span></code> likelihood image:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">predictive_density</span> <span class="o">=</span> <span class="n">prior</span>
<span class="n">posterior_density</span> <span class="o">=</span> <span class="n">predictive_density</span> <span class="o">*</span> <span class="n">logistics</span><span class="o">.</span><span class="n">proximity_map_off</span>
<span class="n">posterior_density</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior_density</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="c1"># prediction phase</span>
    <span class="n">control</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="c1"># ground truth control</span>
    <span class="n">predictive_density</span> <span class="o">=</span> <span class="n">prediction_step</span><span class="p">(</span><span class="n">posterior_density</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="n">motion_model_sigma</span><span class="p">)</span>
    <span class="c1"># measurement update phase</span>
    <span class="n">posterior_density</span> <span class="o">=</span> <span class="n">predictive_density</span> <span class="o">*</span> <span class="n">logistics</span><span class="o">.</span><span class="n">proximity_map_off</span>
    <span class="n">posterior_density</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior_density</span><span class="p">)</span>
<span class="c1"># logistics.show_map(posterior_density/np.max(posterior_density) + 0.1*logistics.base_map)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 5.66 s, sys: 3.94 ms, total: 5.67 s
Wall time: 5.68 s
</pre></div>
</div>
</div>
</div>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures4/posterior.gif?raw=1" id="fig:posterior" style="width:14cm" alt="">
<figcaption>Markov localization in action.</figcaption>
</figure>
<p>The figure above shows Markov localization in action! The measurement information has <em>literally</em> squeezed the predictive density to a posterior that fuses predictive information with the knowledge that we cannot be anywhere near the shelves, or the wall. Note that the density is still spreading in the direction that the sensor does <em>not</em> yield information.</p>
<div class="section" id="exercises">
<h4><span class="section-number">4.4.1.3.1. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>In principle our motion model should have told us that we cannot move inside shelves. How would you change the prediction code to make this so?</p></li>
<li><p>The full Markov localization algorithm takes <em>less</em> time than the code <em>without</em> the measurement update. We do more work yet have faster inference. Why?</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="monte-carlo-localization">
<h2><span class="section-number">4.4.2. </span>Monte Carlo Localization<a class="headerlink" href="#monte-carlo-localization" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Localization with a particle-filter is known as Monte Carlo Localization.</p>
</div></blockquote>
<p>Samples are cheaper, faster, and better. The above finite element discretization of space is very costly, and most of the memory and computation is used to compute near-zero probabilities.
While there <em>are</em> ways to deal with this, switching to a sampling-based representation gets us more bang for the buck, computation-wise. And, as we will see, it also leads to a very simple algorithm.
The sampling-based implementation of a Bayes filter is known as a <strong>particle filter</strong>.
Below we discuss it in a 2D context, but it is in fact rather general.
When used for robot localization, this technique is known as <a class="reference external" href="https://www.ri.cmu.edu/publications/monte-carlo-localization-for-mobile-robots/">“Monte Carlo Localization” or MCL</a>.</p>
<p>A particle filter approximates the Bayes filter by (1) replacing an explicit probability mass function over finite elements with a set of samples, and (b) approximating the prediction step in the Bayes filter with a Monte Carlo approximation. We recursively assume to have access to a sampling based approximation of the filtering density over the previous state <span class="math notranslate nohighlight">\(x_{k-1}\)</span>, as a set of <span class="math notranslate nohighlight">\(S\)</span> <em>weighted</em> samples:</p>
<div class="math notranslate nohighlight">
\[
p(x_{t-1}|\mathcal{Z}^{k-1},\mathcal{U}^{k-1}) \approx \{x_{k-1}^{(s)}, w_{k-1}^{(s)}\}.
\]</div>
<p>We then implemented proceed in two phases:</p>
<ol class="simple">
<li><p>In the prediction phase we approximate the predictive distribution
<span class="math notranslate nohighlight">\(p(x_{k}|\mathcal{Z}^{k-1},\mathcal{U}^{k})\)</span> by drawing <span class="math notranslate nohighlight">\(S\)</span> <em>unweighted</em> samples from the following <strong>mixture density</strong> of motion model densities:
$<span class="math notranslate nohighlight">\(
\{ x_k^{(t)} \} \sim \sum_s w_{k-1}^{(s)} P(x_{k}|x_{k-1}^{(s)},u_{k-1})P(x_{t-1}^{(s)}|\mathcal{Z}^{k-1},\mathcal{U}^{k-1}).
\)</span>$</p></li>
<li><p>In the measurement phase we upgrade this predictive density to a weighted sample approximation of the filtering distribution, by weighting each unweighted sample with the likelihood of <span class="math notranslate nohighlight">\(x_k^{(t)}\)</span> given the measurement <span class="math notranslate nohighlight">\(z_{k}\)</span>:
$<span class="math notranslate nohighlight">\(
p(x_{t-1}|\mathcal{Z}^{k-1},\mathcal{U}^{k-1}) \approx \{x_k^{(t)}, L(x_k^{(t)};z_{k})\}.
\)</span>$</p></li>
</ol>
<p>We start off the algorithm with a set of <span class="math notranslate nohighlight">\(S\)</span> samples from the prior, weighted by the likelihood on the first <span class="math notranslate nohighlight">\(x_1\)</span> given the first measurement <span class="math notranslate nohighlight">\(z_1\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(X_1|\mathcal{Z}^1=\{z_1\}, \mathcal{U}^1=\{\}) \approx \{x_1^{(t)}, L(x_1^{(t)};z_1)\}~\text{with}~x_1^{(t)}\sim p(x_1)
\]</div>
<p>In the “vanilla” particle filter outlined above, the number of samples stays constant over time, but variants exist that adapt the number of samples to the complexity of the density over time, or even to the available computation. Used in that way, a particle filter can be used as a “just in time” algorithm.</p>
<div class="section" id="the-prediction-step">
<h3><span class="section-number">4.4.2.1. </span>The Prediction Step<a class="headerlink" href="#the-prediction-step" title="Permalink to this headline">¶</a></h3>
<p>Again, the prediction phase is the most complex. A mixture density is simply a weighted sum of <em>component densities</em>, in this case a set of motion models. The weights are a probability mass function over the component indices and hence should sum to 1. Sampling from a mixture density proceeds in two steps:</p>
<ol class="simple">
<li><p>Pick a component according to the weight distribution;
2 sample from the component.</p></li>
</ol>
<p>As a toy example, let us assume a <em>Gaussian mixture density</em> with just two Gaussian components, respectively with weights 0.9 and 0.1:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">20</span><span class="p">,</span><span class="mi">25</span><span class="p">),(</span><span class="mi">70</span><span class="p">,</span><span class="mi">40</span><span class="p">)]]</span>
<span class="n">covariances</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="n">sx</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">sy</span><span class="o">**</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">sx</span><span class="p">,</span><span class="n">sy</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">)]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">go</span><span class="o">.</span><span class="n">Contour</span><span class="p">(</span><span class="n">z</span><span class="o">=</span><span class="n">logistics</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">map_coords</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">),</span> <span class="n">contours_coloring</span><span class="o">=</span><span class="s1">&#39;lines&#39;</span><span class="p">,</span> 
        <span class="n">line_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">showscale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">mean</span><span class="p">,</span><span class="n">cov</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">,</span><span class="n">covariances</span><span class="p">)]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">);</span> <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_28_0.png" src="_images/S44_logistics_perception_28_0.png" />
</div>
</div>
<p>The following code samples 100 samples, rather inefficiently:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">component_indices</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span><span class="mf">0.1</span><span class="p">])</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">covariances</span><span class="p">[</span><span class="n">s</span><span class="p">])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">component_indices</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">samples</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">samples</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span> 
        <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_30_0.png" src="_images/S44_logistics_perception_30_0.png" />
</div>
</div>
<p>As you can see the first component is chosen much more often, which is exactly what we expected.</p>
<p>Armed with this general knowledge about sampling mixtures, we apply it below to code up the MCL prediction step:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="n">motion_model_sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create predictive density from weighted samples given control and control stddev.&quot;&quot;&quot;</span>
    <span class="n">weights</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">component_indices</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">samples</span> <span class="o">+</span> <span class="n">control</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">motion_model_sigma</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">cov</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">component_indices</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluating-the-likelihood">
<h3><span class="section-number">4.4.2.2. </span>Evaluating the Likelihood<a class="headerlink" href="#evaluating-the-likelihood" title="Permalink to this headline">¶</a></h3>
<p>As before, we know that the ground truth trajectory stays away from obstacles at all times. However, we only have access to a likelihood <em>image</em>, not a function that evaluates the likelihood for an arbitrary coordinate. The following function calculates the correct cell for looking up the likelihood, and returns 0 likelihood if out of bounds:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood_off</span><span class="p">(</span><span class="n">xy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate likelihood by looking up value in proximity_map_off.&quot;&quot;&quot;</span>
    <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">0</span> <span class="ow">or</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">49</span> <span class="ow">or</span> <span class="n">j</span><span class="o">&lt;</span><span class="mi">0</span> <span class="ow">or</span> <span class="n">j</span><span class="o">&gt;</span><span class="mi">99</span><span class="p">:</span> <span class="k">return</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">proximity_map_off</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="mcl-warehouse-example">
<h3><span class="section-number">4.4.2.3. </span>MCL Warehouse Example<a class="headerlink" href="#mcl-warehouse-example" title="Permalink to this headline">¶</a></h3>
<p>Now that we know how to do the prediction step and evaluate the likelihood function, we are able to implement the entire Monte Carlo localization method. First, let us obtain 500 samples from the posterior:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">S</span><span class="o">=</span><span class="mi">500</span>
<span class="n">prior_samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">S</span><span class="p">)</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="n">prior_samples</span><span class="p">,</span>
         <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_36_0.png" src="_images/S44_logistics_perception_36_0.png" />
</div>
</div>
<p>Compare this sampling-based representation with the Markov localization representation of the prior above, and note they represent the <em>same</em> density, but using vastly different representations. In fact, they also use vastly different resources: for Markov localization we used 5000 cells, and here we use 500 two-dimensional vectors. In higher-dimensional state spaces this difference is even greater: what would happen if we wanted to represent orientation as well?</p>
<p>However, as discussed, we start off MCL with a set of <em>weighted</em> samples <span class="math notranslate nohighlight">\(\{x_1^{(t)}, L(x_1^{(t)};z_1)\}\)</span>, which represents the posterior for <span class="math notranslate nohighlight">\(k=1\)</span>. We do this by weighting each sample from the prior with the likelihood:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">prior_samples</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">likelihood_off</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
         <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="n">weights</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">weights</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_38_0.png" src="_images/S44_logistics_perception_38_0.png" />
</div>
</div>
<p>Note that all samples close to the wall and/or the shelves have disappeared, as they have zero weight. All remaining samples have the same weight.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="c1"># prediction phase</span>
    <span class="n">control</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>  <span class="c1"># ground truth control</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">predict_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="n">motion_model_sigma</span><span class="p">)</span>
    <span class="c1"># measurement update phase</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">likelihood_off</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
<span class="c1"># logistics.show_map(0.1*logistics.base_map, markers=samples,</span>
<span class="c1">#          marker=dict(color=&quot;red&quot;, opacity=0.1, size=10*weights/np.max(weights)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 445 ms, sys: 29 µs, total: 445 ms
Wall time: 445 ms
</pre></div>
</div>
</div>
</div>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures4/samples.gif?raw=1" id="fig:samples" style="width:14cm" alt="">
<figcaption>Monte Carlo localization in action.</figcaption>
</figure>
<p>The figure above shows Monte Carlo localization in action! Comparing with Markov localization, we see that the results are consistent. Not only that, but if you look at the timing numbers, MCL runs at least an order of magnitude faster.</p>
<p>You might wonder about the samples that made it into the seemingly <em>wrong</em> aisles between the shelves. However, if we crank up the Markov localization visualization by a factor of 10, you will see that <em>in</em> fact the probability of being in those aisles is actually non-zero:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="mi">10</span><span class="o">*</span><span class="n">posterior_density</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">posterior_density</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_42_0.png" src="_images/S44_logistics_perception_42_0.png" />
</div>
</div>
<p>MCL can be made to be <em>more</em> accurate than Markov localization, as in the limit an infinite number of samples will represent the actual densities exactly. Of course, we can also increase the resolution of the Markov localization representation, but at exponential cost. In contrast, the samples needed are proportional to the “volume” that the density occupies, an observation that underlies adaptive variants.</p>
</div>
<div class="section" id="adding-range-sensing">
<h3><span class="section-number">4.4.2.4. </span>Adding Range Sensing<a class="headerlink" href="#adding-range-sensing" title="Permalink to this headline">¶</a></h3>
<p>Finally, and this is will be rather easy in MCL, let us investigate the effect of adding range sensing. This time we won’t have the luxury to know the entire measurement sequence in advance, as we did with proximity. Rather, the likelihood will have to be given the output of the RFID sensor. Remember that was either a beacon ID and a range <span class="math notranslate nohighlight">\((i,r)\)</span>, or <span class="math notranslate nohighlight">\((\text{None},\infty)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood_range</span><span class="p">(</span><span class="n">xy</span><span class="p">,</span> <span class="n">rfid_measurement</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate likelihood of xy given range measurement.&quot;&quot;&quot;</span>
    <span class="n">_id</span><span class="p">,</span> <span class="n">_range</span> <span class="o">=</span> <span class="n">rfid_measurement</span>
    <span class="k">if</span> <span class="n">_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">49</span> <span class="ow">or</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">99</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">out_of_bound_map</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># In meters</span>
        <span class="n">range_for_xy</span> <span class="o">=</span> <span class="n">logistics</span><span class="o">.</span><span class="n">rfid_range</span><span class="p">(</span><span class="n">xy</span><span class="p">,</span> <span class="n">logistics</span><span class="o">.</span><span class="n">beacons</span><span class="p">[</span><span class="n">_id</span><span class="p">])</span>
        <span class="k">return</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">range_for_xy</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">range_for_xy</span> <span class="o">-</span> <span class="n">_range</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can also use this to illustrate how to <em>globally</em> localize, without any prior information at all, except that we are <em>somewhere</em> in the warehouse. We can encode this knowledge as samples by uniformly sampling over the entire range for <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>. Because our knowledge is now so diffuse, we use 2000 samples instead of 500 to better approximate it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">T</span><span class="o">=</span><span class="mi">2000</span>
<span class="n">prior_samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="n">gtsam</span><span class="o">.</span><span class="n">Point2</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="n">prior_samples</span><span class="p">,</span>
         <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_47_0.png" src="_images/S44_logistics_perception_47_0.png" />
</div>
</div>
<p>The first range measurement happens to be out if range, and we can see the effect on our estimate for the posterior <span class="math notranslate nohighlight">\(p(x_1|z_1)\)</span> quite clearly:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">prior_samples</span>
<span class="n">range_measurement</span> <span class="o">=</span> <span class="n">logistics</span><span class="o">.</span><span class="n">rfid_measurement</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">likelihood_range</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">range_measurement</span><span class="p">)</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
         <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="n">weights</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">weights</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_49_0.png" src="_images/S44_logistics_perception_49_0.png" />
</div>
</div>
<p>As expected, the likelihood has “punched holes” around the beacons, because we <em>know</em> we cannot have been near them. This is the power of <em>negative</em> information. When we combine it with the proximity OFF measurement, we narrow our posterior down even more:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weights</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">likelihood_off</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
         <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="n">weights</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">weights</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_51_0.png" src="_images/S44_logistics_perception_51_0.png" />
</div>
</div>
<p>We are now ready to bring it all together, now multiplying <em>two</em> likelihoods in ever measurement update phase:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="c1"># prediction phase</span>
    <span class="n">control</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>  <span class="c1"># ground truth control</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">predict_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="n">motion_model_sigma</span><span class="p">)</span>
    <span class="c1"># measurement update phase</span>
    <span class="n">range_measurement</span> <span class="o">=</span> <span class="n">logistics</span><span class="o">.</span><span class="n">rfid_measurement</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span>
        <span class="n">likelihood_range</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">range_measurement</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">likelihood_off</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
<span class="c1"># logistics.show_map(0.1*logistics.base_map, markers=samples,</span>
<span class="c1">#          marker=dict(color=&quot;red&quot;, opacity=0.1, size=10*weights/np.max(weights)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 494 ms, sys: 6 µs, total: 494 ms
Wall time: 494 ms
</pre></div>
</div>
</div>
</div>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures4/global.gif?raw=1" id="fig:global" style="width:14cm" alt="">
<figcaption>Global localization using MCL aided by range sensing.</figcaption>
</figure>
<p>The figure above shows global localization in action! At the onset, we are very confused as to where we might be in the warehouse, but we still have <em>some</em> knowledge. Then we move within range of beacon <span class="math notranslate nohighlight">\(0\)</span>, which immediately localizes us: it acts a bit like a GPS sensor, especially in combination with what we sensed before. After that the particular shape of the range likelihoods makes for some interesting antics, and at the end we are quite a bit more certain that we are in the center aisle.</p>
<p>This example showed off <em>two</em> really nice properties of Monte Carlo localization (and, for that matter, Markov localization):</p>
<ol class="simple">
<li><p>We can reason about multi-modela densities and even the complete absence of knowledge.</p></li>
<li><p>We can incorporate powerful, <em>negative</em> information, such as out of range measurements.</p></li>
</ol>
<p>To emphasize the latter point even more, note that for the last few time steps in the animation above we are <em>out</em> of beacon range, and you can see a bit of “squeezing” of the sample cloud at the very top, because of this. Negative information for the win!</p>
</div>
</div>
<div class="section" id="kalman-smoothing-and-filtering">
<h2><span class="section-number">4.4.3. </span>Kalman Smoothing and Filtering<a class="headerlink" href="#kalman-smoothing-and-filtering" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Where Gaussians are used, Kalman was there first.</p>
</div></blockquote>
<p>The final and mathematically most challenging approach we will discuss is Kalman smoothing and filtering. Ironically, while the math is harder, the circumstances in which these methods can be applied are more limited.
The math is only exact for (a) linear measurement models and (b) Gaussian additive noise.
In addition, although there are ways to deal with nonlinear sensors, a more serious limitation is that the density on the state can only ever be Gaussian itself.</p>
<p>These methods are incredibly important in robotics, however, For all their limitations, Kalman smoothers and filters are incredibly efficient, and are at the core of the navigation stack of many systems, robots and otherwise. In fact, the Kalman filter was developed in order to perform navigation on board of military aircraft in the sixties, and were able to run on the extremely limited computational hardware - by today’s standards - on board those aircraft.</p>
<div class="section" id="factor-graphs-and-least-squares">
<h3><span class="section-number">4.4.3.1. </span>Factor Graphs and Least Squares<a class="headerlink" href="#factor-graphs-and-least-squares" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>When given measurements and actions, we create a factor graph directly.</p>
</div></blockquote>
<p><strong>Kalman smoothing</strong> is the equivalent of the Viterbi algorithm for hidden Markov model, but for continuous state spaces.</p>
<p>In the continuous case, we build the factors directly from given controls and measurements. A factor graph now encodes the negative log-posterior</p>
<div class="math notranslate nohighlight">
\[\Phi(X)=\sum_i \phi(X_i) = \frac{1}{2} \sum_i \|A_i X_i-b_i\|^2.\]</div>
<p>In the continuous case we use <em>minimization</em> of the log-likelihood rather than maximization over the probabilities. The main reason is because then inference becomes a linear least squares problem.</p>
<p>A least-squares problem is convex and can be solved in closed form. The linear terms within the square norm above are <em>sparse</em>, in the sense that <span class="math notranslate nohighlight">\(X_i\)</span> is only a <em>subset</em> of the continuous variables <span class="math notranslate nohighlight">\(X\)</span>. For example, a simple sensor fusion problem on two scalar variables <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> would be one where both have a simple prior on them, resp. with <span class="math notranslate nohighlight">\(\mu_1=3\)</span> and <span class="math notranslate nohighlight">\(\mu_2=7\)</span>, and we know that the difference between them is equal to <span class="math notranslate nohighlight">\(5\)</span>. This yields three factors that have to be minimized over <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\Phi(X)= \frac{1}{2} \|x_1-3\|^2 + \frac{1}{2} \|(x_2-x_1)-5\|^2 + \frac{1}{2} \|x_2-7\|^2.
\]</div>
<p>This corresponds to the following</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(X_i\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(A_i\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(b_i\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(x_1\)</span></p></td>
<td><p>[1]</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(x_1, x_2\)</span></p></td>
<td><p>[-1 1]</p></td>
<td><p>5</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(x_2\)</span></p></td>
<td><p>[1]</p></td>
<td><p>7</p></td>
</tr>
</tbody>
</table>
<p>We can collect all three matrices <span class="math notranslate nohighlight">\(A_1\)</span>, <span class="math notranslate nohighlight">\(A_2\)</span>, and <span class="math notranslate nohighlight">\(A_3\)</span> into one sparse matrix <span class="math notranslate nohighlight">\(A\)</span> and corresponding right-hand-side <span class="math notranslate nohighlight">\(b\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}A=\begin{pmatrix} 1 &amp; 0 \\ -1 &amp; 1 \\ 0 &amp; 1 \end{pmatrix}~~\text{and}~~B=\begin{pmatrix} 3 \\ 5 \\ 7 \end{pmatrix}.\end{split}\]</div>
<p>You can convince yourself that the minimization problem can then be written as</p>
<div class="math notranslate nohighlight">
\[X^* = \arg \min_X \Phi(X) = \arg \min_X \frac{1}{2} \|A X-b\|^2\]</div>
<p>which is now a <em>sparse</em> linear least-squares problem.</p>
<p>Setting the derivative to zero and solving for <span class="math notranslate nohighlight">\(X^*\)</span> we obtain:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
A^T(A X^* - b) &amp;= 0 \\
(A^T A) X^* &amp;= A^T b \\
X^* &amp;= (A^T A)^{-1} A^T b 
\end{align*}\end{split}\]</div>
<p>This is known as a <strong>system of normal equations</strong>, and the last equation above is a closed from solution for it.</p>
<p>Solving a linear least-squares problem this way can be expensive. The matrix <span class="math notranslate nohighlight">\(A\)</span> can be very high dimensional, but luckily in many sensor fusion scenarios it is exceedingly <em>sparse</em>. Still, we have to proceed with some care, as in general the matrix <span class="math notranslate nohighlight">\((A^T A)^{-1}\)</span> is <em>not</em> sparse. The matrix <span class="math notranslate nohighlight">\(Q \doteq A^T A\)</span> is known as the <strong>Hessian</strong> or <strong>Information Matrix</strong> and has dimensions <span class="math notranslate nohighlight">\(n\times n\)</span> if there are <span class="math notranslate nohighlight">\(n\)</span> scalar unknowns. In general, it takes <span class="math notranslate nohighlight">\(O(n^3)\)</span> work to compute it, which is only 27 for <span class="math notranslate nohighlight">\(n=3\)</span>, but is already 1 <em>billion</em> for <span class="math notranslate nohighlight">\(n=1000\)</span>.</p>
</div>
<div class="section" id="numerical-example">
<h3><span class="section-number">4.4.3.2. </span>Numerical Example<a class="headerlink" href="#numerical-example" title="Permalink to this headline">¶</a></h3>
<p>It is trivial to implement in numpy for the small example above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">],[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span><span class="mf">5.</span><span class="p">,</span><span class="mf">7.</span><span class="p">])</span>
<span class="n">X_optimal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">A</span><span class="p">)</span> <span class="o">@</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_optimal</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2.66666667 7.33333333]
</pre></div>
</div>
</div>
</div>
<p>Note that in this simple sensor fusion example, a compromise solution is obtained: all factors are equally <em>unhappy</em>. We can compute the error vector as <span class="math notranslate nohighlight">\(A X^* - b\)</span> and find that the errors is equally divided between all factors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">X_optimal</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-0.33333333 -0.33333333  0.33333333]
</pre></div>
</div>
</div>
</div>
<div class="section" id="exercise">
<h4><span class="section-number">4.4.3.2.1. </span>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">¶</a></h4>
<p>What would make the errors <em>not</em> divide equally between factors?</p>
</div>
</div>
<div class="section" id="sparse-least-squares">
<h3><span class="section-number">4.4.3.3. </span>Sparse Least-Squares<a class="headerlink" href="#sparse-least-squares" title="Permalink to this headline">¶</a></h3>
<p>In practice we use <em>sparse factorization methods</em> to solve for <span class="math notranslate nohighlight">\(X^*\)</span>. In particular, <em>sparse Cholesky</em> factorization can efficiently decompose the sparse Hessian <span class="math notranslate nohighlight">\(Q\)</span> into its matrix square root <span class="math notranslate nohighlight">\(R\)</span></p>
<div class="math notranslate nohighlight">
\[A^T A=R^T R\]</div>
<p>where <span class="math notranslate nohighlight">\(R\)</span> is <em>upper-triangular</em> and sparse as well. There is one wrinkle: the sparsity of <span class="math notranslate nohighlight">\(R\)</span> depends (dramatically) on the column ordering chosen for <span class="math notranslate nohighlight">\(A\)</span>, and the optimal ordering is hard to find (NP-complete, in fact). Hence, many heuristic ordering methods exist that are applied in practice.</p>
<p>After we found <span class="math notranslate nohighlight">\(R\)</span>, which is where the heavy lifting occurs, we can efficiently solve for <span class="math notranslate nohighlight">\(X^*\)</span> in two steps. First, we solve for an auxiliary vector <span class="math notranslate nohighlight">\(y\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
(R^T R) X^* &amp;= A^T b \\
R^T (R X^*) &amp;= A^T b \\
R^T y &amp;= A^T b
\end{align*}\end{split}\]</div>
<p>In the last line, <span class="math notranslate nohighlight">\(R^T\)</span> is lower-triangular, and hence <span class="math notranslate nohighlight">\(y\)</span> can be easily solved for proceeding from <span class="math notranslate nohighlight">\(y_1\)</span> to <span class="math notranslate nohighlight">\(y_n\)</span>, via <em>forward-substitution</em>. We then turn around use the computed value of <span class="math notranslate nohighlight">\(y\)</span> to solve for <span class="math notranslate nohighlight">\(X^*\)</span> by <em>back-substitution</em>:</p>
<div class="math notranslate nohighlight">
\[R X^*=y.\]</div>
<p>Both these steps are <span class="math notranslate nohighlight">\(O(n^2)\)</span> for dense matrices, but typically closer to <span class="math notranslate nohighlight">\(O(n)\)</span> for sparse matrices.</p>
<p>There is a deep connection between sparse factorization methods and the sum-product algorithm discussed in the previous chapter. In fact, sparse factorization <em>is</em> sum-product, where one continuous variable is eliminated at a time. The factor graph corresponding to a sparse least squares problem correspond to its sparsity pattern. In this graphical framework, the <em>product</em> is implemented by collecting all factors connected to that variable, and the <em>sum</em> is implemented by expressing the variable to be eliminated as a linear combination of its neighbors in the graph.</p>
</div>
<div class="section" id="example-with-gps-like-measurements">
<h3><span class="section-number">4.4.3.4. </span>Example with GPS-Like Measurements<a class="headerlink" href="#example-with-gps-like-measurements" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>We build a factor graph and then simply call optimize.</p>
</div></blockquote>
<p>GTSAM is built around state of the art sparse factorization methods, and hence can very efficiently solve large sensor fusion problems, like the localization problem with GPS-like measurements.
Below we illustrate this with an example in code for the GPS-like measurements, which is easily tackled using optimization. Range measurements can also be handled, but <em>out of range</em> measurements are not so easy, so we will defer handling range to the next section.</p>
<p>We simulate measurements using the ground truth trajectory but with noise added, by creating a quick Bayes net do this for us. Remember from the previous section that the measurements are in centimeters, so the number <span class="math notranslate nohighlight">\(30\)</span> below is the standard deviation of the measurement noise, in centimeters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">C</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">measurement_model_sigma</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">symbol</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">}</span>
<span class="n">bn</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">GaussianBayesNet</span><span class="p">()</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
    <span class="n">conditional_on_zk</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">GaussianConditional</span><span class="o">.</span><span class="n">FromMeanAndStddev</span><span class="p">(</span>
        <span class="n">z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">C</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">measurement_model_sigma</span><span class="p">)</span>
    <span class="n">bn</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">conditional_on_zk</span><span class="p">)</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;measurement on </span><span class="si">{</span><span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">simulation</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>measurement on [10.  6.] = [1038.61635761  632.63644323]
</pre></div>
</div>
</div>
</div>
<p>Notice how the measurement is scaled by 100, and is corrupted by noise. Now we are finally ready to create a GaussianFactorGraph that will fuse the information from the prior, the measurements, and the motion models:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gfg</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">GaussianFactorGraph</span><span class="p">()</span>

<span class="c1"># The prior</span>
<span class="n">p_x1</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">GaussianDensity</span><span class="o">.</span><span class="n">FromMeanAndStddev</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">gfg</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">p_x1</span><span class="p">)</span>

<span class="c1"># Create motion model factors from ground truth trajectory displacements</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="n">next_state</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">displacement</span> <span class="o">=</span> <span class="n">next_state</span> <span class="o">-</span> <span class="n">state</span>
    <span class="c1"># |next_state - (A*state + B*u)|</span>
    <span class="n">gfg</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">GaussianConditional</span><span class="o">.</span><span class="n">FromMeanAndStddev</span><span class="p">(</span>
        <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">displacement</span><span class="p">,</span> <span class="n">motion_model_sigma</span><span class="p">))</span>

<span class="c1"># Convert the conditionals in Bayes net from above into likelihood factors</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
    <span class="n">conditional_on_zk</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">measurement</span> <span class="o">=</span> <span class="n">simulation</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="n">likelihood_on_xk</span> <span class="o">=</span> <span class="n">conditional_on_zk</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">measurement</span><span class="p">)</span>
    <span class="n">gfg</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">likelihood_on_xk</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Below we show the factor graph, which looks exactly like the one for inference in an HMM, except we now have more states, and they are continuous. The two problems have essentially the same computational <em>structure</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">position_hints</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="n">pos</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:(</span><span class="mf">0.35</span><span class="p">,</span><span class="mi">1</span><span class="p">)}</span>
<span class="n">pos</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">k</span><span class="p">:(</span><span class="n">k</span><span class="o">+</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]})</span> <span class="c1"># binary</span>
<span class="n">pos</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">k</span><span class="o">+</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">:(</span><span class="n">k</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">})</span> <span class="c1"># unary</span>
<span class="n">show</span><span class="p">(</span><span class="n">gfg</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="n">position_hints</span><span class="p">,</span> <span class="n">factor_positions</span><span class="o">=</span><span class="n">pos</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_73_0.svg" src="_images/S44_logistics_perception_73_0.svg" /></div>
</div>
<p>Now we can find the optimal solution, using the <code class="docutils literal notranslate"><span class="pre">optimize</span></code> method. In the Gaussian factor graph case, this solves a linear least-squares problem with a continuous variant of the sum-product algorithm:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">least_squares_solution</span> <span class="o">=</span> <span class="n">gfg</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Below we compare the estimated trajectory with the ground truth trajectory:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">least_squares_solution</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
<span class="n">logistics</span><span class="o">.</span><span class="n">show_map</span><span class="p">(</span><span class="n">logistics</span><span class="o">.</span><span class="n">base_map</span><span class="p">,</span> <span class="n">estimated</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_77_0.png" src="_images/S44_logistics_perception_77_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="gtsam-102">
<h2><span class="section-number">4.4.4. </span>GTSAM 102<a class="headerlink" href="#gtsam-102" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>A deeper dive in the GTSAM concepts used above.</p>
</div></blockquote>
<p>Recall the <code class="docutils literal notranslate"><span class="pre">gtsam.GaussianFactorGraph</span></code> <code class="docutils literal notranslate"><span class="pre">gfg</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">show</span><span class="p">(</span><span class="n">gfg</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="n">position_hints</span><span class="p">,</span> <span class="n">factor_positions</span><span class="o">=</span><span class="n">pos</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_80_0.svg" src="_images/S44_logistics_perception_80_0.svg" /></div>
</div>
<p>We can also visualize the sparse <span class="math notranslate nohighlight">\(A\)</span> matrix, which is called the <strong>sparse Jacobian</strong> of the system:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># show [A|b]</span>
<span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">gfg</span><span class="o">.</span><span class="n">jacobian</span><span class="p">()</span>
<span class="n">px</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="n">color_continuous_scale</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_82_0.png" src="_images/S44_logistics_perception_82_0.png" />
</div>
</div>
<p>In fact, the deep connection between factor graphs and sparse linear algebra is this:</p>
<blockquote>
<div><p>Columns correspond to variables, and rows correspond to factors</p>
</div></blockquote>
<p>You can make out, from the top:</p>
<ul class="simple">
<li><p>the first two rows correspond to the prior</p></li>
<li><p>the two darker diagonals correspond to the motion model factors</p></li>
<li><p>the single red diagonal corresponds to the measurements</p></li>
</ul>
<p>We can use the method <code class="docutils literal notranslate"><span class="pre">eliminateSequential</span></code> to use the linear-Gaussian sum-product algorithm (matrix factorization!) to turn it into a Bayes net, which encodes the multivariate Gaussian posterior:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian_posterior</span> <span class="o">=</span> <span class="n">gfg</span><span class="o">.</span><span class="n">eliminateSequential</span><span class="p">()</span>
<span class="n">show</span><span class="p">(</span><span class="n">gaussian_posterior</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="n">position_hints</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_85_0.svg" src="_images/S44_logistics_perception_85_0.svg" /></div>
</div>
<p>This Bayes net <em>is</em> the upper-triangular (DAG!) Cholesky factor <span class="math notranslate nohighlight">\(R\)</span> we discussed above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">gaussian_posterior</span><span class="o">.</span><span class="n">matrix</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">px</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">R</span><span class="p">),</span> <span class="n">color_continuous_scale</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S44_logistics_perception_87_0.png" src="_images/S44_logistics_perception_87_0.png" />
</div>
</div>
<p>Indeed, here the correspondence is:</p>
<blockquote>
<div><p>columns correspond to variables, and rows correspond to Gaussian conditionals.</p>
</div></blockquote>
<p>In general, the correspondence is about <em>block</em> columns, as vraiables in this case are two-dimensional, and <em>block</em> rows. For example, the first <code class="docutils literal notranslate"><span class="pre">GaussianConditional</span></code> in the <code class="docutils literal notranslate"><span class="pre">gaussian_posterior</span></code> Bayes net corresponds to the first two rows above, and can be shown like so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian_posterior</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s2">&quot;First two rows are: &quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First two rows are:  p(x1 | x2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  R = [ 3.91933       0 ]
      [       0 3.91933 ]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  S[x2] = [ -0.0637865          0 ]
          [          0 -0.0637865 ]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  d = [ 39.3312 24.0585 ]
  No noise model
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="S43_logistics_sensing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">4.3. </span>Sensor Models with Continuous State</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="S45_logistics_planning.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4.5. </span>Planning for Logistics</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Frank Dellaert and Seth Hutchinson<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>