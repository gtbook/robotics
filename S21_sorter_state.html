
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2.1. Modeling the World State &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S21_sorter_state';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2.2. Actions for Sorting Trash" href="S22_sorter_actions.html" />
    <link rel="prev" title="2. A Trash Sorting Robot" href="S20_sorter_intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Introduction to Robotics and Perception - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S27_sorter_summary.html">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S32_vacuum_actions.html">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S21_sorter_state.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Modeling the World State</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-probability-to-model-uncertainty">2.1.1. Using Probability to Model Uncertainty</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-distributions">2.1.2. Probability Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-probability-distributions">2.1.3. Prior Probability Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-distributions-in-python">2.1.4. Probability Distributions in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-by-sampling">2.1.5. Simulation by Sampling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cumulative-distribution-function">2.1.5.1. Cumulative Distribution Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">2.1.5.2. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">2.1.6. GTSAM 101</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="modeling-the-world-state">
<h1><span class="section-number">2.1. </span>Modeling the World State<a class="headerlink" href="#modeling-the-world-state" title="Link to this heading">#</a></h1>
<p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S21_sorter_state.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<blockquote id="index-0">
<div><p>The physical properties of a piece of trash comprise all of the information needed by the robot.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S21-Trash_sorting_robot_with_gripper-09.jpg"><img alt="Splash image with robot approaching a trash bin" class="align-center" src="_images/S21-Trash_sorting_robot_with_gripper-09.jpg" style="width: 40%;" /></a>
<p>For our simple trash sorting robot, the only thing that matters at a given moment is the category
of the item of trash on the conveyor belt. Remember that items of trash are presented individually to the robot,
so there is no clutter, and no circumstance in which multiple pieces of trash are simultaneously in the workspace.
Therefore, it is natural to define the world state explicitly in terms of the category of the current
item of trash. We consider five possible categories:</p>
<ul class="simple">
<li><p>cardboard</p></li>
<li><p>paper</p></li>
<li><p>can</p></li>
<li><p>scrap metal</p></li>
<li><p>bottle</p></li>
</ul>
<p>For simplicity, we assume here that there will never be a piece of trash that does not belong to one of these categories.  We do not, however, assume that the category of an item can be reliably determined with 100% accuracy.
Instead, we use probability theory to quantify the uncertainty associated to an object’s categorization.</p>
<section id="using-probability-to-model-uncertainty">
<h2><span class="section-number">2.1.1. </span>Using Probability to Model Uncertainty<a class="headerlink" href="#using-probability-to-model-uncertainty" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Probability theory provides a rigorous methodology for reasoning about uncertainty.</p>
</div></blockquote>
<p>We will use probability theory to model uncertainty.
While a comprehensive coverage of probability theory is beyond the scope of this book,
we introduce key concepts and methods throughout the text, as needed,
to deal with various kinds of uncertainty that occur in robotics applications.
Rigorous introductions can be found in many textbooks, including the book  <a class="reference external" href="https://probability4datascience.com/index.html">“Introduction to Probability for Data Science”</a> <span id="id1">[<a class="reference internal" href="bibliography.html#id6" title="Stanley H. Chan. Introduction to Probability for Data Science. Michigan Publishing Services, 2023. ISBN 978-1-60785-747-1. URL: https://probability4datascience.com/index.html.">Chan, 2023</a>]</span> (which is available online).</p>
<p id="index-1">The starting point for reasoning with uncertainty is to define the set of outcomes that might occur.
The set of all possible outcomes is called the <strong>sample space</strong>, often denoted by <span class="math notranslate nohighlight">\(\Omega.\)</span>
In our example, when an item of trash arrives on the conveyor belt,
there are five possible outcomes,</p>
<div class="amsmath math notranslate nohighlight" id="equation-8cd0bfb5-2544-4087-b927-2b4f610f0b54">
<span class="eqno">(2.1)<a class="headerlink" href="#equation-8cd0bfb5-2544-4087-b927-2b4f610f0b54" title="Permalink to this equation">#</a></span>\[\begin{equation}
\Omega = \{ \rm{cardboard, paper, can, scrap \; metal, bottle}\}.
\end{equation}\]</div>
</section>
<section id="probability-distributions">
<span id="index-2"></span><h2><span class="section-number">2.1.2. </span>Probability Distributions<a class="headerlink" href="#probability-distributions" title="Link to this heading">#</a></h2>
<p>A subset of the sample space <span class="math notranslate nohighlight">\(\Omega\)</span> is called an <strong>event</strong>.  A <strong>probability distribution</strong>, <span class="math notranslate nohighlight">\(P\)</span>, assigns a probability <span class="math notranslate nohighlight">\(0 \leq P(A) \leq 1\)</span> to each event <span class="math notranslate nohighlight">\(A \subseteq \Omega\)</span>, with <span class="math notranslate nohighlight">\(P(\emptyset) = 0\)</span> and <span class="math notranslate nohighlight">\(P(\Omega)=1\)</span>.
In addition, for disjoint events, <span class="math notranslate nohighlight">\(A_i \cap A_j = \emptyset\)</span>, we have
<span class="math notranslate nohighlight">\(P(A_i \cup A_j) = P(A_i) + P(A_j)\)</span>.
Using this property, it is a simple matter to compute the probability for any <span class="math notranslate nohighlight">\(A \subseteq \Omega\)</span>
if we are provided with the probabilities of the individual outcomes.
Further, since <span class="math notranslate nohighlight">\(P(\Omega)=1\)</span>, it follows immediately that</p>
<div class="amsmath math notranslate nohighlight" id="equation-5ac4a7c1-f904-43cb-b22c-110469f85fae">
<span class="eqno">(2.2)<a class="headerlink" href="#equation-5ac4a7c1-f904-43cb-b22c-110469f85fae" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(\Omega) = \sum_{\omega \in \Omega} P(\{\omega\}) = 1
\end{equation}\]</div>
<p>i.e., that the probabilities of the individual outcomes sum to unity.
As a slight abuse of notation, for singleton events, we will often write <span class="math notranslate nohighlight">\(P(\omega)\)</span> rather than <span class="math notranslate nohighlight">\(P(\{\omega\})\)</span>
to simplify notation.</p>
<p>In robotics applications, the probability assigned to an outcome reflects our certainty in that outcome.
These probabilities can change based on the arrival of new evidence.
In robotics, this can occur when the robot acts in the world, or based on sensor data.
How evidence affects the propagation of probability values is a recurring topic in this book.</p>
</section>
<section id="prior-probability-distributions">
<span id="index-3"></span><h2><span class="section-number">2.1.3. </span>Prior Probability Distributions<a class="headerlink" href="#prior-probability-distributions" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>A <em>prior</em> describes our beliefs before any sensor data is obtained.</p>
</div></blockquote>
<p>Once we have enumerated the set of possible outcomes, we confront a fundamental question: <em>Where do the
probability values come from?</em> In this section we explicitly consider the notion of prior knowledge that is available in a particular application. High-quality “priors” can make a big difference in performance, especially when measurements are few or unreliable.</p>
<p>In some cases, we merely assume that all outcomes are equally likely, for example, when rolling a die or tossing coin.
In such cases, the probability of any outcome is merely <span class="math notranslate nohighlight">\(P(\omega) = 1/N\)</span> for each <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>, where <span class="math notranslate nohighlight">\(N =| \Omega |\)</span>.
This leads to <span class="math notranslate nohighlight">\(P(\mathrm{heads}) = P(\mathrm{tails}) = 0.5\)</span> when tossing a fair coin,
where <span class="math notranslate nohighlight">\(\Omega = \{ \mathrm{heads, tails} \}\)</span>.</p>
<p>In other cases, we can estimate probabilities using data.
Suppose, for example, that the owner of the trash-sorting facility has told us (or we have kept statistics over time) that for every 1000 pieces of trash, the observed category counts are approximately as follows:</p>
<ul class="simple">
<li><p>cardboard: 200</p></li>
<li><p>paper: 300</p></li>
<li><p>can: 250</p></li>
<li><p>scrap metal: 200</p></li>
<li><p>bottle: 50</p></li>
</ul>
<p>It is common to assume that outcomes occur in proportion to their probability. There are a number of
technical conditions that underlie this assumption, such as the condition that outcomes are independent,
but we will not address these here. Thus, from the above observed frequencies, we might estimate that the probability of seeing a piece of cardboard in the work cell is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-00bf910b-c77f-496a-9204-3b89ede46ad3">
<span class="eqno">(2.3)<a class="headerlink" href="#equation-00bf910b-c77f-496a-9204-3b89ede46ad3" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(\mathrm{cardboard}) \approx 200/1000 = 0.2
\end{equation}\]</div>
<p>Using the same logic, we can do this for all categories, yielding:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><em>Category (C)</em></p></th>
<th class="head text-center"><p><em>P(C)</em></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>cardboard</p></td>
<td class="text-center"><p>0.20</p></td>
</tr>
<tr class="row-odd"><td><p>paper</p></td>
<td class="text-center"><p>0.30</p></td>
</tr>
<tr class="row-even"><td><p>can</p></td>
<td class="text-center"><p>0.25</p></td>
</tr>
<tr class="row-odd"><td><p>scrap metal</p></td>
<td class="text-center"><p>0.20</p></td>
</tr>
<tr class="row-even"><td><p>bottle</p></td>
<td class="text-center"><p>0.05</p></td>
</tr>
</tbody>
</table>
</div>
<p id="index-4">We call this type of probabilistic knowledge about the state of the world, in the absence of any other information, a <strong>prior</strong>, because it represents our belief <em>before</em> any evidence (e.g., sensor data) has been acquired.</p>
<!-- Here, a word about notation is in order.  We use upper case letters to denote random quantities. For example, we use $C$ to denote the random outcome of a particular
category of trash arriving to the sorting station.  When you see an uppercase letter, it indicates that we do not know what value this outcome will take, but
that we do know a probability distribution for the values that could occur.
We use lower case letters, possibly subscripted, to denote specific outcomes. For example, we might define $c_1 =$ cardboard,
$c_2 =$ paper, etc.  Thus, we might write $P(C = c_1)$ or merely $P(c_1)$ to denote the prior probability that an item of trash is cardboard. --></section>
<section id="probability-distributions-in-python">
<h2><span class="section-number">2.1.4. </span>Probability Distributions in Python<a class="headerlink" href="#probability-distributions-in-python" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>We represent probability distributions using the <code class="docutils literal notranslate"><span class="pre">DiscreteDistribution</span></code> class in GTSAM.</p>
</div></blockquote>
<p id="index-7"><span id="index-6"></span><span id="index-5"></span>The GTSAM library (GTSAM stands for “Georgia Tech Smoothing and
Mapping”) is a BSD-licensed C++ library based on factor graphs which we make heavy use of in the code examples.
It provides state of the art solutions to important problems in robotics,
such as the Simultaneous Localization and Mapping (SLAM) and Structure from Motion (SfM) problems,
but can also be used to model and solve both
simpler and more complex estimation problems. More information is
available at <a class="reference external" href="http://gtsam.org">http://gtsam.org</a>.</p>
<p>GTSAM also provides both a MATLAB and a python interface,
enabling rapid prototype development, visualization, and user interaction.
The python library can be imported directly into a Google colab via
<code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">gtsam</span></code>. A large subset of the GTSAM functionality can be
accessed through wrapped classes from within python.
To not interrupt the flow of the book too much, we do not always fully explain the code throughout the text, but rather include a “GTSAM 101” subsection at the end that elaborates on the types and functions we used.</p>
<p>The code below illustrates the use of GTSAM. First we create a <code class="docutils literal notranslate"><span class="pre">Variables</span></code> data structure that will be used to obtain more informative output from other code below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">VARIABLES</span> <span class="o">=</span> <span class="n">Variables</span><span class="p">()</span>
<span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cardboard&quot;</span><span class="p">,</span> <span class="s2">&quot;paper&quot;</span><span class="p">,</span> <span class="s2">&quot;can&quot;</span><span class="p">,</span> <span class="s2">&quot;scrap metal&quot;</span><span class="p">,</span> <span class="s2">&quot;bottle&quot;</span><span class="p">]</span>
<span class="n">Category</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete</span><span class="p">(</span><span class="s2">&quot;Category&quot;</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Conceptually, the <code class="docutils literal notranslate"><span class="pre">Variables</span></code> class keeps track of the names of variables and what values each variable can take on. For example in the above, we need the variable <code class="docutils literal notranslate"><span class="pre">Category</span></code>, and it can take on the values <code class="docutils literal notranslate"><span class="pre">cardboard</span></code>, <code class="docutils literal notranslate"><span class="pre">paper</span></code>, <code class="docutils literal notranslate"><span class="pre">can</span></code>, <code class="docutils literal notranslate"><span class="pre">scrap</span> <span class="pre">metal</span></code>, and <code class="docutils literal notranslate"><span class="pre">bottle</span></code>. We do this so that later when we print, it can show us a nicely rendered outputs.</p>
<p>We can now create a prior probability distribution <span class="math notranslate nohighlight">\(P(Category)\)</span> on the category using a <code class="docutils literal notranslate"><span class="pre">DiscreteDistribution</span></code> constructor:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">category_prior</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">Category</span><span class="p">,</span> <span class="s2">&quot;200/300/250/200/50&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The constructor automatically normalizes the numbers given to it to a proper probability distribution, i.e., it makes the probabilities sum to one. It is rendered in notebook as a table below, where we can verify this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pretty</span><span class="p">(</span><span class="n">category_prior</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(Category):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>Category</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>cardboard</th><td>0.2</td></tr>
    <tr><th>paper</th><td>0.3</td></tr>
    <tr><th>can</th><td>0.25</td></tr>
    <tr><th>scrap metal</th><td>0.2</td></tr>
    <tr><th>bottle</th><td>0.05</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can evaluate the prior for any category value, e.g., “can”, but that function takes integer indices, not srings. Hence, we use the built-in python function <code class="docutils literal notranslate"><span class="pre">index</span></code> to obtain that integer (2 in this case):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">categories</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;can&#39;</span><span class="p">)</span>  <span class="c1"># we still have to use an integer value</span>
<span class="n">P_can</span> <span class="o">=</span> <span class="n">category_prior</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(&#39;can&#39;) = </span><span class="si">{</span><span class="n">P_can</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P(&#39;can&#39;) = 0.25
</pre></div>
</div>
</div>
</div>
<p>We can also recover all values in the probability distribution at once, using the <code class="docutils literal notranslate"><span class="pre">pmf</span></code> method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PMF</span> <span class="o">=</span> <span class="n">category_prior</span><span class="o">.</span><span class="n">pmf</span><span class="p">()</span>
<span class="n">PMF</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.2, 0.3, 0.25, 0.2, 0.05]
</pre></div>
</div>
</div>
</div>
<p id="index-8">Here “PMF” is short for “probability mass function”, which we define more precisely in Section 2.2. Note that the ordering of the array was fixed when we defined <code class="docutils literal notranslate"><span class="pre">categories</span></code> above.  It is the programmer’s responsibility
to maintain consistency when using arrays to store values associated to a collection of variables.</p>
<p>We can display probability distributions in various ways, including as a bar graph, as shown in Figure <a class="reference internal" href="#fig:discrete-distribution"><span class="xref myst">2.1</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A discrete probability distribution as a bar graph.</span>
<span class="c1">#| label: fig:discrete-distribution</span>
<span class="n">px</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">PMF</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/db17d39d22046e863dc1a082668bfb91b971bcc53234fb00b4a15b25270e668e.png" src="_images/db17d39d22046e863dc1a082668bfb91b971bcc53234fb00b4a15b25270e668e.png" />
</div>
</div>
</section>
<section id="simulation-by-sampling">
<h2><span class="section-number">2.1.5. </span>Simulation by Sampling<a class="headerlink" href="#simulation-by-sampling" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>We can simulate our trash sorting cell by sampling from the prior.</p>
</div></blockquote>
<p id="index-9">Suppose we wish to simulate our trash sorting system such that the behavior of the simulation matches,
in some statistical sense, the behavior of the actual system.
In our case, this amounts to generating samples from the probability distribution
on trash categories.
In particular, we would like to generate a sequence of categories,
<span class="math notranslate nohighlight">\(\omega_1, \omega_2, \dots, \omega_n\)</span> such that
<span class="math notranslate nohighlight">\(\omega_i = \mathrm{cardboard}\)</span> approximately 25% of the time,
<span class="math notranslate nohighlight">\(\omega_i = \mathrm{paper}\)</span> approximately 20% of the time, etc.
How can we write a computer program to do this?</p>
<p id="index-10">While most programming libraries do not include functions to generate samples from an arbitrary distribution,
almost all include a random number generator that will generate a random number from the unit interval.
We denote by <span class="math notranslate nohighlight">\(U(a,b)\)</span> the <em>uniform probability distribution</em> on the interval <span class="math notranslate nohighlight">\([a,b]\)</span>.
In numpy, the function <code class="docutils literal notranslate"><span class="pre">np.random.rand()</span></code> generates a sample <span class="math notranslate nohighlight">\(x \sim U(0,1)\)</span>. We will often use the symbol <span class="math notranslate nohighlight">\(\sim\)</span> to indicate a variable is sampled from a given distribution.
Below we explain how we can use this to generate a sample from an arbitrary probability distribution.</p>
<section id="cumulative-distribution-function">
<h3><span class="section-number">2.1.5.1. </span>Cumulative Distribution Function<a class="headerlink" href="#cumulative-distribution-function" title="Link to this heading">#</a></h3>
<p id="index-12"><span id="index-11"></span>We begin by introducing the Cumulative Distribution Function (CDF) for a random variable <span class="math notranslate nohighlight">\(X\)</span>.
We will more carefully introduce the notion of a discrete random variable in Section 2.2, but for now it
is sufficient to know that a discrete random variable takes values from a countable set,
each of which is assigned a probability value.
For a random variable <span class="math notranslate nohighlight">\(X\)</span>, the CDF for <span class="math notranslate nohighlight">\(X\)</span> is denoted by <span class="math notranslate nohighlight">\(F_X\)</span>, and is defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-e9559db2-1cd5-49ad-b266-1464ee422f4f">
<span class="eqno">(2.4)<a class="headerlink" href="#equation-e9559db2-1cd5-49ad-b266-1464ee422f4f" title="Permalink to this equation">#</a></span>\[\begin{equation}
F_X(\alpha) = P(X \leq \alpha)
\end{equation}\]</div>
<p>It follows immediately that <span class="math notranslate nohighlight">\(0 \leq F_X(\alpha) \leq 1\)</span>,
since <span class="math notranslate nohighlight">\(F_X(\alpha)\)</span> is itself a probability.
In the case of discrete random variables,
say <span class="math notranslate nohighlight">\(X \in \{ x_0, \dots x_{n-1}\}\)</span>, we can compute the CDF
<span class="math notranslate nohighlight">\(F_X(\alpha)\)</span> by summing the probabilities assigned
to all <span class="math notranslate nohighlight">\(x_i \leq \alpha\)</span></p>
<div class="amsmath math notranslate nohighlight" id="equation-087f412e-4a84-453f-99e1-a527603fc55c">
<span class="eqno">(2.5)<a class="headerlink" href="#equation-087f412e-4a84-453f-99e1-a527603fc55c" title="Permalink to this equation">#</a></span>\[\begin{equation}
F_X(\alpha) = \sum_{x_i \leq \alpha} P(x_i) = \sum_{i=0}^{k-1} P(x_i)
\end{equation}\]</div>
<p>in which the rightmost summation follows if we choose <span class="math notranslate nohighlight">\(k\)</span> such that <span class="math notranslate nohighlight">\(x_{k-1} \leq \alpha &lt; x_k\)</span>.
The terminology <em>Cumulative Distribution Function</em> stems from the fact that <span class="math notranslate nohighlight">\(F_X(\alpha)\)</span>
is the accumulated probability assigned to all outcomes less than or equal to <span class="math notranslate nohighlight">\(\alpha\)</span>,
which is apparent in these summation expressions.</p>
<p>But what does this have to do with generating samples from our distribution on categories?
The idea is simple: we can generate <span class="math notranslate nohighlight">\(x\sim U(0,1)\)</span>, and a CDF takes on values in the
interval <span class="math notranslate nohighlight">\([0,1]\)</span>.  For a discrete random variable <span class="math notranslate nohighlight">\(X \in \{ x_0, \dots x_{n-1}\}\)</span>
the probability that our sample <span class="math notranslate nohighlight">\(x\)</span> corresponds to category <span class="math notranslate nohighlight">\(k\)</span>
is exactly equal to <span class="math notranslate nohighlight">\(F_X(x_k) - F_X(x_{k-1})\)</span>, and we define <span class="math notranslate nohighlight">\(F_X(x_k)=0\)</span> for <span class="math notranslate nohighlight">\(k &lt; 0\)</span>.</p>
<p>To see this, we impose an ordering on our categories,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
c_0 &amp;= \mathrm{cardboard} \\
c_1 &amp;= \mathrm{paper} \\
c_2 &amp;= \mathrm{can} \\
c_3 &amp;= \mathrm{scrap \; metal} \\
c_4 &amp;= \mathrm{bottle}
\end{align*}\]</div>
<p>and we define the random variable <span class="math notranslate nohighlight">\(X \in \{ 0,1,2,3,4\}\)</span> to be the index of the chosen category.
The CDF for <span class="math notranslate nohighlight">\(X\)</span> is given by:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(k\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(x_k\)</span></p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(F_X\)</span>(<span class="math notranslate nohighlight">\(x_k\)</span>)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>cardboard</p></td>
<td class="text-center"><p>0.20</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>paper</p></td>
<td class="text-center"><p>0.50</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>can</p></td>
<td class="text-center"><p>0.75</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>scrap metal</p></td>
<td class="text-center"><p>0.95</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>bottle</p></td>
<td class="text-center"><p>1.00</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="example">
<h3><span class="section-number">2.1.5.2. </span>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h3>
<p>Some numpy code to generate the CDF:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CDF</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">PMF</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">CDF</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.2  0.5  0.75 0.95 1.  ]
</pre></div>
</div>
</div>
</div>
<p>Now, suppose we generate a random sample <span class="math notranslate nohighlight">\(x \sim U(0,1)\)</span>,
and use this <span class="math notranslate nohighlight">\(x\)</span> to choose category <span class="math notranslate nohighlight">\(k\)</span> such that <span class="math notranslate nohighlight">\(F_X(x_{k-1}) &lt; x \leq F_X(x_k)\)</span>.
For example, we choose category 4 if <span class="math notranslate nohighlight">\(0.95 &lt; x \leq 1.0\)</span>.
In this case, what is the probability of choosing category 4?
The answer follows from the fact that,
for the uniform distribution on the unit interval, <span class="math notranslate nohighlight">\(P(X \in [a,b]) = b-a\)</span>.
Therefore, the probability that our sample lies in the interval <span class="math notranslate nohighlight">\([0.95,1.0]\)</span> is
<span class="math notranslate nohighlight">\(0.05\)</span>, which happens to be exactly the prior probability assigned to category 4!
Likewise, if our sample <span class="math notranslate nohighlight">\(x\)</span> satisfies <span class="math notranslate nohighlight">\(0.2 &lt; x \leq 0.5\)</span>,
we choose category 1, and the probability that our sample lies in the interval
<span class="math notranslate nohighlight">\([0.2,0.5]\)</span> is <span class="math notranslate nohighlight">\(0.3\)</span>, which is, as expected, exactly the prior probability assigned
to category 1.</p>
<p>The code to accomplish sampling is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">():</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">u</span><span class="o">&lt;</span><span class="nb">float</span><span class="p">(</span><span class="n">CDF</span><span class="p">[</span><span class="n">category</span><span class="p">]):</span>
            <span class="k">return</span> <span class="n">category</span>
</pre></div>
</div>
</div>
</div>
<p>If we simulate our system by generating a large number of samples, we expect that the frequencies of each category will approximate their prior probabilities. To see this, the code below generates a histogram for 1000 generated samples. While the histogram values do not exactly match the prior probabilities, we can see that the approximation is quite good.</p>
<p id="index-13">We can use the plotly library to plot a set of 1000 samples generated using this method, as a <em>histogram</em>. The result is shown in Figure <a class="reference internal" href="#fig:discrete-samples"><span class="xref myst">2.2</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A histogram of samples from the discrete distribution.</span>
<span class="c1">#| label: fig:discrete-samples</span>
<span class="n">px</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">sample</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f6752ee804591fbe0701734c16acacc120fb72aaac7df4155fd65968a96fc636.png" src="_images/f6752ee804591fbe0701734c16acacc120fb72aaac7df4155fd65968a96fc636.png" />
</div>
</div>
<p>Of course, GTSAM has all this machinery built-in, and Figure <a class="reference internal" href="#fig:discrete-samples-gtsam"><span class="xref myst">2.3</span></a> is generated using GTSAM’s <code class="docutils literal notranslate"><span class="pre">DiscreteDistribution.sample</span></code> method. Notice that even for a 1000 samples the histograms can look noticeably different because of the variability in sampling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: The same histogram produced by GTSAM&#39;s `DiscreteDistribution.sample` method.</span>
<span class="c1">#| label: fig:discrete-samples-gtsam</span>
<span class="n">px</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">category_prior</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3ad6258a0d093d37e5034140dd8f7b8f1ab48cea625f5567147cdcc6d3cea319.png" src="_images/3ad6258a0d093d37e5034140dd8f7b8f1ab48cea625f5567147cdcc6d3cea319.png" />
</div>
</div>
</section>
</section>
<section id="gtsam-101">
<h2><span class="section-number">2.1.6. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>The GTSAM concepts used in this section, explained.</p>
</div></blockquote>
<p>Above we created an instance of the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteDistribution</span></code> class. As with any GTSAM class, you can type</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">)</span>
</pre></div>
</div>
<p>
to get documentation on its constructors and methods. In particular, we called the constructor</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">spec</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</pre></div>
</div>
<p>
which expects two arguments (besides <code class="docutils literal notranslate"><span class="pre">self</span></code>, which you can ignore):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">key</span></code>: Many GTSAM objects take a <em>key</em> to indicate which variable is involved. In the case of a DiscreteDistribution, the key is actually a tuple of ints:</p>
<ul>
<li><p>the first int is a 64-bit identifier for the variable;</p></li>
<li><p>the second int is the <em>cardinality</em> of the variable.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">spec</span></code>: The <code class="docutils literal notranslate"><span class="pre">DiscreteDistribution</span></code> class specifies a PMF (remember: probability mass function) which is given as a string of numbers, separated by <code class="docutils literal notranslate"><span class="pre">/</span></code>.</p></li>
</ul>
<p>
Let’s look at an example below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">((</span><span class="mi">42</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;0.4/0.1/0.5&quot;</span><span class="p">)</span>
<span class="n">prior</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(42):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>42</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>0</th><td>0.4</td></tr>
    <tr><th>1</th><td>0.1</td></tr>
    <tr><th>2</th><td>0.5</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p id="index-14">As you can see, this is a PMF on the variable with id <span class="math notranslate nohighlight">\(42\)</span>, and it indeed has probabilities (that add up to one) for values <code class="docutils literal notranslate"><span class="pre">0..2</span></code>. Internally, GTSAM <em>actually</em> represents a PMF as a small <strong>decision tree</strong>, which you can reveal using <code class="docutils literal notranslate"><span class="pre">show</span></code>, as illustrated in <a class="reference internal" href="#fig:discrete-decision-tree"><span class="xref myst">Figure 2.4</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: The decision tree representation for a discrete probability distribution.</span>
<span class="c1">#| label: fig:discrete-decision-tree</span>
<span class="n">show</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/cae451834d64d502e44f69b5f7ea51b8e1f6cd8225274e053c1c518a738798ea.svg" src="_images/cae451834d64d502e44f69b5f7ea51b8e1f6cd8225274e053c1c518a738798ea.svg" />
</div>
</div>
<p>Of course, it would be much nicer if we could print out these PMFs in a more readable format, that shows us a name for each variable as well as a pretty name for each. This is where the <code class="docutils literal notranslate"><span class="pre">Variables</span></code> class comes to the rescue. We actually defined a global variable at the top of this notebook, like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">VARIABLES</span> <span class="o">=</span> <span class="n">Variables</span><span class="p">()</span>
</pre></div>
</div>
<p>
which then allows us to give a name to a variable. It will also pick a unique ID for our variable. We can do this with the <code class="docutils literal notranslate"><span class="pre">discrete</span></code> method, which takes a name and a set of value names:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete</span><span class="p">(</span><span class="s2">&quot;TresCommas&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">,</span> <span class="s2">&quot;three&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key = </span><span class="si">{</span><span class="n">T</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>key = (1, 3)
</pre></div>
</div>
</div>
</div>
<p>As you can see, the id for the variable is 1 (<code class="docutils literal notranslate"><span class="pre">Category</span></code>, defined above, took id 0), and the cardinality was inferred to be three from the length of the list given as second argument.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Variables</span></code> class can tell us about any discrete variable so defined, using the two methods <code class="docutils literal notranslate"><span class="pre">name</span></code> and <code class="docutils literal notranslate"><span class="pre">domain</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key = </span><span class="si">{</span><span class="n">T</span><span class="si">}</span><span class="s2">, name = </span><span class="si">{</span><span class="n">VARIABLES</span><span class="o">.</span><span class="n">name</span><span class="p">(</span><span class="n">T</span><span class="p">)</span><span class="si">}</span><span class="s2">, domain = </span><span class="si">{</span><span class="n">VARIABLES</span><span class="o">.</span><span class="n">domain</span><span class="p">(</span><span class="n">T</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>key = (1, 3), name = TresCommas, domain = [&#39;one&#39;, &#39;two&#39;, &#39;three&#39;]
</pre></div>
</div>
</div>
</div>
<p>Conceptually, the <code class="docutils literal notranslate"><span class="pre">Variables</span></code> class keeps track of the names of variables and what values each variable can take on. We do this so that later when we print, it can show us a beautiful outputs. Of course, this only works if we actually use the key returned to use by <code class="docutils literal notranslate"><span class="pre">Variables.discrete</span></code>. We first define a prior using a string “spec” as shown in <a class="reference internal" href="#fig:unnormalized-spec"><span class="xref myst">Figure 2.5</span></a>. This also illustrates once again that the <code class="docutils literal notranslate"><span class="pre">spec</span></code> string does not need to contain normalized probabilities. The constructor will do the normalization for us! Note that the function <code class="docutils literal notranslate"><span class="pre">pretty(*)</span></code> above is just a shortcut for <code class="docutils literal notranslate"><span class="pre">gtbook.discrete.pretty(*,</span> <span class="pre">VARIABLES)</span></code>, and is also defined alongside <code class="docutils literal notranslate"><span class="pre">VARIABLES</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Creating a `DiscreteDistribution` using an unnormalized &quot;spec&quot;.</span>
<span class="c1">#| label: fig:unnormalized-spec</span>
<span class="n">prior_on_tres_commas</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="s2">&quot;2/4/2&quot;</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">prior_on_tres_commas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(TresCommas):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>TresCommas</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>one</th><td>0.25</td></tr>
    <tr><th>two</th><td>0.5</td></tr>
    <tr><th>three</th><td>0.25</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Finally, let us also look at the other <code class="docutils literal notranslate"><span class="pre">DiscreteDistribution</span></code> methods we called above:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sample(self:</span> <span class="pre">gtsam.DiscreteConditional)</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code>: The <code class="docutils literal notranslate"><span class="pre">sample</span></code> method generates samples according to the PMF, returning the integer index of the sampled value, in <span class="math notranslate nohighlight">\(0\dots cardinality-1\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pmf(self:</span> <span class="pre">gtsam.DiscreteDistribution)</span> <span class="pre">-&gt;</span> <span class="pre">List[float]</span></code>: The <code class="docutils literal notranslate"><span class="pre">pmf</span></code> method will simply return all probability values, in order.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__call__(self:</span> <span class="pre">gtsam.DiscreteDistribution,</span> <span class="pre">arg0:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code>: The call operator: when given an integer value, will return just the one corresponding probability value.</p></li>
</ul>
<p>
We have illustrated the use of all of these in the text, already.</p>
<p>Finally, we can also inspect the value of <code class="docutils literal notranslate"><span class="pre">VARIABLES</span></code>, as it has an HTML representation. The table shown in <a class="reference internal" href="#fig:nice-Variables-value"><span class="xref myst">Figure 2.6</span></a> lists that we have defined two variables so far, <code class="docutils literal notranslate"><span class="pre">Category</span></code> and <code class="docutils literal notranslate"><span class="pre">TresCommas</span></code>, with respectively six and three possible values, enumerated in the <code class="docutils literal notranslate"><span class="pre">Domain</span></code> column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A value of the `Variables` renders to a nice HTML output.</span>
<span class="c1">#| label: fig:nice-Variables-value</span>
<span class="n">VARIABLES</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table class='Variables'>
  <thead>
    <tr><th>Variable</th><th>Domain</th></tr>
  </thead>
  <tbody>
    <tr><th>Category</th><td>cardboard, paper, can, scrap metal, bottle</td></tr>
    <tr><th>TresCommas</th><td>one, two, three</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S20_sorter_intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2. </span>A Trash Sorting Robot</p>
      </div>
    </a>
    <a class="right-next"
       href="S22_sorter_actions.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2.2. </span>Actions for Sorting Trash</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-probability-to-model-uncertainty">2.1.1. Using Probability to Model Uncertainty</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-distributions">2.1.2. Probability Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-probability-distributions">2.1.3. Prior Probability Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-distributions-in-python">2.1.4. Probability Distributions in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-by-sampling">2.1.5. Simulation by Sampling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cumulative-distribution-function">2.1.5.1. Cumulative Distribution Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">2.1.5.2. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">2.1.6. GTSAM 101</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>