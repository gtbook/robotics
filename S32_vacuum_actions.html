
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>3.2. Actions over time &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=51e3b7cf" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S32_vacuum_actions';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3.3. Dynamic Bayesian Networks" href="S33_vacuum_sensing.html" />
    <link rel="prev" title="3.1. Modeling the State of the Vacuum Cleaning Robot" href="S31_vacuum_state.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Introduction to Robotics and Perception - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_models.html">1.1. Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_reasoning.html">1.2. Reasoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_math.html">1.3. The Mathematics of Robotics</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S27_sorter_summary.html">2.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Learning to Act Optimally</a></li>
<li class="toctree-l2"><a class="reference internal" href="S37_vacuum_summary.html">3.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="S47_logistics_summary.html">4.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S57_diffdrive_summary.html">5.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S67_driving_summary.html">6.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S76_drone_learning.html">7.6. Neural Radiance Fields for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S77_drone_summary.html">7.7. Chapter Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">8. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S32_vacuum_actions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Actions over time</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-outcomes-of-actions">3.2.1. Probabilistic Outcomes of Actions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">3.2.1.1. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-sequences-of-actions">3.2.2. Understanding Sequences of Actions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#state-transition-matrices-and-the-belief-state">3.2.3. State Transition Matrices and the Belief State</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">3.2.3.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlled-markov-chains">3.2.4. Controlled Markov Chains</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.2.4.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-simulation">3.2.5. Forward Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.2.5.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-networks">3.2.6. Bayesian Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">3.2.6.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factored-state-representations">3.2.7. Factored State Representations*</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">3.2.7.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">3.2.8. GTSAM 101</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S32_vacuum_actions.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="actions-over-time">
<span id="index-0"></span><h1><span class="section-number">3.2. </span>Actions over time<a class="headerlink" href="#actions-over-time" title="Link to this heading">#</a></h1>
<blockquote>
<div><p>Using the language of probability to describe systems with uncertainty in the effects of actions.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S32-iRobot_vacuuming_robot-04.jpg"><img alt="Splash image with vacuuming robot in action" class="align-center" src="_images/S32-iRobot_vacuuming_robot-04.jpg" style="width: 40%;" /></a>
<p>In the real world, robots do not always execute actions perfectly, for a
variety of reasons.
To model the uncertainty when executing an action, we will once again use the
language of probability.
We will use <em>conditional probability distributions</em> to model how we can affect the state
of the robot by actions.
Recall that in Chapter 2 we used conditional probabilities to model
the effects of uncertainty in sensing at a specific moment in time.
Here, we use conditional probabilities to model the uncertainty in state transitions when
actions are executed.</p>
<p>We can model this using graphs, with directed edges that specify conditional
probabilities on variables.
We can use these “graphical models” to generate sample system trajectories
for a fixed sequence of actions.
Such sample trajectories can be used for planning, as we will see later in the chapter.
In addition, the graphical model approach allows us to easily extend probabilistic actions to
factored state representations, which can provide significant computational advantages.</p>
<p id="index-1">In our example, we assume that our robot is equipped with navigation software that implements four
primitive actions: <em>move left, move right, move up, move down</em>,
which we will denote by <em>L,R,U,D</em>.
Together, these four actions define the <strong>action space</strong>.
The nominal effects of these actions (i.e., the effects of the actions without taking into account uncertainty)
are to move the robot from the current room to an adjacent
room, according to the direction specified by the action.
For example, executing the <em>move down</em> action from the living room should take the robot into the hallway.</p>
<figure id="fig:Stochastic">
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/S32-Actions.png?raw=1" style="width:14cm" alt="" />
<figcaption>Our robot is equipped with
four primitive actions: Left, Right, Up, and Down.
</figcaption>
</figure>
<p>We can represent these actions graphically by making a slight modification to our state space graph
from the previous section.
Instead of using undirected edges to denote adjacency, each action contributes a directed edge, as shown in
Figure <a href="#fig:Stochastic" data-reference-type="ref" data-reference="fig:Stochastic">3.5</a>.
Note that to simplify notation  we use <em>L,R,U,D</em>
instead of <em>move left, move right, move up, move down</em> to label the edges.</p>
<section id="probabilistic-outcomes-of-actions">
<h2><span class="section-number">3.2.1. </span>Probabilistic Outcomes of Actions<a class="headerlink" href="#probabilistic-outcomes-of-actions" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Actions are uncertain.</p>
</div></blockquote>
<figure id="fig:Mud">
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/N3-Mud.png?raw=1" style="width:14cm" alt="" />
<figcaption>Mobile robot driving in mud.</figcaption>
</figure>
<p>In the real world, robots do not always execute actions perfectly, for a
variety of reasons. For example, as shown in Figure
<a href="#fig:Mud" data-reference-type="ref" data-reference="fig:Mud">3.6</a>,
a robot may want to drive forward in an outdoor environment but mud
under its wheels might prevent it from traveling as far as we would like.</p>
<figure id="fig:Pickup">
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/N3-Pick.png?raw=1" style="width:14cm" alt="" />
<figcaption>A humanoid attempting to pick up an object.</figcaption>
</figure>
<p>Or a robot with an articulated arm (Figure
<a href="#fig:Pickup" data-reference-type="ref" data-reference="fig:Pickup">3.7</a>)
might attempt to pick up an object, but fail. Some objects are easier to grasp than others, and robot grippers are not as dexterous as human hands, so this is not such a rare occurrence.</p>
<p>Similarly, in our vacuum cleaning robot example a variety of things could go wrong: a particular doorway might be blocked, the robot might get lost, or it might take an action that is simply not available in a particular room - for example executing <em>move up</em> in the office.
As a reminder, in this chapter we <em>discretize</em> time and talk about the state of the robot at discretized times <span class="math notranslate nohighlight">\(t_k\)</span>, with <span class="math notranslate nohighlight">\(k\geq1\)</span> an integer. Here we don’t care too much about the underlying times <span class="math notranslate nohighlight">\(t_k\)</span> at which the robot finishes a transition, as long as it is in a reasonable time. For example, the robot control system could time out after several unsuccessful attempts to move to a different room. That is then another way an action can fail.</p>
<p id="index-2">To model the uncertainty associated with executing an action, we will once again use the language of probability.
In particular, we will use the conditional probability <span class="math notranslate nohighlight">\(P(X_{k+1}|X_k=x,A=a)\)</span> to define
the the <strong>state transition model</strong>  model, i.e.,
the conditional probability distribution for the next state <span class="math notranslate nohighlight">\(X_{k+1}\)</span>,
given the value <span class="math notranslate nohighlight">\(x\)</span> of the current state <span class="math notranslate nohighlight">\(X_k\)</span>, and the value <span class="math notranslate nohighlight">\(a\)</span> of the action <span class="math notranslate nohighlight">\(A\)</span>.
Because the state space in this case involves navigation, we could also call the corresponding conditional distribution
<span class="math notranslate nohighlight">\(P(X_{k+1}|X_k,A)\)</span> a <strong>motion model</strong>.</p>
<p>The code below generates a motion model for moving from state <span class="math notranslate nohighlight">\(X_1\)</span> to <span class="math notranslate nohighlight">\(X_2\)</span> in the
form of a large conditional probability table. In the code, we make use of two new variables (<code class="docutils literal notranslate"><span class="pre">action_space</span></code> and <code class="docutils literal notranslate"><span class="pre">action_spec</span></code>) that were predefined for us but are repeated here in the comment for clarity. The <code class="docutils literal notranslate"><span class="pre">motion_model</span></code> is rendered as a table below the code, showing <span class="math notranslate nohighlight">\(P(X_2|X_1,A_1)\)</span> as a row for all possible <span class="math notranslate nohighlight">\((X_1,A_1)\)</span> combinations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># vacuum.action_space = [&quot;L&quot;,&quot;R&quot;,&quot;U&quot;,&quot;D&quot;,]</span>
<span class="c1"># vacuum.action_spec is a string with the transition probabilities:</span>
<span class="c1">#  &quot;1/0/0/0/0 2/8/0/0/0 1/0/0/0/0 2/0/0/8/0</span>
<span class="c1">#   8/2/0/0/0 0/1/0/0/0 0/1/0/0/0 0/2/0/0/8</span>
<span class="c1">#   0/0/1/0/0 0/0/2/8/0 0/0/1/0/0 0/0/1/0/0</span>
<span class="c1">#   0/0/8/2/0 0/0/0/2/8 8/0/0/2/0 0/0/0/1/0</span>
<span class="c1">#   0/0/0/8/2 0/0/0/0/1 0/8/0/0/2 0/0/0/0/1&quot;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span> <span class="c1"># states for times 1,2 and 3</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span> <span class="c1"># actions for times 1 and 2</span>
<span class="n">motion_model</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">motion_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(X2|X1,A1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>X1</i></th><th><i>A1</i></th><th>Living Room</th><th>Kitchen</th><th>Office</th><th>Hallway</th><th>Dining Room</th></tr>
  </thead>
  <tbody>
    <tr><th>Living Room</th><th>L</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>R</th><td>0.2</td><td>0.8</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>U</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>D</th><td>0.2</td><td>0</td><td>0</td><td>0.8</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>L</th><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>R</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>U</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>D</th><td>0</td><td>0.2</td><td>0</td><td>0</td><td>0.8</td></tr>
    <tr><th>Office</th><th>L</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Office</th><th>R</th><td>0</td><td>0</td><td>0.2</td><td>0.8</td><td>0</td></tr>
    <tr><th>Office</th><th>U</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Office</th><th>D</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Hallway</th><th>L</th><td>0</td><td>0</td><td>0.8</td><td>0.2</td><td>0</td></tr>
    <tr><th>Hallway</th><th>R</th><td>0</td><td>0</td><td>0</td><td>0.2</td><td>0.8</td></tr>
    <tr><th>Hallway</th><th>U</th><td>0.8</td><td>0</td><td>0</td><td>0.2</td><td>0</td></tr>
    <tr><th>Hallway</th><th>D</th><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
    <tr><th>Dining Room</th><th>L</th><td>0</td><td>0</td><td>0</td><td>0.8</td><td>0.2</td></tr>
    <tr><th>Dining Room</th><th>R</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>Dining Room</th><th>U</th><td>0</td><td>0.8</td><td>0</td><td>0</td><td>0.2</td></tr>
    <tr><th>Dining Room</th><th>D</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is of course rather tedious to specify this table by hand.
In this case, for each of the four actions, we must compute a transition probability from
each of the five possible starting rooms to each of the five possible destination rooms:
<span class="math notranslate nohighlight">\(4*5*5=100\)</span> entries.
In the example above, impossible transitions (e.g., moving up from the living room to any other room)
are assigned zero probability.
Other actions are assumed to have 80% chance of success (e.g., moving right from the living room
and arriving to the kitchen is assigned a transition probability of <span class="math notranslate nohighlight">\(0.8\)</span>).</p>
<p>Conditional probability distributions do not <em>have</em> to be specified as giant
tables. Because the state space is potentially quite large, such a
motion model is almost never explicitly specified, but
rather exploits the semantics of the states and actions to calculate the conditional distribution at run-time.
For example, rather than enumerate every possible action from every possible room, we might
determine the probability of successfully moving to an adjacent room is <span class="math notranslate nohighlight">\(0.8\)</span>, for all
rooms and for all actions, and that the probability of failing to do so is <span class="math notranslate nohighlight">\(0.2\)</span>.
If we apply this rule to each combination of action and adjacent rooms, we can
construct specific rows the table above on an as-needed basis.</p>
<section id="exercises">
<h3><span class="section-number">3.2.1.1. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Even though the CPT above
has 100 numbers in it, how many <em>independent</em> numbers do we
actually have when specifying this CPT?</p></li>
<li><p>Specify a <em>parametric</em> conditional density for the action models for
the vacuuming robot that is somewhat realistic, yet not completely
deterministic.</p></li>
<li><p>It is possible to create models that do not reflect everyday
physics. For example, how could we model the game “Portal”?</p></li>
</ol>
</section>
</section>
<section id="understanding-sequences-of-actions">
<span id="index-3"></span><h2><span class="section-number">3.2.2. </span>Understanding Sequences of Actions<a class="headerlink" href="#understanding-sequences-of-actions" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>From one to many actions.</p>
</div></blockquote>
<p>How do we use the above to predict what happens when taking <em>multiple</em> actions?
Formally, assume we apply a sequence of actions <span class="math notranslate nohighlight">\(a_1 \dots a_k\)</span>, and we wish to compute the probability distribution associated with the resulting state <span class="math notranslate nohighlight">\(X_{k+1}\)</span>.
Below we accomplish this by applying the law of total probability.</p>
<p>The <strong>law of total probability</strong> provides a convenient way to compute the probability of an
event by considering all of the different ways the event could occur. Suppose
we have a set of events <span class="math notranslate nohighlight">\({\cal B} = \{B_1, \dots , B_n\}\)</span> such that <span class="math notranslate nohighlight">\(B_i \cap B_j = \emptyset\)</span> when <span class="math notranslate nohighlight">\(i \neq j\)</span>
and with <span class="math notranslate nohighlight">\(\cup B_i = \Omega\)</span>, i.e., the set of events <span class="math notranslate nohighlight">\({\cal B}\)</span> form a partition of the sample space.
To compute the probability of an event <span class="math notranslate nohighlight">\(A\)</span>, the law of total probability is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-74bbb5b1-1fa4-4aa7-ab0c-20eda0379b50">
<span class="eqno">(3.1)<a class="headerlink" href="#equation-74bbb5b1-1fa4-4aa7-ab0c-20eda0379b50" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(A) = \sum_{i} P(A | B_i ) P(B_i)
\end{equation}\]</div>
<p>We merely sum the conditional probabilities <span class="math notranslate nohighlight">\(P(A | B_i)\)</span> for each event <span class="math notranslate nohighlight">\(B_i\)</span>, weighted by the probability
of the event <span class="math notranslate nohighlight">\(B_i\)</span>.</p>
<p>We can use the law of total probability to compute the probability that the robot
is in state <span class="math notranslate nohighlight">\(x_{k+1}\)</span> at time step <span class="math notranslate nohighlight">\(k+1\)</span> by conditioning on the possible states for time step <span class="math notranslate nohighlight">\(k\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-ce3fc9d2-cbaf-4b10-9c86-465999353ea2">
<span class="eqno">(3.2)<a class="headerlink" href="#equation-ce3fc9d2-cbaf-4b10-9c86-465999353ea2" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X_{k+1} = x_{k+1}) = \sum_{x_k} P(X_{k+1} = x_{k+1}| X_k = x_k) P(X_k = x_k).
\end{equation}\]</div>
<p>Now, condition every term in the above equation on the sequence of actions
<span class="math notranslate nohighlight">\(a_1 \dots a_k\)</span>, and we obtain</p>
<div class="amsmath math notranslate nohighlight" id="equation-b9c96ed8-7832-4992-bf8a-15dc60a186ce">
<span class="eqno">(3.3)<a class="headerlink" href="#equation-b9c96ed8-7832-4992-bf8a-15dc60a186ce" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X_{k+1} | a_1 \dots a_k) = \sum_{x_k} P(X_{k+1} | X_k, a_1 \dots a_k) P(X_k|a_1 \dots a_k),
\end{equation}\]</div>
<p>where, for brevity’s sake, we omit the explicit assignment of values to <span class="math notranslate nohighlight">\(X_k\)</span> and <span class="math notranslate nohighlight">\(X_{k+1}\)</span>.</p>
<p id="index-4">This expression may seem complex, but it can be simplified by making the following observation:
<em>If we know that the robot is in a specific state <span class="math notranslate nohighlight">\(x_k\)</span> at time step <span class="math notranslate nohighlight">\(k\)</span>, then the next state will depend only
on the action executed at time step <span class="math notranslate nohighlight">\(k\)</span>; the previously executed actions will not affect our belief
about <span class="math notranslate nohighlight">\(X_{k+1}\)</span></em>.
For example, if the robot executes the action <em>move down</em> knowing with certainty that it is in the living room at time step <span class="math notranslate nohighlight">\(k\)</span>,
the sequence of actions that brought the robot to the living room (i.e., actions <span class="math notranslate nohighlight">\(a_1 \dots a_{k-1}\)</span>) does not affect our belief
about whether the robot will arrive to the hallway.
Mathematically, we can write this relationship as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8362be23-0aee-471c-a5cd-b71c048b31d4">
<span class="eqno">(3.4)<a class="headerlink" href="#equation-8362be23-0aee-471c-a5cd-b71c048b31d4" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X_{k+1} | X_k, a_1 \dots a_k) =  P(X_{k+1} | X_k,  a_k)
\end{equation}\]</div>
<p>We can also  simplify the term <span class="math notranslate nohighlight">\(P(X_k |a_1 \dots a_k)\)</span>.
Notice that the action performed at time step <span class="math notranslate nohighlight">\(k\)</span> has no affect on the state at time step <span class="math notranslate nohighlight">\(k\)</span>.
For example, if the robot executes the <em>move down</em> action
in the living room at time step <span class="math notranslate nohighlight">\(k\)</span>, this actions does not change the fact that the robot was in the living room
at time <em>t</em>.
Therefore, we have</p>
<div class="amsmath math notranslate nohighlight" id="equation-1954974a-04b6-428e-b104-f344f0974d91">
<span class="eqno">(3.5)<a class="headerlink" href="#equation-1954974a-04b6-428e-b104-f344f0974d91" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X_k |a_1 \dots a_k) =  P(X_k |a_1 \dots a_{k-1})
\end{equation}\]</div>
<p>Applying these two simplifications, we obtain the final form for the desired probability distribution <span class="math notranslate nohighlight">\(P(X_{k+1} | a_1 \dots a_k)\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b4ba5b69-46d9-4c95-8af9-f8081f55a935">
<span class="eqno">(3.6)<a class="headerlink" href="#equation-b4ba5b69-46d9-4c95-8af9-f8081f55a935" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X_{k+1} | a_1 \dots a_k) = \sum_{x_k} P(X_{k+1} | X_k, a_k) P(X_k |a_1 \dots a_{k-1})
\end{equation}\]</div>
<p>We can think of the terms in this expression as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(X_k |a_1 \dots a_{k-1})\)</span> is the prior over the current state <span class="math notranslate nohighlight">\(X_k\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_{k+1} | X_k, a_k)\)</span> is the motion model;</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_{k+1} | a_1 \dots a_k)\)</span> is the <strong>posterior</strong> over the next state <span class="math notranslate nohighlight">\(X_{k+1}\)</span>.</p></li>
</ul>
<p>For the initial state, no actions have yet been applied, and the prior is merely
the prior <span class="math notranslate nohighlight">\(P(X_1)\)</span> over the initial state <span class="math notranslate nohighlight">\(X_1\)</span>.
And then the posterior at time step <span class="math notranslate nohighlight">\(k=2\)</span> can be computed as</p>
<div class="amsmath math notranslate nohighlight" id="equation-2cd85171-ae7f-48c7-98ce-78e7cfab1c0d">
<span class="eqno">(3.7)<a class="headerlink" href="#equation-2cd85171-ae7f-48c7-98ce-78e7cfab1c0d" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X_{2}| a_1) = \sum_{x_1} P(X_{2} | X_1, a_1) P(X_1).
\end{equation}\]</div>
<p>This posterior <span class="math notranslate nohighlight">\(P(X_{2}| a_1)\)</span> then becomes the prior in the next step, and so forth… This is one example of computing probability distributions recursively, a scheme which we will encounter many times more.</p>
</section>
<section id="state-transition-matrices-and-the-belief-state">
<span id="index-5"></span><h2><span class="section-number">3.2.3. </span>State Transition Matrices and the Belief State<a class="headerlink" href="#state-transition-matrices-and-the-belief-state" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>It’s an elementary matrix multiply, my dear Watson.</p>
</div></blockquote>
<p>In order to specify the complete posterior distribution at time step <span class="math notranslate nohighlight">\(k+1\)</span>, we would need to perform the calculation above five times, once for each of the possible next states (<span class="math notranslate nohighlight">\(L,K,O,H,D\)</span>), i.e., all the rooms in the house we could end up in after taking the action sequence.
This complete distribution is called the <strong>belief state</strong> <span class="math notranslate nohighlight">\(b_{k+1}\)</span>, defined as the <em>row vector</em></p>
<div class="amsmath math notranslate nohighlight" id="equation-fb7e6bce-74b2-425d-aa40-80ee7cd25fa2">
<span class="eqno">(3.8)<a class="headerlink" href="#equation-fb7e6bce-74b2-425d-aa40-80ee7cd25fa2" title="Permalink to this equation">#</a></span>\[\begin{equation}
b_{k+1} = \begin{bmatrix}
P(X_{k+1} = L | a_{1:k})\\
P(X_{k+1} = K | a_{1:k})\\
P(X_{k+1} = O | a_{1:k})\\
P(X_{k+1} = H | a_{1:k})\\
P(X_{k+1} = D | a_{1:k})
\end{bmatrix}^T
\end{equation}\]</div>
<p>in which we have simplified notation by using the notation
<span class="math notranslate nohighlight">\(a_{1:k} \doteq a_1, \dots, a_k\)</span>.</p>
<p>We can write the equations for the belief state in a compact form by writing the conditional probability tables as
transition matrices.
To do so, for each action, we merely gather the corresponding rows from the complete conditional probability
table into a state transition matrix.
For the action <em>move right</em>, this is illustrated below in
Figure <a href="#fig:TM" data-reference-type="ref" data-reference="fig:TM">4</a>.</p>
<figure id="fig:TM">
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/S32-transition-matrix.png?raw=1" style="width:20cm" alt="" />
<figcaption>The transition matrix for the action *move right*.
</figcaption>
</figure>
<p>If we apply the action <em>move right</em> to the initial state, by straightforward calculations, we can see that <span class="math notranslate nohighlight">\(b_2 = b_1 M_r\)</span>, i.e., a simple vector-matrix multiply.
This can be generalized to a sequence of actions.
If we execute action <span class="math notranslate nohighlight">\({\cal A}_k\)</span> at time step <span class="math notranslate nohighlight">\(k\)</span>,
the belief state <span class="math notranslate nohighlight">\(b_{k+1}\)</span> is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-19ed1d12-06a5-41ec-bf10-33ba542c706a">
<span class="eqno">(3.9)<a class="headerlink" href="#equation-19ed1d12-06a5-41ec-bf10-33ba542c706a" title="Permalink to this equation">#</a></span>\[\begin{equation}
b_{k+1} = b_k M_{{\cal A}_k}.
\end{equation}\]</div>
<p>Above <span class="math notranslate nohighlight">\(M_{\cal A}\)</span> is the conditional probability matrix for action <span class="math notranslate nohighlight">\(\cal A\)</span> and <span class="math notranslate nohighlight">\(b_k\)</span> is the belief state at time step <span class="math notranslate nohighlight">\(k\)</span>.
We refer to this equation as a <em>belief transition function</em> – given the
belief at time step <span class="math notranslate nohighlight">\(k\)</span> and the action <span class="math notranslate nohighlight">\(a_k\)</span>, it can be applied to compute the belief at time step <span class="math notranslate nohighlight">\(k+1\)</span>.
This result can be applied recursively to yield</p>
<div class="amsmath math notranslate nohighlight" id="equation-630ae69b-1226-4d52-b10c-d88846545861">
<span class="eqno">(3.10)<a class="headerlink" href="#equation-630ae69b-1226-4d52-b10c-d88846545861" title="Permalink to this equation">#</a></span>\[\begin{equation}
b_{k+1} = b_1 M_{{\cal A}_1} \dots M_{{\cal A}_k}
\end{equation}\]</div>
<section id="exercise">
<h3><span class="section-number">3.2.3.1. </span>Exercise<a class="headerlink" href="#exercise" title="Link to this heading">#</a></h3>
<p>Implement the above in python and observe how the belief state evolves from various initial belief states.</p>
</section>
</section>
<section id="controlled-markov-chains">
<h2><span class="section-number">3.2.4. </span>Controlled Markov Chains<a class="headerlink" href="#controlled-markov-chains" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Markov chains are everywhere. Actions control them.</p>
</div></blockquote>
<p id="index-6">In the derivation above of the belief transition function we employed a temporal decoupling property,
namely, given the state at time step <span class="math notranslate nohighlight">\(k\)</span>, all actions that were applied prior to time step <span class="math notranslate nohighlight">\(k\)</span> were irrelevant
to determining the belief state <span class="math notranslate nohighlight">\(b_{k+1}\)</span>.
This is an example of what is called the <strong>Markov property</strong>.
Variations of this property
are essential for reducing the amount of computation required to reason probabilistically over long periods of time.</p>
<p>The most common example of this property arises in systems that are called Markov chains.
In its simplest form, a <strong>Markov chain</strong> is a sequence of random variables, <span class="math notranslate nohighlight">\(X_1, X_2, \dots \)</span>
for which, for every <span class="math notranslate nohighlight">\(k\)</span>, we have</p>
<div class="amsmath math notranslate nohighlight" id="equation-914aa202-9385-46be-9400-f4403607395b">
<span class="eqno">(3.11)<a class="headerlink" href="#equation-914aa202-9385-46be-9400-f4403607395b" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X_{k+1} | X_1 \dots X_k) = P(X_{k+1} | X_k).
\end{equation}\]</div>
<p>For Markov chains, knowledge of <span class="math notranslate nohighlight">\(X_k\)</span> completely decouples the past (i.e., <span class="math notranslate nohighlight">\(X_1 \dots X_{k-1}\)</span>) from the future (i.e., <span class="math notranslate nohighlight">\(X_{k+1}\)</span>).
Therefore, when reasoning about future states, we need not perform computations over the entire history of the system: if we know <span class="math notranslate nohighlight">\(X_k\)</span>, we need only perform computations related to the present when reasoning about the future.</p>
<p>Markov chains have a nice graphical representation.
Each node corresponds to a random variable,
and directed edges specify conditional probabilities.
As an application, we can use this simple graphical model to represent
the probabilistic transitions between states, and in fact it can be generated in code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span> <span class="c1"># states for times 1...N</span>
<span class="n">markov_chain</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">markov_chain</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">markov_chain</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="s2">&quot;6/1/1/1/1 1/6/1/1/1 1/1/6/1/1 1/1/6/1/1 1/1/1/1/6&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A simple three state Markov chain.</span>
<span class="c1">#| label: fig:markov_chain_3</span>
<span class="n">show</span><span class="p">(</span><span class="n">markov_chain</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/758fd162014956ff470c2cfa1ed7da472e0ec1d2666c9135bc022f71f572c586.svg" src="_images/758fd162014956ff470c2cfa1ed7da472e0ec1d2666c9135bc022f71f572c586.svg" />
</div>
</div>
<p>Each node in this graph denotes a random variable, and therefore each node has an associated probability distribution.
If we know the distribution for the initial state <span class="math notranslate nohighlight">\(X_1\)</span>, we can recursively compute the distributions for the states <span class="math notranslate nohighlight">\(X_k\)</span> for all <span class="math notranslate nohighlight">\(k &gt; 1\)</span>, by evaluating the conditional distributions associated to the directed edges in the graph.</p>
<p id="index-7">Our robot vacuum cleaner is slightly more sophisticated than this simple Markov chain, since
the robot has the ability to execute actions, and these actions affect the propagation
of probabilities through the chain.
This type of system is called a <strong>controlled Markov chain</strong>, since it incorporates
a control input (the actions) into the usual Markov chain.</p>
<p>Graphically, we can represent such a system by augmenting the graph above to include nodes that denote actions.
We use a <em>box</em> to denote nodes whose values are known.
Since the robot knows which actions it executes, action nodes are denoted by boxes.
For our vacuuming robot, we also know the value of the initial state,
since the robot always begins in the office.
Therefore, we also use a box to denote the initial state in this graph.</p>
<p>As an example, the code below builds the controlled Markov chain for a single step of our system, i.e., up to time step <span class="math notranslate nohighlight">\(k=2\)</span>.
By applying the belief transition equation above, we can compute the posterior probability <span class="math notranslate nohighlight">\(P(X_2|a_1)\)</span> over <span class="math notranslate nohighlight">\(X_2\)</span>,
since the action <span class="math notranslate nohighlight">\(a_1\)</span> and the initial state <span class="math notranslate nohighlight">\(x_1\)</span> are both completely known.
The code below builds the graphical model, and then we do the computation below that. Note that the variable <code class="docutils literal notranslate"><span class="pre">motion_model</span></code> was defined early on in this section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">action_prior</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1/1/1/1&quot;</span><span class="p">)</span>
<span class="n">fragment</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">fragment</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">motion_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A Bayes net fragment modeling the effect of an action on the state.</span>
<span class="c1">#| label: fig:bayes_net_fragment</span>
<span class="n">show</span><span class="p">(</span><span class="n">fragment</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/dedc2197b32ad0ea9c92a8418bc034945474d253780a275af12f8b9977ca9755.svg" src="_images/dedc2197b32ad0ea9c92a8418bc034945474d253780a275af12f8b9977ca9755.svg" />
</div>
</div>
<p>Given values for the parent variables <span class="math notranslate nohighlight">\(A_1\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span>, we can examine the corresponding transition probability. For example, if we start from the <span class="math notranslate nohighlight">\(x_1=\text{Office}\)</span> and attempt to go right, i.e., action <span class="math notranslate nohighlight">\(a_1=\text{R}\)</span>, we can obtain the probability over the next state <span class="math notranslate nohighlight">\(X_2\)</span>, showing that we move to the hallway with 80% probability, and stay in the office with 20% probability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="s2">&quot;Office&quot;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="s2">&quot;R&quot;</span><span class="p">})</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">motion_model</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(X2):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>X2</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>Living Room</th><td>0</td></tr>
    <tr><th>Kitchen</th><td>0</td></tr>
    <tr><th>Office</th><td>0.2</td></tr>
    <tr><th>Hallway</th><td>0.8</td></tr>
    <tr><th>Dining Room</th><td>0</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>This idea can be extended to arbitrarily many actions by merely adding action and state nodes for each
time step <span class="math notranslate nohighlight">\(k\)</span>. The code below creates a controlled Markov chain with three states.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span> <span class="c1"># actions for times 1...N-1</span>
<span class="n">bayesNet</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">bayesNet</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">bayesNet</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span> <span class="c1"># add creates conditional and adds</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: Concatenating Bayes net fragments into a controlled Markov chain.</span>
<span class="c1">#| label: fig:controlled_markov_chain</span>
<span class="n">show</span><span class="p">(</span><span class="n">bayesNet</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d052cf2d6bf6a6ad0343b0df9d95f3c1ada597ded27bbd3f201888852b62dc67.svg" src="_images/d052cf2d6bf6a6ad0343b0df9d95f3c1ada597ded27bbd3f201888852b62dc67.svg" />
</div>
</div>
<p>The above just shows the graphical model as produced by the code fragment above. It is not yet obvious how to obtain the posterior over <span class="math notranslate nohighlight">\(X_3\)</span> in this two-step example: we explore that below.</p>
<section id="id1">
<h3><span class="section-number">3.2.4.1. </span>Exercise<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>Try varying the value of <span class="math notranslate nohighlight">\(N\)</span> to see other examples.</p>
</section>
</section>
<section id="forward-simulation">
<h2><span class="section-number">3.2.5. </span>Forward Simulation<a class="headerlink" href="#forward-simulation" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Sampling from Markov chains.</p>
</div></blockquote>
<p>We can use simulation in a graphical model to explore what a sequence of
actions might yield as an outcome.
Because the (controlled) Markov chains above are specified in as a set of conditional distributions, and we have already seen how to sample from those, we just need to know in what order to sample them.
Indeed: to sample from a conditional distribution <span class="math notranslate nohighlight">\(p(X|Y)\)</span> we need to make
sure we sample the variable <span class="math notranslate nohighlight">\(Y\)</span> <em>beforehand</em>, and then proceed simply by
selecting the appropriate PMF (probability mass function) depending on the value of <span class="math notranslate nohighlight">\(Y\)</span>. We can then
proceed as before using the inverse transform sampling method.</p>
<p>Forward sampling in a Markov chain simply repeats these steps in
succession, proceeding from left to right, because that ensures that we always have the condition before we attempt sampling from the conditional.
Simulating a robot <em>given</em> an initial state <span class="math notranslate nohighlight">\(X_1\)</span> and
sequence of actions <span class="math notranslate nohighlight">\(a_{1}, a_{2},\ldots\)</span> is then equivalent to sampling
from this Markov chain:</p>
<ol class="arabic">
<li><p>Set <span class="math notranslate nohighlight">\(k=1\)</span>, and we assume <span class="math notranslate nohighlight">\(X_1\)</span> is known.</p></li>
<li><p>Simulate the effect of the next action <span class="math notranslate nohighlight">\(A_k\)</span> by sampling the next state
<span class="math notranslate nohighlight">\(x_{k+1}\)</span> from</p>
<div class="amsmath math notranslate nohighlight" id="equation-f2e6f873-1ae2-4a30-ba81-be84223f7a2f">
<span class="eqno">(3.12)<a class="headerlink" href="#equation-f2e6f873-1ae2-4a30-ba81-be84223f7a2f" title="Permalink to this equation">#</a></span>\[\begin{equation}
x_{x+1} \sim P(X_{k+1}|X_k=x_k,A_k=a_k).
\end{equation}\]</div>
</li>
<li><p>Increment <span class="math notranslate nohighlight">\(k\)</span> and return to step <span class="math notranslate nohighlight">\(2\)</span>.</p></li>
</ol>
<p id="index-8">Below we show how to code this up and show  4 different <strong>rollouts</strong> by simulating in this way.
Rollouts will be discussed in more detail in Section 3.5.
After that, we can approximate the PMF of the final state by constructing a
histogram over the possible values of the state:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">):</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">x1</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">a1</span><span class="p">})</span>  <span class="c1"># initial state and action</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">[</span><span class="n">bayesNet</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">values</span><span class="p">)]</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">x2</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">a2</span><span class="p">})</span>  <span class="c1"># next state and action</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">[</span><span class="n">bayesNet</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">values</span><span class="p">)]</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">]</span>


<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;Office&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">,</span> <span class="s2">&quot;U&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Office&#39;, &#39;Office&#39;, &#39;Office&#39;]
[&#39;Office&#39;, &#39;Hallway&#39;, &#39;Hallway&#39;]
[&#39;Office&#39;, &#39;Hallway&#39;, &#39;Living Room&#39;]
[&#39;Office&#39;, &#39;Office&#39;, &#39;Office&#39;]
</pre></div>
</div>
</div>
</div>
<p>While simple, simulating from a forward model is a rather important
technique, and underlies some of the recent successes in deep
reinforcement learning, as well as the success of DeepMind in beating
the world’s best players of the game of Go.</p>
<section id="id2">
<h3><span class="section-number">3.2.5.1. </span>Exercise<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>Generalize the above forward sampling algorithm to an arbitrary number of actions. Hint: you will have to make sure the variables are defined, and the graphical model is extended properly.</p>
</section>
</section>
<section id="bayesian-networks">
<span id="index-9"></span><h2><span class="section-number">3.2.6. </span>Bayesian Networks<a class="headerlink" href="#bayesian-networks" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Bayes nets provide a graphical language to string together conditional probabilities into a generative world model.</p>
</div></blockquote>
<p>A Markov chain is a special case of the more general <strong>Bayesian network</strong> or <strong>Bayes net</strong>.
A Bayes net is a directed <em>acyclic</em> graph (DAG) describing a factored
probability distribution over a set of random variables.
By the term <em>factored probability distribution</em>, we mean that the
probability distribution is expressed as a product of factors,
which in Bayes nets are always conditional distributions.</p>
<p>The following code creates a Bayes net using GTSAM, which we can then display. We formally define Bayes nets below that.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wxyz</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;W&quot;</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">Z1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="p">[</span><span class="n">X1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="p">[</span><span class="n">Y1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="p">[</span><span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="s2">&quot;1/1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A general Bayes net on four discrete variables.</span>
<span class="c1">#| label: fig:general_bayes_net</span>
<span class="n">show</span><span class="p">(</span><span class="n">wxyz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/70c8f84887a16f552ce775fcda7252899abd1497cbdf544b89c004ad727afc35.svg" src="_images/70c8f84887a16f552ce775fcda7252899abd1497cbdf544b89c004ad727afc35.svg" />
</div>
</div>
<p>The example Bayes net we created is shown in Figure <a href="#fig:general_bayes_net" data-reference-type="ref" data-reference="fig:general_bayes_net">5</a>,
and it is simply a graphical representation of which random variables’s
CPT (conditional probability table) depend on which other variables. Formally, in Bayes nets the joint probability distribution <span class="math notranslate nohighlight">\(P(X_1, \dots , X_n)\)</span> over a set
of random variables, <span class="math notranslate nohighlight">\(X_1, \dots, X_n\)</span> can be computed as the product of
<span class="math notranslate nohighlight">\(n\)</span> conditional probabilities associated with each of the individual variables <span class="math notranslate nohighlight">\(X_i\)</span>
as</p>
<div class="amsmath math notranslate nohighlight" id="equation-867d2246-a18f-46cc-a6d1-d856f336aa3d">
<span class="eqno">(3.13)<a class="headerlink" href="#equation-867d2246-a18f-46cc-a6d1-d856f336aa3d" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X_1, \dots , X_n)=\prod_{i=1}^{n}P(X_{i}|\Pi_{i})
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the number
of variables, and <span class="math notranslate nohighlight">\(\Pi_{i}\)</span> denotes the set of parents for variable
<span class="math notranslate nohighlight">\(X_{i}\)</span> in the directed graph.
In the example the joint distribution can then be read off as</p>
<div class="amsmath math notranslate nohighlight" id="equation-b991b3d9-264f-42a6-8c84-47cf357bac68">
<span class="eqno">(3.14)<a class="headerlink" href="#equation-b991b3d9-264f-42a6-8c84-47cf357bac68" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(W,X,Y,Z)=P(W|X,Z)P(X|Y,Z)P(Y|Z)P(Z).
\end{equation}\]</div>
<p>Note that the order in which
we multiply the conditionals does not matter, but we typically prefer to put the parents more towards the right, as above.
Finally, note that the above graph has cycles, but the cycles are only in the underlying <em>undirected</em> graph, not in the directed graph. Directed cycles, i.e. cycles with a consistent direction, are not allowed.</p>
<p>Bayes nets can be very efficient representations of complex
probability distributions, as they encode the dependence and especially
independence relationships between the variables.
The Bayes net above was created assuming binary variables, and hence did not take
a lot of effort to specify, but as we saw above, even for relatively small state spaces
the complexity of specifying CPTs can be daunting.</p>
<p>If we were to construct a full table of probabilities for each possible
outcome of the variables <span class="math notranslate nohighlight">\(W\)</span>, <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span>, the table could be quite long.
For example, if we assume they all have 10 possible values,
then the table required to represent the full joint distribution will have <span class="math notranslate nohighlight">\(10^{4}\)</span> entries,
i.e., <span class="math notranslate nohighlight">\(10,000\)</span> unique values. You
can save a tiny bit, because they have to sum up to 1, so strictly
speaking we need only <span class="math notranslate nohighlight">\(9,999\)</span> values. In contrast, we can tally how many
entries all four CPT tables have for the Bayes net above.
This is shown in the following table.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>CPT</p></th>
<th class="head"><p># entries</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><em>P(Z)</em></p></td>
<td><p>9</p></td>
</tr>
<tr class="row-odd"><td><p><em>P(Y|Z)</em></p></td>
<td><p>90</p></td>
</tr>
<tr class="row-even"><td><p><em>P(X|Y,Z)</em></p></td>
<td><p>900</p></td>
</tr>
<tr class="row-odd"><td><p><em>P(W|X,Z)</em></p></td>
<td><p>900</p></td>
</tr>
</tbody>
</table>
</div>
<p>For example, <span class="math notranslate nohighlight">\(P(X|Y,Z)\)</span> has 900 entries, i.e., 9
(independent) entries for each of 100 possible combinations of <span class="math notranslate nohighlight">\(Y\)</span> and
<span class="math notranslate nohighlight">\(Z\)</span>. Hence, the total number of parameters we need is only <span class="math notranslate nohighlight">\(1,899\)</span>,
which is significantly less than <span class="math notranslate nohighlight">\(9,999\)</span>.</p>
<section id="id3">
<h3><span class="section-number">3.2.6.1. </span>Exercise<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>What are the savings for the binary version of the graph that we created? You’ll find it is much less, of course.</p>
</section>
</section>
<section id="factored-state-representations">
<h2><span class="section-number">3.2.7. </span>Factored State Representations*<a class="headerlink" href="#factored-state-representations" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>We can save even more by factoring the state.</p>
</div></blockquote>
<p>Factored state representations are useful if the state of the robot can
be described using features that are relatively independent of each
other. Continuing our example, the robot vacuum cleaner might also run
out of battery power, so we could associate a different variable with
its battery status, e.g., <code class="docutils literal notranslate"><span class="pre">empty</span></code>, <code class="docutils literal notranslate"><span class="pre">half</span></code>, or <code class="docutils literal notranslate"><span class="pre">full</span></code>.
The state of the robot would then be specified by the combination of
two variables: the room the robot is in, and its battery status.
Note that now the total number of possible states
is combinatorial: if there are five rooms and three different battery
levels, we have a total of 15 possible states for the robot.</p>
<p>A possible model for battery life could be the following transition table, which is independent of which action was taken, and will always progress from <code class="docutils literal notranslate"><span class="pre">full</span></code> to <code class="docutils literal notranslate"><span class="pre">half</span></code>, then from <code class="docutils literal notranslate"><span class="pre">half</span></code> to <code class="docutils literal notranslate"><span class="pre">empty</span></code>, and of course once the battery is empty it will stay empty:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">battery_states</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;full&quot;</span><span class="p">,</span> <span class="s2">&quot;half&quot;</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">battery_states</span><span class="p">)</span>
<span class="n">spec_b</span> <span class="o">=</span> <span class="s2">&quot;9/1/0 0/9/1 0/0/1 &quot;</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">spec_b</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(B2|B1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>B1</i></th><th>full</th><th>half</th><th>empty</th></tr>
  </thead>
  <tbody>
    <tr><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The graphical model approach allows us to easily extend probabilistic
actions to factored state representations. The code below shows one way to do it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">factored</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="s2">&quot;1/0/0&quot;</span><span class="p">)</span> <span class="c1"># initial battery state</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span> <span class="c1"># motion model for location</span>
    <span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">))</span> <span class="c1"># battery evolution model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| caption: A factored Bayes net for the vacuum cleaner problem.</span>
<span class="c1">#| label: fig:factored_bayes_net</span>
<span class="n">show</span><span class="p">(</span><span class="n">factored</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01f7a3e25c01a1e8b347b309f6b67c48f6ebc8a13bd45321c83a0469ea7521ea.svg" src="_images/01f7a3e25c01a1e8b347b309f6b67c48f6ebc8a13bd45321c83a0469ea7521ea.svg" />
</div>
</div>
<p>You can see that under the transition models chosen, there are now Markov chains, and these are indpendent when the action sequence is <em>given</em>.</p>
<section id="id4">
<h3><span class="section-number">3.2.7.1. </span>Exercise<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>Note that the above model makes a number of strong statements about the nature of the world:</p>
<ol class="arabic simple">
<li><p>The next battery state does not depend on where we are in the world. This seems like an OK assumption. Still, can you think of situations where this is not a realistic assumption?</p></li>
<li><p>The next state does not depend on the battery life. Maybe this is not so defensible: clearly, if the battery is empty the robot cannot move, and the next state is the same as the previous state. It is worthwhile to think about what you would change above to make a more realistic model of the world.</p></li>
</ol>
</section>
</section>
<section id="gtsam-101">
<h2><span class="section-number">3.2.8. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>The GTSAM concepts used in this section, explained.</p>
</div></blockquote>
<p>As in Chapter 2, we once again used a <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteConditional</span></code>, this time to specify a motion model for the controlled Markov chain above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pretty</span><span class="p">(</span><span class="n">motion_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(X2|X1,A1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>X1</i></th><th><i>A1</i></th><th>Living Room</th><th>Kitchen</th><th>Office</th><th>Hallway</th><th>Dining Room</th></tr>
  </thead>
  <tbody>
    <tr><th>Living Room</th><th>L</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>R</th><td>0.2</td><td>0.8</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>U</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>D</th><td>0.2</td><td>0</td><td>0</td><td>0.8</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>L</th><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>R</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>U</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>D</th><td>0</td><td>0.2</td><td>0</td><td>0</td><td>0.8</td></tr>
    <tr><th>Office</th><th>L</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Office</th><th>R</th><td>0</td><td>0</td><td>0.2</td><td>0.8</td><td>0</td></tr>
    <tr><th>Office</th><th>U</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Office</th><th>D</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Hallway</th><th>L</th><td>0</td><td>0</td><td>0.8</td><td>0.2</td><td>0</td></tr>
    <tr><th>Hallway</th><th>R</th><td>0</td><td>0</td><td>0</td><td>0.2</td><td>0.8</td></tr>
    <tr><th>Hallway</th><th>U</th><td>0.8</td><td>0</td><td>0</td><td>0.2</td><td>0</td></tr>
    <tr><th>Hallway</th><th>D</th><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
    <tr><th>Dining Room</th><th>L</th><td>0</td><td>0</td><td>0</td><td>0.8</td><td>0.2</td></tr>
    <tr><th>Dining Room</th><th>R</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>Dining Room</th><th>U</th><td>0</td><td>0.8</td><td>0</td><td>0</td><td>0.2</td></tr>
    <tr><th>Dining Room</th><th>D</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Above, we use the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteBayesNet</span></code> class, and in particular these methods:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add(self:,</span> <span class="pre">key:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">parents:</span> <span class="pre">List[Tuple[int,</span> <span class="pre">int]],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code>: adds a conditional with the same arguments as the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteConditional</span></code> constructor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">at(self,</span> <span class="pre">i:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">gtsam.DiscreteConditional</span></code>: retrieves the <span class="math notranslate nohighlight">\(i^{th}\)</span> conditional added.</p></li>
</ul>
<p>We used a sleight of hand above to extend the battery depletion model to depend on the navigation action. The following is a bit of python code that replicates our specification four times:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 &#39;
</pre></div>
</div>
</div>
</div>
<p>We then made sure to specify the action <em>before</em> the previous battery state, so that the string above works out. Below we pretty-print to  verify that this came out right:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pretty</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(B2|A2,B1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>A2</i></th><th><i>B1</i></th><th>full</th><th>half</th><th>empty</th></tr>
  </thead>
  <tbody>
    <tr><th>L</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>L</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>L</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>R</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>R</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>R</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>U</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>U</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>U</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>D</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>D</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>D</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Of course, it is entirely possible to make the battery model <em>dependent</em> on the action chosen.</p>
<p>Finally, a word about the graphs above. You might wonder, why these graphs come out so beautifully positioned, e.g., to indicate time from left to right. This was accomplished with the <code class="docutils literal notranslate"><span class="pre">hints</span></code> argument, which positions variables series at an appropriate height. Similarly, the <code class="docutils literal notranslate"><span class="pre">boxes</span></code> argument (which takes <code class="docutils literal notranslate"><span class="pre">gtsam.Keys</span></code>, not tuples) indicates which variables should considered as given.</p>
<p>These arguments are handled in the <a class="reference external" href="https://gtbook.github.io/gtbook/"><code class="docutils literal notranslate"><span class="pre">gtbook</span></code> library</a>, and are passed on in the appropriate format to the underlying GTSAM <code class="docutils literal notranslate"><span class="pre">dot</span></code> methods.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S31_vacuum_state.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3.1. </span>Modeling the State of the Vacuum Cleaning Robot</p>
      </div>
    </a>
    <a class="right-next"
       href="S33_vacuum_sensing.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.3. </span>Dynamic Bayesian Networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-outcomes-of-actions">3.2.1. Probabilistic Outcomes of Actions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">3.2.1.1. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-sequences-of-actions">3.2.2. Understanding Sequences of Actions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#state-transition-matrices-and-the-belief-state">3.2.3. State Transition Matrices and the Belief State</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">3.2.3.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlled-markov-chains">3.2.4. Controlled Markov Chains</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.2.4.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-simulation">3.2.5. Forward Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.2.5.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-networks">3.2.6. Bayesian Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">3.2.6.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factored-state-representations">3.2.7. Factored State Representations*</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">3.2.7.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">3.2.8. GTSAM 101</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>