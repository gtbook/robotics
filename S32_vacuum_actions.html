

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>3.2. Actions over time &#8212; Introduction to Robotics and Perception</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-312077-7"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-312077-7');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S32_vacuum_actions';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3.3. Dynamic Bayes Nets" href="S33_vacuum_sensing.html" />
    <link rel="prev" title="3.1. Modeling the State of the Vacuum Cleaning Robot" href="S31_vacuum_state.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Introduction to Robotics and Perception - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Introduction to Robotics and Perception - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction to Robotics and Perception
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="S10_introduction.html">1. Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S11_intro_state.html">1.1. Representing State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S12_intro_actions.html">1.2. Robot Actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S13_intro_sensing.html">1.3. Sensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="S14_intro_perception.html">1.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S15_intro_decision.html">1.5. Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S16_intro_learning.html">1.6. Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S20_sorter_intro.html">2. A Trash Sorting Robot</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S21_sorter_state.html">2.1. Modeling the World State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S22_sorter_actions.html">2.2. Actions for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S23_sorter_sensing.html">2.3. Sensors for Sorting Trash</a></li>
<li class="toctree-l2"><a class="reference internal" href="S24_sorter_perception.html">2.4. Perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="S25_sorter_decision_theory.html">2.5. Decision Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="S26_sorter_learning.html">2.6. Learning</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="S30_vacuum_intro.html">3. A Robot Vacuum Cleaner</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="S31_vacuum_state.html">3.1. Modeling the State of the Vacuum Cleaning Robot</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">3.2. Actions over time</a></li>
<li class="toctree-l2"><a class="reference internal" href="S33_vacuum_sensing.html">3.3. Dynamic Bayes Nets</a></li>
<li class="toctree-l2"><a class="reference internal" href="S34_vacuum_perception.html">3.4. Perception with Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="S35_vacuum_decision.html">3.5. Markov Decision Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="S36_vacuum_RL.html">3.6. Reinforcement Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S40_logistics_intro.html">4. Warehouse Robots in 2D</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S41_logistics_state.html">4.1. Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S42_logistics_actions.html">4.2. Moving in 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="S43_logistics_sensing.html">4.3. Sensor Models with Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="S44_logistics_perception.html">4.4. Localization</a></li>
<li class="toctree-l2"><a class="reference internal" href="S45_logistics_planning.html">4.5. Planning for Logistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="S46_logistics_learning.html">4.6. Some System Identification</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S50_diffdrive_intro.html">5. A Mobile Robot With Simple Kinematics</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S51_diffdrive_state.html">5.1. State Space for a Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S52_diffdrive_actions.html">5.2. Motion Model for the Differential Drive Robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="S53_diffdrive_sensing.html">5.3. Robot Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S54_diffdrive_perception.html">5.4. Computer Vision 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="S55_diffdrive_planning.html">5.5. Path Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="S56_diffdrive_learning.html">5.6. Deep Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S60_driving_intro.html">6. Autonomous Vehicles</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S61_driving_state.html">6.1. Planar Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="S62_driving_actions.html">6.2. Kinematics for Driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="S63_driving_sensing.html">6.3. Sensing for Autonomous Vehicles</a></li>
<li class="toctree-l2"><a class="reference internal" href="S64_driving_perception.html">6.4. SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S65_driving_planning.html">6.5. Planning for Autonomous Driving.</a></li>
<li class="toctree-l2"><a class="reference internal" href="S66_driving_DRL.html">6.6. Deep Reinforcement Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="S70_drone_intro.html">7. Autonomous Drones in 3D</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S71_drone_state.html">7.1. Moving in Three Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S72_drone_actions.html">7.2. Multi-rotor Aircraft</a></li>
<li class="toctree-l2"><a class="reference internal" href="S73_drone_sensing.html">7.3. Sensing for Drones</a></li>
<li class="toctree-l2"><a class="reference internal" href="S74_drone_perception.html">7.4. Visual SLAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="S75_drone_planning.html">7.5. Trajectory Optimization</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gtbook/robotics" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS32_vacuum_actions.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S32_vacuum_actions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Actions over time</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#primitive-actions">3.2.1. Primitive Actions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-outcomes-of-actions">3.2.2. Probabilistic Outcomes of Actions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">3.2.2.1. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-the-posterior-distribution-for-a-sequence-of-actions">3.2.3. Computing the Posterior Distribution for a Sequence of Actions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#state-transition-matrices-and-the-belief-state">3.2.4. State Transition Matrices and the Belief State</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlled-markov-chains">3.2.5. Controlled Markov Chains</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-simulation">3.2.6. Forward Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">3.2.6.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-nets">3.2.7. Bayes Nets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factored-state-representations">3.2.8. Factored State Representations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.2.8.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">3.2.9. GTSAM 101</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S32_vacuum_actions.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="actions-over-time">
<h1><span class="section-number">3.2. </span>Actions over time<a class="headerlink" href="#actions-over-time" title="Permalink to this heading">#</a></h1>
<blockquote>
<div><p>We can use the language of probability to describe systems with uncertainty in the effects of actions.</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/S32-iRobot_vacuuming_robot-04.jpg"><img alt="Splash image with vacuuming robot in action" class="align-center" src="_images/S32-iRobot_vacuuming_robot-04.jpg" style="width: 40%;" /></a>
<p>In the real world, robots do not always execute actions perfectly, for a
variety of reasons.
To model the uncertainty when executing an action, we will once again use the
language of probability.
We will use <em>conditional probability distributions</em> to model how we can affect the state
of the robot by actions.
Recall that in Chapter 2 we used conditional probabilities to model
the effects of uncertainty in sensing at a specific moment in time.
Here, we use conditional probabilities to model the uncertainty in state transitions when
actions are executed.</p>
<p>We can model this using graphs, with directed edges that specify conditional
probabilities on variables.
We can use these graphical models to generate sample system trajectories
for a fixed sequence of actions.
Such sample trajectories can be used for planning, as we will see later in the chapter.
In addition, the graphical model approach allows us to easily extend probabilistic actions to
factored state representations, which can provide significant computational advantages.</p>
<section id="primitive-actions">
<h2><span class="section-number">3.2.1. </span>Primitive Actions<a class="headerlink" href="#primitive-actions" title="Permalink to this heading">#</a></h2>
<p>We will assume that our robot is equipped with navigation software that implements four
primitive actions: <em>move left, move right, move up, move down</em>,
which we will denote by <em>L,R,U,D</em>.
Together, these four actions define the <strong>action space</strong>.
The nominal effects of these actions (i.e., the effects of the actions without taking into account uncertainty)
are to move the robot from the current room to an adjacent
room, according to the direction specified by the action.
For example, executing the <em>move down</em> action from the living room should take the robot into the hallway.</p>
<p>We can represent these actions graphically by making a slight modification to our state space graph
from the previous section.
Instead of using undirected edges to denote adjacency, each action contributes a directed edge, as shown in
Figure <a href="#fig:Stochastic" data-reference-type="ref" data-reference="fig:Stochastic">1</a>.
Note that to simplify notation  we use <em>L,R,U,D</em>
instead of <em>move left, move right, move up, move down</em> to label the edges.</p>
<figure id="fig:Stochastic">
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/S32-Actions.png?raw=1" style="width:14cm" alt="" />
<figcaption>Our robot is equipped with
four primitive actions: Left, Right, Up, and Down.
</figcaption>
</figure></section>
<section id="probabilistic-outcomes-of-actions">
<h2><span class="section-number">3.2.2. </span>Probabilistic Outcomes of Actions<a class="headerlink" href="#probabilistic-outcomes-of-actions" title="Permalink to this heading">#</a></h2>
<figure id="fig:Mud">
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/N3-Mud.png?raw=1" style="width:14cm" alt="" />
<figcaption>Mobile robot driving in mud.</figcaption>
</figure>
<p>In the real world, robots do not always execute actions perfectly, for a
variety of reasons. For example, as shown in Figure
<a href="#fig:Mud" data-reference-type="ref" data-reference="fig:Mud">2</a>,
a robot may want to drive forward in an outdoor environment but mud
under its wheels might prevent it from traveling as far as we would like.</p>
<figure id="fig:Pickup">
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/N3-Pick.png?raw=1" style="width:14cm" alt="" />
<figcaption>A humanoid attempting to pick up an object.</figcaption>
</figure>
<p>Or a robot with an articulated arm (Figure
<a href="#fig:Pickup" data-reference-type="ref" data-reference="fig:Pickup">3</a>)
might attempt to pick up an object, but fail.</p>
<p>For our vacuum cleaning robot, a variety of things could go wrong: a particular doorway might be blocked, the robot might get lost, or it might take an action that is simply not available in a particular room - for example executing
<em>move up</em> in the office.</p>
<p>To model the uncertainty associated with executing an action, we will once again use the language of probability.
In particular, we will use the conditional probability <span class="math notranslate nohighlight">\(P(X_{t+1}|X_{t}=x,A=a)\)</span> to define
the the <strong>state transition model</strong>  model, i.e.,
the conditional probability distribution for the next state <span class="math notranslate nohighlight">\(X_{t+1}\)</span>,
given the value <span class="math notranslate nohighlight">\(x\)</span> of the current state <span class="math notranslate nohighlight">\(X_{t}\)</span>, and the value <span class="math notranslate nohighlight">\(a\)</span> of the action <span class="math notranslate nohighlight">\(A\)</span>.
Because the state space in this case involves navigation, we also call the corresponding conditional distribution
<span class="math notranslate nohighlight">\(P(X_{t+1}|X_{t},A)\)</span> a <strong>motion model</strong>.</p>
<p>The code below generates a motion model for moving from state <span class="math notranslate nohighlight">\(X_1\)</span> to <span class="math notranslate nohighlight">\(X_2\)</span> in the
form of a large conditional probability table:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># vacuum.action_space = [&quot;L&quot;,&quot;R&quot;,&quot;U&quot;,&quot;D&quot;,]</span>
<span class="c1"># vacuum.action_spec is a string with the transition probabilities:</span>
<span class="c1">#  &quot;1/0/0/0/0 2/8/0/0/0 1/0/0/0/0 2/0/0/8/0</span>
<span class="c1">#   8/2/0/0/0 0/1/0/0/0 0/1/0/0/0 0/2/0/0/8</span>
<span class="c1">#   0/0/1/0/0 0/0/2/8/0 0/0/1/0/0 0/0/1/0/0</span>
<span class="c1">#   0/0/8/2/0 0/0/0/2/8 8/0/0/2/0 0/0/0/1/0</span>
<span class="c1">#   0/0/0/8/2 0/0/0/0/1 0/8/0/0/2 0/0/0/0/1&quot;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span> <span class="c1"># states for times 1,2 and 3</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span> <span class="c1"># actions for times 1 and 2</span>
<span class="n">motion_model</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">motion_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(X2|X1,A1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>X1</i></th><th><i>A1</i></th><th>Living Room</th><th>Kitchen</th><th>Office</th><th>Hallway</th><th>Dining Room</th></tr>
  </thead>
  <tbody>
    <tr><th>Living Room</th><th>L</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>R</th><td>0.2</td><td>0.8</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>U</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>D</th><td>0.2</td><td>0</td><td>0</td><td>0.8</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>L</th><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>R</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>U</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>D</th><td>0</td><td>0.2</td><td>0</td><td>0</td><td>0.8</td></tr>
    <tr><th>Office</th><th>L</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Office</th><th>R</th><td>0</td><td>0</td><td>0.2</td><td>0.8</td><td>0</td></tr>
    <tr><th>Office</th><th>U</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Office</th><th>D</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Hallway</th><th>L</th><td>0</td><td>0</td><td>0.8</td><td>0.2</td><td>0</td></tr>
    <tr><th>Hallway</th><th>R</th><td>0</td><td>0</td><td>0</td><td>0.2</td><td>0.8</td></tr>
    <tr><th>Hallway</th><th>U</th><td>0.8</td><td>0</td><td>0</td><td>0.2</td><td>0</td></tr>
    <tr><th>Hallway</th><th>D</th><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
    <tr><th>Dining Room</th><th>L</th><td>0</td><td>0</td><td>0</td><td>0.8</td><td>0.2</td></tr>
    <tr><th>Dining Room</th><th>R</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>Dining Room</th><th>U</th><td>0</td><td>0.8</td><td>0</td><td>0</td><td>0.2</td></tr>
    <tr><th>Dining Room</th><th>D</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is of course very tedious to specify this table by hand.
In this case, for each of the four actions, we must compute a transition probability from
each of the five possible starting rooms to each of the five possible destination rooms:
<span class="math notranslate nohighlight">\(4*5*5=100\)</span> entries.
In the example above, impossible transitions (e.g., moving up from the living room to any other room)
are assigned zero probability.
Other actions are assumed to have 80% chance of success (e.g., moving right from the living room
and arriving to the kitchen is assigned a transition probability of <span class="math notranslate nohighlight">\(0.8\)</span>).</p>
<p>Conditional probability distributions do not <em>have</em> to be specified as giant
tables. Because the state space is potentially quite large, such a
motion model is almost never explicitly specified, but
rather exploits the semantics of the states and actions to calculate the conditional distribution at run-time.
For example, rather than enumerate every possible action from every possible room, we might
determine the probability of successfully moving to an adjacent room is <span class="math notranslate nohighlight">\(0.8\)</span>, for all
rooms and for all actions, and that the probability of failing to do so is <span class="math notranslate nohighlight">\(0.2\)</span>.
If we apply this rule to each combination of action and adjacent rooms, we can
construct specific rows the table above on an as-needed basis.</p>
<section id="exercises">
<h3><span class="section-number">3.2.2.1. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Even though the CPT above
has 100 numbers in it, how many independent degrees of freedom do we
actually have when specifying this CPT?</p></li>
<li><p>Specify a <em>parametric</em> conditional density for the action models for
the vacuuming robot that is somewhat realistic, yet not completely
deterministic.</p></li>
<li><p>It is possible to create models that do not reflect everyday
physics. For example, how could we model the game “Portal”?</p></li>
</ol>
</section>
</section>
<section id="computing-the-posterior-distribution-for-a-sequence-of-actions">
<h2><span class="section-number">3.2.3. </span>Computing the Posterior Distribution for a Sequence of Actions<a class="headerlink" href="#computing-the-posterior-distribution-for-a-sequence-of-actions" title="Permalink to this heading">#</a></h2>
<p>Suppose we apply a sequence of actions <span class="math notranslate nohighlight">\(a_1 \dots a_t\)</span>
and we wish to compute the probability distribution associated to the resulting state <span class="math notranslate nohighlight">\(X_{t+1}\)</span>.
We can accomplish this by applying the law of total probability.</p>
<p>The <strong>law of total probability</strong> provides a convenient way to compute the probability of an
event by considering all of the different ways the event could occur. Suppose
we have a set of events <span class="math notranslate nohighlight">\({\cal B} = \{B_1, \dots , B_n\}\)</span> such that <span class="math notranslate nohighlight">\(B_i \cap B_j = \emptyset\)</span> when <span class="math notranslate nohighlight">\(i \neq j\)</span>
and with <span class="math notranslate nohighlight">\(\cup B_i = \Omega\)</span>, i.e., the set of events <span class="math notranslate nohighlight">\({\cal B}\)</span> form a partition of the sample space.
To compute the probability of an event <span class="math notranslate nohighlight">\(A\)</span>, the law of total probability is given by</p>
<div class="math notranslate nohighlight">
\[
P(A) = \sum_{i} P(A | B_i ) P(B_i)
\]</div>
<p>We merely sum the conditional probabilities <span class="math notranslate nohighlight">\(P(A | B_i)\)</span> for each event <span class="math notranslate nohighlight">\(B_i\)</span>, weighted by the probability
of the event <span class="math notranslate nohighlight">\(B_i\)</span>.</p>
<p>We can use the law of total probability to compute the probability that the robot
is in state <span class="math notranslate nohighlight">\(x_{t+1}\)</span> at time <span class="math notranslate nohighlight">\(t+1\)</span> by conditioning on the possible states for time <span class="math notranslate nohighlight">\(t\)</span>.:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(X_{t+1} = x_{t+1} ) = \sum_{x_t} P(X_{t+1} | X_t = x_t) P(X_t = x_t) \\
\end{split}\]</div>
<p>Now, condition every term in the above equation on the sequence of actions
<span class="math notranslate nohighlight">\(a_1 \dots a_t\)</span>, and we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(X_{t+1} = x_{t+1} | a_1 \dots a_t) = \sum_{x_t} P(X_{t+1} | X_t = x_t, a_1 \dots a_t) P(X_t = x_t |a_1 \dots a_t) \\
\end{split}\]</div>
<p>This expression may seem complex, but it can be simplified by making the following observation:
<em>If we know that the robot is in a specific state <span class="math notranslate nohighlight">\(x_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, then the next state will depend only
on the action executed at time <span class="math notranslate nohighlight">\(t\)</span>; the previously executed actions will not affect our belief
about <span class="math notranslate nohighlight">\(X_{t+1}\)</span>.</em><br />
For example, if the robot executes the action <em>move down</em> knowing with certainty that it is in the living room at time <span class="math notranslate nohighlight">\(t\)</span>,
the sequence of actions that brought the robot to the living room (i.e., actions <span class="math notranslate nohighlight">\(a_1 \dots a_{t-1}\)</span>) does not affect our belief
about whether the robot will arrive to the hallway.
Mathematically, we can write this relationship as follows:</p>
<div class="math notranslate nohighlight">
\[ P(X_{t+1} | X_t = x_t, a_1 \dots a_t) =  P(X_{t+1} | X_t = x_t,  a_t) \]</div>
<p>We can also  simplify the term <span class="math notranslate nohighlight">\(P(X_t = x_t |a_1 \dots a_t)\)</span>.
Notice that the action performed at time <span class="math notranslate nohighlight">\(t\)</span> has no affect on the state at time <span class="math notranslate nohighlight">\(t\)</span>.
For example, if the robot executes the <em>move down</em> action
in the living room at time <span class="math notranslate nohighlight">\(t\)</span>, this actions does not change the fact that the robot was in the living room
at time <em>t</em>.
Therefore, we have</p>
<div class="math notranslate nohighlight">
\[ P(X_t = x_t |a_1 \dots a_t) =  P(X_t = x_t |a_1 \dots a_{t-1})\]</div>
<p>Applying these two simplifications, we obtain the final form for our posterior:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(X_{t+1} = x_{t+1} | a_1 \dots a_t) = \sum_{x_t} P(X_{t+1} | X_t = x_t, a_t) P(X_t = x_t |a_1 \dots a_{t-1}) \\
\end{split}\]</div>
<p>We can think of the terms in this expression as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(X_{t+1} = x_{t+1} | a_1 \dots a_t)\)</span> is the posterior</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_{t+1} | X_t = x_t, a_t)\)</span> is the motion model</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_t = x_t |a_1 \dots a_{t-1})\)</span> is the prior.</p></li>
</ul>
<p>For the initial state, no actions have yet been applied, and the prior is merely
the probability distribution at the initial state <span class="math notranslate nohighlight">\(P(X_1 = x_1)\)</span>.
Specifically, we can compute the posterior at time <span class="math notranslate nohighlight">\(t=2\)</span> by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(X_{2} = x_{2} | a_1 ) = \sum_{x_1} P(X_{2} | X_1 = x_1, a_1) P(X_1 = x_1 ) \\
\end{split}\]</div>
</section>
<section id="state-transition-matrices-and-the-belief-state">
<h2><span class="section-number">3.2.4. </span>State Transition Matrices and the Belief State<a class="headerlink" href="#state-transition-matrices-and-the-belief-state" title="Permalink to this heading">#</a></h2>
<p>In order to specify the complete posterior distribution at time <span class="math notranslate nohighlight">\(t+1\)</span>, we would need to perform the calculation above
five times, once for each of the possible next states (<span class="math notranslate nohighlight">\(L,K,O,H,D\)</span>).
This complete distribution is called the belief state, defined as</p>
<div class="math notranslate nohighlight">
\[b_{t+1} = \left[ 
P(X_{t+1} = L | a_{1:t}),
P(X_{t+1} = K | a_{1:t}),
P(X_{t+1} = O | a_{1:t}),
P(X_{t+1} = H | a_{1:t}),
P(X_{t+1} = D | a_{1:t}) \right]
\]</div>
<p>in which we have simplified notation by using the notation
<span class="math notranslate nohighlight">\(a_{1:t} = a_1, \dots, a_t\)</span>.</p>
<p>We can write the equations for the belief state in a compact form by writing the conditional probability tables as
transition matrices.
To do so, for each action, we merely gather the corresponding rows from the complete conditional probability
table into a state transition matrix.
For the action <em>move right</em>, this is illustrated below in
Figure <a href="#fig:TM" data-reference-type="ref" data-reference="fig:TM">4</a>.</p>
<figure id="fig:TM">
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/S32-transition-matrix.png?raw=1" style="width:20cm" alt="" />
<figcaption>The transition matrix for the action *move right*.
</figcaption>
</figure>
<p>If we apply the action <em>move right</em> to the initial state, by straightforward calculations, we can see that <span class="math notranslate nohighlight">\(b_2 = b_1 M_r\)</span>.
This can be generalized to a sequence of actions.
If we execute action <span class="math notranslate nohighlight">\({\cal A}_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>,
the belief state <span class="math notranslate nohighlight">\(b_{t+1}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[b_{t+1} = b_t M_{{\cal A}_t}\]</div>
<p>in which <span class="math notranslate nohighlight">\(M_{\cal A}\)</span>
the conditional probability matrix for action <span class="math notranslate nohighlight">\(\cal A\)</span> and <span class="math notranslate nohighlight">\(b_t\)</span> is the
belief state at time <span class="math notranslate nohighlight">\(t\)</span>.
We refer to this equation as a <em>belief transition function</em> – given the
belief at time <span class="math notranslate nohighlight">\(t\)</span> and the action <span class="math notranslate nohighlight">\(a_t\)</span>, it can be applied to compute the belief at time <span class="math notranslate nohighlight">\(t+1\)</span>.
This result can be applied recursively to yield</p>
<div class="math notranslate nohighlight">
\[b_{t+1} = b_1 M_{{\cal A}_1} \dots M_{{\cal A}_t}\]</div>
</section>
<section id="controlled-markov-chains">
<h2><span class="section-number">3.2.5. </span>Controlled Markov Chains<a class="headerlink" href="#controlled-markov-chains" title="Permalink to this heading">#</a></h2>
<p>In the derivation above of the belief transition function we employed a temporal decoupling property,
namely, given the state at time <span class="math notranslate nohighlight">\(t\)</span>, all actions that were applied prior to time <span class="math notranslate nohighlight">\(t\)</span> were irrelevant
to determining the belief state <span class="math notranslate nohighlight">\(b_{t+1}\)</span>.
This is an example of what is called <strong>the Markov property</strong>.
Variations of this property
are essential for reducing the amount of computation required to reason probabilistically over long periods of time.</p>
<p>The most common example of this property arises in systems that are called <strong>Markov chains</strong>.
In its simplest form, a Markov chain is a sequence of random variables, <span class="math notranslate nohighlight">\(X_1, X_2, \dots \)</span>
for which</p>
<div class="math notranslate nohighlight">
\[P(X_{t+1} | X_1 \dots X_t) = P(X_{t+1} | X_t)\]</div>
<p>For Markov chains, knowing <span class="math notranslate nohighlight">\(X_t\)</span> completely decouples the past (i.e., <span class="math notranslate nohighlight">\(X_1 \dots X_{t-1}\)</span>) from the future (i.e., <span class="math notranslate nohighlight">\(X_{t+1}\)</span>).
Therefore, when reasoning about future states, we need not perform computations over the entire
history of the system; if we know <span class="math notranslate nohighlight">\(X_t\)</span>, we need only perform computations related to the present
when reasoning about the future.</p>
<p>Markov chains have a nice graphical representation.
Each node corresponds to a random variable,
and directed edges specify conditional probabilities.
As an application, we can use this simple graphical model to represent
the probabilistic transitions between states, as shown below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span> <span class="c1">## states for times 1...N</span>
<span class="n">markov_chain</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">markov_chain</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">markov_chain</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="s2">&quot;6/1/1/1/1 1/6/1/1/1 1/1/6/1/1 1/1/6/1/1 1/1/1/1/6 &quot;</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">markov_chain</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a124c3fd0e8861a3f5a8c0f77900ef1977c835a508505c4d8d2cc1044b195714.svg" src="_images/a124c3fd0e8861a3f5a8c0f77900ef1977c835a508505c4d8d2cc1044b195714.svg" /></div>
</div>
<p>Each node in this graph denotes a random variable, and therefore each node has an associated probability distribution.
If we know the distribution for the initial state <span class="math notranslate nohighlight">\(X_1\)</span>, we can iteratively compute the distributions for
<span class="math notranslate nohighlight">\(X_t\)</span> for all <span class="math notranslate nohighlight">\(t &gt; 1\)</span> by evaluating the conditional distributions associated to the directed edges in the graph.</p>
<p>Our robot vacuum cleaner is slightly more sophisticated than this simple Markov chain, since
the robot has the ability to execute actions, and these actions affect the propagation
of probabilities through the chain.
This type of system is sometimes called a <strong>controlled Markov chain</strong>, since it incorporates
a control input (the actions) into the usual Markov chain.</p>
<p>Graphically, we can represent such a system by augmenting the graph above to include nodes that denote actions.
We use a <em>box</em> to denote nodes whose values are known.
Since the robot knows which actions it executes, action nodes are denoted by boxes.
For our vacuuming robot, we also know the value of the initial state,
since the robot always begins in the office.
Therefore, we also use a box to denote the initial state in this graph.</p>
<p>As an example, the code below builds the controlled Markov chain for our system up to time <span class="math notranslate nohighlight">\(t=2\)</span>.
By applying the belief transition equation above, we can compute the probabililty distribution for <span class="math notranslate nohighlight">\(X_2\)</span>,
since the action <span class="math notranslate nohighlight">\(a_1\)</span> and the initial state <span class="math notranslate nohighlight">\(X_1\)</span> are both completely known.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">action_prior</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1/1/1/1&quot;</span><span class="p">)</span>
<span class="n">fragment</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">fragment</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">motion_model</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">fragment</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/39ee1d3d1ef9c3795879cb38d917239ba1cb8c282af0063646799a67a0a8b622.svg" src="_images/39ee1d3d1ef9c3795879cb38d917239ba1cb8c282af0063646799a67a0a8b622.svg" /></div>
</div>
<p>Given values for the parent variables, we can examine the corresponding transition probability. For example, if we start from the <span class="math notranslate nohighlight">\(X_1=\text{Office}\)</span> and attempt to go right, i.e., action <span class="math notranslate nohighlight">\(a_1=\text{R}\)</span>, we retrieve the following PMF over the next state <span class="math notranslate nohighlight">\(X_2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="s2">&quot;Office&quot;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="s2">&quot;R&quot;</span><span class="p">})</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">motion_model</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(X2):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>X2</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>Living Room</th><td>0</td></tr>
    <tr><th>Kitchen</th><td>0</td></tr>
    <tr><th>Office</th><td>0.2</td></tr>
    <tr><th>Hallway</th><td>0.8</td></tr>
    <tr><th>Dining Room</th><td>0</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>This idea can be extended to arbitrarily many actions by merely adding action and state nodes for each
time <span class="math notranslate nohighlight">\(t\)</span>. The code below creates a controlled Markov chain with three states.
Try varying the value of <span class="math notranslate nohighlight">\(N\)</span> to see other examples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span> <span class="c1"># actions for times 1...N-1</span>
<span class="n">bayesNet</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">bayesNet</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">bayesNet</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span> <span class="c1"># add creates conditional and adds</span>
<span class="n">show</span><span class="p">(</span><span class="n">bayesNet</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5295e96ddc84769836ff511acd3ebd70b8cfce49150cd4ca9feb6aa1c02aa71f.svg" src="_images/5295e96ddc84769836ff511acd3ebd70b8cfce49150cd4ca9feb6aa1c02aa71f.svg" /></div>
</div>
</section>
<section id="forward-simulation">
<h2><span class="section-number">3.2.6. </span>Forward Simulation<a class="headerlink" href="#forward-simulation" title="Permalink to this heading">#</a></h2>
<p>We can use simulation in a graphical model to explore what a sequence of
actions might yield as an outcome.
To sample from a <em>conditional</em> distribution <span class="math notranslate nohighlight">\(p(X|Y)\)</span> we need to make
sure we sample the variable <span class="math notranslate nohighlight">\(Y\)</span> beforehand, and then proceed simply by
selecting the appropriate PMF depending on the value of <span class="math notranslate nohighlight">\(Y\)</span>. We can then
proceed as before using the inverse transform sampling method.</p>
<p>Forward sampling in a Markov chain simply repeats these steps in
succession, proceeding from left to right.
Simulating a robot <em>given</em> an initial state <span class="math notranslate nohighlight">\(X_1\)</span> and
sequence of actions <span class="math notranslate nohighlight">\(a_{1}, a_{2},\ldots\)</span> is then equivalent to sampling
from this Markov chain:</p>
<ol class="arabic">
<li><p>Set <span class="math notranslate nohighlight">\(k=1\)</span>.</p></li>
<li><p>Simulate the effect of the next action by sampling the next state
<span class="math notranslate nohighlight">\(x_{k+1}\)</span> from</p>
<div class="math notranslate nohighlight">
\[P(X_{k+1}|X_{k}=x_{k},A_{k}=a_{k}).\]</div>
</li>
<li><p>Increment <span class="math notranslate nohighlight">\(k\)</span> and return to step <span class="math notranslate nohighlight">\(2\)</span>.</p></li>
</ol>
<p>Below we show how to code this up and show  4 different <strong>rollouts</strong> by simulating in this way.
Rollouts will be discussed in more detail in Section 3.5.
After that, we can approximate the PMF of the final state by constructing a
histogram over the possible values of the state:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">):</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="n">x1</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">a1</span><span class="p">})</span> <span class="c1"># initial state and action</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">[</span><span class="n">bayesNet</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">values</span><span class="p">)]</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span><span class="n">x2</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">a2</span><span class="p">})</span> <span class="c1"># next state and action</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">[</span><span class="n">bayesNet</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">values</span><span class="p">)]</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;Office&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">,</span><span class="s2">&quot;U&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Office&#39;, &#39;Office&#39;, &#39;Office&#39;]
[&#39;Office&#39;, &#39;Hallway&#39;, &#39;Hallway&#39;]
[&#39;Office&#39;, &#39;Hallway&#39;, &#39;Living Room&#39;]
[&#39;Office&#39;, &#39;Office&#39;, &#39;Office&#39;]
</pre></div>
</div>
</div>
</div>
<p>While simple, simulating from a forward model is a rather important
technique, and underlies some of the recent successes in deep
reinforcement learning, as well as the success of DeepMind in beating
the world’s best players of the game of Go.</p>
<section id="exercise">
<h3><span class="section-number">3.2.6.1. </span>Exercise<a class="headerlink" href="#exercise" title="Permalink to this heading">#</a></h3>
<p>Generalize the above forward sampling algorithm to an arbitrary number of actions. Hint: you will have to make sure the variables are defined, and the Bayes Net is extended properly.</p>
</section>
</section>
<section id="bayes-nets">
<h2><span class="section-number">3.2.7. </span>Bayes Nets<a class="headerlink" href="#bayes-nets" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>Bayes nets provide a graphical language to string together conditional probabilities into a generative world model.</p>
</div></blockquote>
<p>A Markov chain is a special case of the more general <strong>Bayes network</strong>.
A Bayes net is a directed <em>acyclic</em> graph (DAG) describing a factored
probability distribution over a set of random variables.
By the term <em>factored probability distribution</em>, we mean that the
probability distribution is expressed as a product of terms, each of which is
called a factor.</p>
<p>For Bayes nets, the joint probability distribution for a set
of random variables, <span class="math notranslate nohighlight">\(X_1, \dots, X_n\)</span> is expressed in terms
of conditional probabilities for the individual variables <span class="math notranslate nohighlight">\(X_i\)</span>
as</p>
<div class="math notranslate nohighlight">
\[P(X_1, \dots , X_n)=\prod_{i=1}^{n}P(X_{i}|\Pi_{i})\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the number
of variables, and <span class="math notranslate nohighlight">\(\Pi_{i}\)</span> denotes the set of parents for variable
<span class="math notranslate nohighlight">\(X_{i}\)</span>. An example of a Bayes net is shown in the Figure below,
and it is simply a graphical representation of which random variables’s
CPT depend on which other variables. In this case, the joint
distribution can be read off as</p>
<div class="math notranslate nohighlight">
\[P(W,X,Y,Z)=P(W|X,Z)P(X|Y,Z)P(Y|Z)P(Z).\]</div>
<p>Note that the order in which
we multiply the conditionals does not matter, but we typically prefer to put the parents more towards the right, as above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wxyz</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;W&quot;</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">Z1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="p">[</span><span class="n">X1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="p">[</span><span class="n">Y1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="p">[</span><span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="s2">&quot;1/1&quot;</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">wxyz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/12f265cdf0e20ed01de7ef05320a4fd2f80167cdebfdd77aa86334c591bd5c9c.svg" src="_images/12f265cdf0e20ed01de7ef05320a4fd2f80167cdebfdd77aa86334c591bd5c9c.svg" /></div>
</div>
<p>Note that the above graph has cycles, but the cycles are only in the underlying <em>undirected</em> graph, not in the directed graph. Directed cycles, i.e. cycles with a consistent direction, are not allowed.</p>
<p>Bayes nets can be very efficient representations of complex
probability distributions, as they encode the dependence and especially
independence relationships between the variables.
The Bayes net above was created assuming binary variables, and hence did not take
a lot of effort to specify, but as we saw above, even for relatively small state spaces
the complexity of specifying CPTs can be daunting.</p>
<p>If we were to construct a full table of probabilities for each possible
outcome of the variables <span class="math notranslate nohighlight">\(W\)</span>,<span class="math notranslate nohighlight">\(X\)</span>,<span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span>, the table could be quite
long. For example, if we assume they all have 10 possible values,
then the table required to represent the full joint distribution will have <span class="math notranslate nohighlight">\(10^{4}\)</span> entries,
i.e., <span class="math notranslate nohighlight">\(10,000\)</span> unique values. You
can save a tiny bit, because they have to sum up to 1, so strictly
speaking we need only <span class="math notranslate nohighlight">\(9,999\)</span> values. In contrast, we can tally how many
entries all four CPT tables have for the Bayes net above.
This is shown in the following table.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>CPT</p></th>
<th class="head"><p># entries</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><em>P(Z)</em></p></td>
<td><p>9</p></td>
</tr>
<tr class="row-odd"><td><p><em>P(Y|Z)</em></p></td>
<td><p>90</p></td>
</tr>
<tr class="row-even"><td><p><em>P(X|Y,Z)</em></p></td>
<td><p>900</p></td>
</tr>
<tr class="row-odd"><td><p><em>P(W|X,Z)</em></p></td>
<td><p>900</p></td>
</tr>
</tbody>
</table>
<p>For example, <span class="math notranslate nohighlight">\(P(X|Y,Z)\)</span> has 900 entries, i.e., 9
(independent) entries for each of 100 possible combinations of <span class="math notranslate nohighlight">\(Y\)</span> and
<span class="math notranslate nohighlight">\(Z\)</span>. Hence, the total number of parameters we need is only <span class="math notranslate nohighlight">\(1,899\)</span>,
which is significantly less than <span class="math notranslate nohighlight">\(9,999\)</span>.</p>
</section>
<section id="factored-state-representations">
<h2><span class="section-number">3.2.8. </span>Factored State Representations<a class="headerlink" href="#factored-state-representations" title="Permalink to this heading">#</a></h2>
<p>Factored state representations are useful if the state of the robot can
be described using features that are relatively independent of each
other. Continuing our example, the robot vacuum cleaner might also run
out of battery power, so we could associate a different variable with
its battery status, e.g., <code class="docutils literal notranslate"><span class="pre">empty</span></code>, <code class="docutils literal notranslate"><span class="pre">half</span></code>, or <code class="docutils literal notranslate"><span class="pre">full</span></code>.
The state of the robot would then be specified by the combination of
two variables: the room the robot is in, and its battery status.
Note that now the total number of possible states
is combinatorial: if there are five rooms and three different battery
levels, we have a total of 15 possible states for the robot.</p>
<p>A possible model for battery life could be the following transition table, which is independent of which action was taken, and will always progress from <code class="docutils literal notranslate"><span class="pre">full</span></code> to <code class="docutils literal notranslate"><span class="pre">half</span></code>, then from <code class="docutils literal notranslate"><span class="pre">half</span></code> to <code class="docutils literal notranslate"><span class="pre">empty</span></code>, and of course once the battery is empty it will stay empty:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">battery_states</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;full&quot;</span><span class="p">,</span> <span class="s2">&quot;half&quot;</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">battery_states</span><span class="p">)</span>
<span class="n">spec_b</span> <span class="o">=</span> <span class="s2">&quot;9/1/0 0/9/1 0/0/1 &quot;</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">spec_b</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(B2|B1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>B1</i></th><th>full</th><th>half</th><th>empty</th></tr>
  </thead>
  <tbody>
    <tr><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The graphical model approach allows us to easily extend probabilistic
actions to factored state representations. The code below shows one way to do it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">factored</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="s2">&quot;1/0/0&quot;</span><span class="p">)</span> <span class="c1"># initial battery state</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span> <span class="c1"># motion model for location</span>
    <span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">))</span> <span class="c1"># battery evolution model</span>
<span class="n">show</span><span class="p">(</span><span class="n">factored</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/31569d3db2125738e94e18b4eac5022ae3a8f4b84ee978ea7d0387128d36de13.svg" src="_images/31569d3db2125738e94e18b4eac5022ae3a8f4b84ee978ea7d0387128d36de13.svg" /></div>
</div>
<p>You can see that under the transition models chosen, there are now Markov chains, and these are indpendent when the action sequence is <em>given</em>.</p>
<section id="id1">
<h3><span class="section-number">3.2.8.1. </span>Exercise<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>Note that the above model makes a number of strong statements about the nature of the world:</p>
<ol class="arabic simple">
<li><p>The next battery state does not depend on where we are in the world. This seems like an OK assumption. Still, can you think of situations where this is not a realistic assumption?</p></li>
<li><p>The next state does not depend on the battery life. Maybe this is not so defensible: clearly, if the battery is empty the robot cannot move, and the next state is the same as the previous state. It is worthwhile to think about what you would change above to make a more realistic model of the world.</p></li>
</ol>
</section>
</section>
<section id="gtsam-101">
<h2><span class="section-number">3.2.9. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>The GTSAM concepts used in this section, explained.</p>
</div></blockquote>
<p>Above, we use the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteBayesNet</span></code> class, and in particular these methods:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add(self:,</span> <span class="pre">key:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">parents:</span> <span class="pre">List[Tuple[int,</span> <span class="pre">int]],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code>: adds a conditional with the same arguments as the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteConditional</span></code> constructor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">at(self,</span> <span class="pre">i:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">gtsam.DiscreteConditional</span></code>: retrieves the <span class="math notranslate nohighlight">\(i^{th}\)</span> conditional added.</p></li>
</ul>
<p>We used a sleight of hand above to extend the battery depletion model to depend on the navigation action. The following is a bit of python code that replicates our specification four times:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 &#39;
</pre></div>
</div>
</div>
</div>
<p>We then made sure to specify the action <em>before</em> the previous battery state, so that the string above works out. Below we pretty-print to  verify that this came out right:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pretty</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(B2|A2,B1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>A2</i></th><th><i>B1</i></th><th>full</th><th>half</th><th>empty</th></tr>
  </thead>
  <tbody>
    <tr><th>L</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>L</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>L</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>R</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>R</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>R</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>U</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>U</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>U</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>D</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>D</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>D</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Of course, it is entirely possible to make the battery model <em>dependent</em> on the action chosen.</p>
<p>Finally, a word about the graphs above. You might wonder, why these graphs come out so beautifully positioned, e.g., to indicate time from left to right. This was accomplished with the <code class="docutils literal notranslate"><span class="pre">hints</span></code> argument, which positions variables series at an appropriate height. Similarly, the <code class="docutils literal notranslate"><span class="pre">boxes</span></code> argument (which takes <code class="docutils literal notranslate"><span class="pre">gtsam.Keys</span></code>, not tuples) indicates which variables should considered as given.</p>
<p>These arguments are handled in the <a class="reference external" href="https://gtbook.github.io/gtbook/"><code class="docutils literal notranslate"><span class="pre">gtbook</span></code> library</a>, and are passed on in the appropriate format to the underlying GTSAM <code class="docutils literal notranslate"><span class="pre">dot</span></code> methods.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S31_vacuum_state.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3.1. </span>Modeling the State of the Vacuum Cleaning Robot</p>
      </div>
    </a>
    <a class="right-next"
       href="S33_vacuum_sensing.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.3. </span>Dynamic Bayes Nets</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#primitive-actions">3.2.1. Primitive Actions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-outcomes-of-actions">3.2.2. Probabilistic Outcomes of Actions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">3.2.2.1. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-the-posterior-distribution-for-a-sequence-of-actions">3.2.3. Computing the Posterior Distribution for a Sequence of Actions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#state-transition-matrices-and-the-belief-state">3.2.4. State Transition Matrices and the Belief State</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlled-markov-chains">3.2.5. Controlled Markov Chains</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-simulation">3.2.6. Forward Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">3.2.6.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-nets">3.2.7. Bayes Nets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factored-state-representations">3.2.8. Factored State Representations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.2.8.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gtsam-101">3.2.9. GTSAM 101</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Frank Dellaert and Seth Hutchinson
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>